{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import random\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_time = 333\n",
    "name = 'abalone regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/Users/matt/Desktop/abalone.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:49941..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_144\"; Java(TM) SE Runtime Environment (build 1.8.0_144-b01); Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)\n",
      "  Starting server from /anaconda3/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/qb/37dx26k10cn0288tblh64zg40000gn/T/tmp7fqz_cel\n",
      "  JVM stdout: /var/folders/qb/37dx26k10cn0288tblh64zg40000gn/T/tmp7fqz_cel/h2o_matt_started_from_python.out\n",
      "  JVM stderr: /var/folders/qb/37dx26k10cn0288tblh64zg40000gn/T/tmp7fqz_cel/h2o_matt_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:49941\n",
      "Connecting to H2O server at http://127.0.0.1:49941... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.20.0.8</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>24 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_matt_pkfcp3</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>5.750 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:49941</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.3 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         02 secs\n",
       "H2O cluster timezone:       America/New_York\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.20.0.8\n",
       "H2O cluster version age:    24 days\n",
       "H2O cluster name:           H2O_from_python_matt_pkfcp3\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    5.750 Gb\n",
       "H2O cluster total cores:    0\n",
       "H2O cluster allowed cores:  0\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:49941\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.3 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "port_no=random.randint(5555,55555)\n",
    "h2o.init(strict_version_check=False,min_mem_size_GB=6,port=port_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/matt/Desktop/abalone.csv\n"
     ]
    }
   ],
   "source": [
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "df = h2o.import_file(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Sex  </th><th style=\"text-align: right;\">  Length</th><th style=\"text-align: right;\">  Diameter</th><th style=\"text-align: right;\">  Height</th><th style=\"text-align: right;\">  Whole weight</th><th style=\"text-align: right;\">  Shucked weight</th><th style=\"text-align: right;\">  Viscera weight</th><th style=\"text-align: right;\">  Shell weight</th><th style=\"text-align: right;\">  Rings</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>M    </td><td style=\"text-align: right;\">   0.455</td><td style=\"text-align: right;\">     0.365</td><td style=\"text-align: right;\">   0.095</td><td style=\"text-align: right;\">        0.514 </td><td style=\"text-align: right;\">          0.2245</td><td style=\"text-align: right;\">          0.101 </td><td style=\"text-align: right;\">         0.15 </td><td style=\"text-align: right;\">     15</td></tr>\n",
       "<tr><td>M    </td><td style=\"text-align: right;\">   0.35 </td><td style=\"text-align: right;\">     0.265</td><td style=\"text-align: right;\">   0.09 </td><td style=\"text-align: right;\">        0.2255</td><td style=\"text-align: right;\">          0.0995</td><td style=\"text-align: right;\">          0.0485</td><td style=\"text-align: right;\">         0.07 </td><td style=\"text-align: right;\">      7</td></tr>\n",
       "<tr><td>F    </td><td style=\"text-align: right;\">   0.53 </td><td style=\"text-align: right;\">     0.42 </td><td style=\"text-align: right;\">   0.135</td><td style=\"text-align: right;\">        0.677 </td><td style=\"text-align: right;\">          0.2565</td><td style=\"text-align: right;\">          0.1415</td><td style=\"text-align: right;\">         0.21 </td><td style=\"text-align: right;\">      9</td></tr>\n",
       "<tr><td>M    </td><td style=\"text-align: right;\">   0.44 </td><td style=\"text-align: right;\">     0.365</td><td style=\"text-align: right;\">   0.125</td><td style=\"text-align: right;\">        0.516 </td><td style=\"text-align: right;\">          0.2155</td><td style=\"text-align: right;\">          0.114 </td><td style=\"text-align: right;\">         0.155</td><td style=\"text-align: right;\">     10</td></tr>\n",
       "<tr><td>I    </td><td style=\"text-align: right;\">   0.33 </td><td style=\"text-align: right;\">     0.255</td><td style=\"text-align: right;\">   0.08 </td><td style=\"text-align: right;\">        0.205 </td><td style=\"text-align: right;\">          0.0895</td><td style=\"text-align: right;\">          0.0395</td><td style=\"text-align: right;\">         0.055</td><td style=\"text-align: right;\">      7</td></tr>\n",
       "<tr><td>I    </td><td style=\"text-align: right;\">   0.425</td><td style=\"text-align: right;\">     0.3  </td><td style=\"text-align: right;\">   0.095</td><td style=\"text-align: right;\">        0.3515</td><td style=\"text-align: right;\">          0.141 </td><td style=\"text-align: right;\">          0.0775</td><td style=\"text-align: right;\">         0.12 </td><td style=\"text-align: right;\">      8</td></tr>\n",
       "<tr><td>F    </td><td style=\"text-align: right;\">   0.53 </td><td style=\"text-align: right;\">     0.415</td><td style=\"text-align: right;\">   0.15 </td><td style=\"text-align: right;\">        0.7775</td><td style=\"text-align: right;\">          0.237 </td><td style=\"text-align: right;\">          0.1415</td><td style=\"text-align: right;\">         0.33 </td><td style=\"text-align: right;\">     20</td></tr>\n",
       "<tr><td>F    </td><td style=\"text-align: right;\">   0.545</td><td style=\"text-align: right;\">     0.425</td><td style=\"text-align: right;\">   0.125</td><td style=\"text-align: right;\">        0.768 </td><td style=\"text-align: right;\">          0.294 </td><td style=\"text-align: right;\">          0.1495</td><td style=\"text-align: right;\">         0.26 </td><td style=\"text-align: right;\">     16</td></tr>\n",
       "<tr><td>M    </td><td style=\"text-align: right;\">   0.475</td><td style=\"text-align: right;\">     0.37 </td><td style=\"text-align: right;\">   0.125</td><td style=\"text-align: right;\">        0.5095</td><td style=\"text-align: right;\">          0.2165</td><td style=\"text-align: right;\">          0.1125</td><td style=\"text-align: right;\">         0.165</td><td style=\"text-align: right;\">      9</td></tr>\n",
       "<tr><td>F    </td><td style=\"text-align: right;\">   0.55 </td><td style=\"text-align: right;\">     0.44 </td><td style=\"text-align: right;\">   0.15 </td><td style=\"text-align: right;\">        0.8945</td><td style=\"text-align: right;\">          0.3145</td><td style=\"text-align: right;\">          0.151 </td><td style=\"text-align: right;\">         0.32 </td><td style=\"text-align: right;\">     19</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:4177\n",
      "Cols:9\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>Sex  </th><th>Length             </th><th>Diameter           </th><th>Height             </th><th>Whole weight      </th><th>Shucked weight     </th><th>Viscera weight     </th><th>Shell weight       </th><th>Rings             </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>enum </td><td>real               </td><td>real               </td><td>real               </td><td>real              </td><td>real               </td><td>real               </td><td>real               </td><td>int               </td></tr>\n",
       "<tr><td>mins   </td><td>     </td><td>0.075              </td><td>0.055              </td><td>0.0                </td><td>0.002             </td><td>0.001              </td><td>0.0005             </td><td>0.0015             </td><td>1.0               </td></tr>\n",
       "<tr><td>mean   </td><td>     </td><td>0.5239920995930094 </td><td>0.40788125448886764</td><td>0.13951639932966242</td><td>0.8287421594445776</td><td>0.35936748862820206</td><td>0.18059360785252573</td><td>0.23883085946851806</td><td>9.933684462532918 </td></tr>\n",
       "<tr><td>maxs   </td><td>     </td><td>0.815              </td><td>0.65               </td><td>1.13               </td><td>2.8255            </td><td>1.488              </td><td>0.76               </td><td>1.005              </td><td>29.0              </td></tr>\n",
       "<tr><td>sigma  </td><td>     </td><td>0.12009291256479956</td><td>0.09923986613365944</td><td>0.04182705660725727</td><td>0.4903890182309976</td><td>0.2219629490332201 </td><td>0.10961425025968448</td><td>0.1392026695223861 </td><td>3.2241690320681275</td></tr>\n",
       "<tr><td>zeros  </td><td>     </td><td>0                  </td><td>0                  </td><td>2                  </td><td>0                 </td><td>0                  </td><td>0                  </td><td>0                  </td><td>0                 </td></tr>\n",
       "<tr><td>missing</td><td>0    </td><td>0                  </td><td>0                  </td><td>0                  </td><td>0                 </td><td>0                  </td><td>0                  </td><td>0                  </td><td>0                 </td></tr>\n",
       "<tr><td>0      </td><td>M    </td><td>0.455              </td><td>0.365              </td><td>0.095              </td><td>0.514             </td><td>0.2245             </td><td>0.101              </td><td>0.15               </td><td>15.0              </td></tr>\n",
       "<tr><td>1      </td><td>M    </td><td>0.35               </td><td>0.265              </td><td>0.09               </td><td>0.2255            </td><td>0.0995             </td><td>0.0485             </td><td>0.07               </td><td>7.0               </td></tr>\n",
       "<tr><td>2      </td><td>F    </td><td>0.53               </td><td>0.42               </td><td>0.135              </td><td>0.677             </td><td>0.2565             </td><td>0.1415             </td><td>0.21               </td><td>9.0               </td></tr>\n",
       "<tr><td>3      </td><td>M    </td><td>0.44               </td><td>0.365              </td><td>0.125              </td><td>0.516             </td><td>0.2155             </td><td>0.114              </td><td>0.155              </td><td>10.0              </td></tr>\n",
       "<tr><td>4      </td><td>I    </td><td>0.33               </td><td>0.255              </td><td>0.08               </td><td>0.205             </td><td>0.0895             </td><td>0.0395             </td><td>0.055              </td><td>7.0               </td></tr>\n",
       "<tr><td>5      </td><td>I    </td><td>0.425              </td><td>0.3                </td><td>0.095              </td><td>0.3515            </td><td>0.141              </td><td>0.0775             </td><td>0.12               </td><td>8.0               </td></tr>\n",
       "<tr><td>6      </td><td>F    </td><td>0.53               </td><td>0.415              </td><td>0.15               </td><td>0.7775            </td><td>0.237              </td><td>0.1415             </td><td>0.33               </td><td>20.0              </td></tr>\n",
       "<tr><td>7      </td><td>F    </td><td>0.545              </td><td>0.425              </td><td>0.125              </td><td>0.768             </td><td>0.294              </td><td>0.1495             </td><td>0.26               </td><td>16.0              </td></tr>\n",
       "<tr><td>8      </td><td>M    </td><td>0.475              </td><td>0.37               </td><td>0.125              </td><td>0.5095            </td><td>0.2165             </td><td>0.1125             </td><td>0.165              </td><td>9.0               </td></tr>\n",
       "<tr><td>9      </td><td>F    </td><td>0.55               </td><td>0.44               </td><td>0.15               </td><td>0.8945            </td><td>0.3145             </td><td>0.151              </td><td>0.32               </td><td>19.0              </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = None\n",
    "# dependent variable\n",
    "if target == None:\n",
    "    target=df.columns[-1]\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rings\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.columns\n",
    "X.remove(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sex', 'Length', 'Diameter', 'Height', 'Whole weight', 'Shucked weight', 'Viscera weight', 'Shell weight']\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = df.split_frame([0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "glm_model = H2OGeneralizedLinearEstimator(family= \"gaussian\", nfolds = 5, lambda_ = 0, compute_p_values = True)\n",
    "glm_model.train(x=X, y=y, training_frame= train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGeneralizedLinearEstimator :  Generalized Linear Modeling\n",
      "Model Key:  GLM_model_python_1539652131523_1\n",
      "\n",
      "\n",
      "ModelMetricsRegressionGLM: glm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 4.727609412839928\n",
      "RMSE: 2.1743066510591205\n",
      "MAE: 1.5676362306509557\n",
      "RMSLE: NaN\n",
      "R^2: 0.5382748892718207\n",
      "Mean Residual Deviance: 4.727609412839928\n",
      "Null degrees of freedom: 3768\n",
      "Residual degrees of freedom: 3759\n",
      "Null deviance: 38590.84001061291\n",
      "Residual deviance: 17818.359876993687\n",
      "AIC: 16572.797381412263\n",
      "\n",
      "ModelMetricsRegressionGLM: glm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 4.8839296088993205\n",
      "RMSE: 2.209961449640993\n",
      "MAE: 1.5789585647858577\n",
      "RMSLE: NaN\n",
      "R^2: 0.5230077735835945\n",
      "Mean Residual Deviance: 4.8839296088993205\n",
      "Null degrees of freedom: 3768\n",
      "Residual degrees of freedom: 3759\n",
      "Null deviance: 38594.588444507935\n",
      "Residual deviance: 18407.53069594154\n",
      "AIC: 16695.404754345516\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>mae</td>\n",
       "<td>1.578133</td>\n",
       "<td>0.0303044</td>\n",
       "<td>1.6600491</td>\n",
       "<td>1.5334682</td>\n",
       "<td>1.5661643</td>\n",
       "<td>1.5627037</td>\n",
       "<td>1.5682793</td></tr>\n",
       "<tr><td>mean_residual_deviance</td>\n",
       "<td>4.872696</td>\n",
       "<td>0.3330815</td>\n",
       "<td>5.765526</td>\n",
       "<td>4.896015</td>\n",
       "<td>4.4248857</td>\n",
       "<td>4.6662703</td>\n",
       "<td>4.610783</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>4.872696</td>\n",
       "<td>0.3330815</td>\n",
       "<td>5.765526</td>\n",
       "<td>4.896015</td>\n",
       "<td>4.4248857</td>\n",
       "<td>4.6662703</td>\n",
       "<td>4.610783</td></tr>\n",
       "<tr><td>null_deviance</td>\n",
       "<td>7718.9175</td>\n",
       "<td>441.03506</td>\n",
       "<td>8575.956</td>\n",
       "<td>8148.385</td>\n",
       "<td>7836.6846</td>\n",
       "<td>6902.0986</td>\n",
       "<td>7131.465</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.5236005</td>\n",
       "<td>0.0239304</td>\n",
       "<td>0.4687661</td>\n",
       "<td>0.5400013</td>\n",
       "<td>0.5719854</td>\n",
       "<td>0.5131378</td>\n",
       "<td>0.5241121</td></tr>\n",
       "<tr><td>residual_deviance</td>\n",
       "<td>3681.506</td>\n",
       "<td>325.63263</td>\n",
       "<td>4554.765</td>\n",
       "<td>3745.4514</td>\n",
       "<td>3354.0632</td>\n",
       "<td>3359.7144</td>\n",
       "<td>3393.5361</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>2.204963</td>\n",
       "<td>0.0736014</td>\n",
       "<td>2.401151</td>\n",
       "<td>2.2126942</td>\n",
       "<td>2.1035411</td>\n",
       "<td>2.160155</td>\n",
       "<td>2.1472733</td></tr>\n",
       "<tr><td>rmsle</td>\n",
       "<td>0.1788261</td>\n",
       "<td>0.0020560</td>\n",
       "<td>NaN</td>\n",
       "<td>0.1787922</td>\n",
       "<td>0.1759356</td>\n",
       "<td>NaN</td>\n",
       "<td>0.1817506</td></tr></table></div>"
      ],
      "text/plain": [
       "                        mean      sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "----------------------  --------  ----------  ------------  ------------  ------------  ------------  ------------\n",
       "mae                     1.57813   0.0303044   1.66005       1.53347       1.56616       1.5627        1.56828\n",
       "mean_residual_deviance  4.8727    0.333082    5.76553       4.89602       4.42489       4.66627       4.61078\n",
       "mse                     4.8727    0.333082    5.76553       4.89602       4.42489       4.66627       4.61078\n",
       "null_deviance           7718.92   441.035     8575.96       8148.39       7836.68       6902.1        7131.47\n",
       "r2                      0.523601  0.0239304   0.468766      0.540001      0.571985      0.513138      0.524112\n",
       "residual_deviance       3681.51   325.633     4554.77       3745.45       3354.06       3359.71       3393.54\n",
       "rmse                    2.20496   0.0736014   2.40115       2.21269       2.10354       2.16016       2.14727\n",
       "rmsle                   0.178826  0.00205599  nan           0.178792      0.175936      nan           0.181751"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>negative_log_likelihood</b></td>\n",
       "<td><b>objective</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:10:05</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>0</td>\n",
       "<td>38590.8400106</td>\n",
       "<td>10.2390130</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    iterations    negative_log_likelihood    objective\n",
       "--  -------------------  ----------  ------------  -------------------------  -----------\n",
       "    2018-10-15 21:10:05  0.000 sec   0             38590.8                    10.239"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2ORegressionModel.plot of >"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_model.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">   StdErr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\"> 10.4739 </td><td style=\"text-align: right;\">0.0880559</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  6.48864</td><td style=\"text-align: right;\">0.078627 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  8.41301</td><td style=\"text-align: right;\">0.0844624</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 10.1266 </td><td style=\"text-align: right;\">0.0938841</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 12.7386 </td><td style=\"text-align: right;\">0.107574 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 13.323  </td><td style=\"text-align: right;\">0.0944259</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 12.0331 </td><td style=\"text-align: right;\">0.0902499</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 11.3363 </td><td style=\"text-align: right;\">0.0696541</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 11.7532 </td><td style=\"text-align: right;\">0.066692 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 10.828  </td><td style=\"text-align: right;\">0.0815718</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = glm_model.predict(test)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsRegressionGLM: glm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 5.51529836028047\n",
      "RMSE: 2.3484672363651296\n",
      "MAE: 1.6935956499765874\n",
      "RMSLE: 0.18833150757282965\n",
      "R^2: 0.5327228711931041\n",
      "Mean Residual Deviance: 5.51529836028047\n",
      "Null degrees of freedom: 407\n",
      "Residual degrees of freedom: 398\n",
      "Null deviance: 4820.239128593776\n",
      "Residual deviance: 2250.2417309944317\n",
      "AIC: 1876.5243495115792\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref = glm_model.model_performance(test)\n",
    "pref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For GLM_model the mse is 4.727609412839928 on train data and 5.51529836028047 on test data, the mse had incresed a little bit. So it's did a better job on the training data than the test data, probably is overfitting a litte bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 GBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_model = H2OGradientBoostingEstimator(distribution= \"gaussian\",nfolds=5)\n",
    "gbm_model.train(x=X, y=y, training_frame= train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_model_python_1539652131523_3\n",
      "\n",
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 3.317293085701543\n",
      "RMSE: 1.8213437582459668\n",
      "MAE: 1.3052167180806011\n",
      "RMSLE: 0.14924445040700277\n",
      "Mean Residual Deviance: 3.317293085701543\n",
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 4.6284232326211825\n",
      "RMSE: 2.1513770549629796\n",
      "MAE: 1.5108482776204106\n",
      "RMSLE: 0.17373691684808915\n",
      "Mean Residual Deviance: 4.6284232326211825\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>mae</td>\n",
       "<td>1.5097485</td>\n",
       "<td>0.0679860</td>\n",
       "<td>1.673924</td>\n",
       "<td>1.4904824</td>\n",
       "<td>1.5452557</td>\n",
       "<td>1.393461</td>\n",
       "<td>1.4456192</td></tr>\n",
       "<tr><td>mean_residual_deviance</td>\n",
       "<td>4.618915</td>\n",
       "<td>0.369506</td>\n",
       "<td>5.429313</td>\n",
       "<td>4.317406</td>\n",
       "<td>4.8715534</td>\n",
       "<td>3.8748977</td>\n",
       "<td>4.601405</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>4.618915</td>\n",
       "<td>0.369506</td>\n",
       "<td>5.429313</td>\n",
       "<td>4.317406</td>\n",
       "<td>4.8715534</td>\n",
       "<td>3.8748977</td>\n",
       "<td>4.601405</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.5480938</td>\n",
       "<td>0.0107978</td>\n",
       "<td>0.5354102</td>\n",
       "<td>0.5558609</td>\n",
       "<td>0.5248618</td>\n",
       "<td>0.5600668</td>\n",
       "<td>0.5642692</td></tr>\n",
       "<tr><td>residual_deviance</td>\n",
       "<td>4.618915</td>\n",
       "<td>0.369506</td>\n",
       "<td>5.429313</td>\n",
       "<td>4.317406</td>\n",
       "<td>4.8715534</td>\n",
       "<td>3.8748977</td>\n",
       "<td>4.601405</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>2.14573</td>\n",
       "<td>0.0859014</td>\n",
       "<td>2.3300886</td>\n",
       "<td>2.077837</td>\n",
       "<td>2.2071595</td>\n",
       "<td>1.968476</td>\n",
       "<td>2.1450887</td></tr>\n",
       "<tr><td>rmsle</td>\n",
       "<td>0.1734292</td>\n",
       "<td>0.0058107</td>\n",
       "<td>0.1862806</td>\n",
       "<td>0.1671833</td>\n",
       "<td>0.1793366</td>\n",
       "<td>0.1639879</td>\n",
       "<td>0.1703575</td></tr></table></div>"
      ],
      "text/plain": [
       "                        mean      sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "----------------------  --------  ---------  ------------  ------------  ------------  ------------  ------------\n",
       "mae                     1.50975   0.067986   1.67392       1.49048       1.54526       1.39346       1.44562\n",
       "mean_residual_deviance  4.61892   0.369506   5.42931       4.31741       4.87155       3.8749        4.6014\n",
       "mse                     4.61892   0.369506   5.42931       4.31741       4.87155       3.8749        4.6014\n",
       "r2                      0.548094  0.0107978  0.53541       0.555861      0.524862      0.560067      0.564269\n",
       "residual_deviance       4.61892   0.369506   5.42931       4.31741       4.87155       3.8749        4.6014\n",
       "rmse                    2.14573   0.0859014  2.33009       2.07784       2.20716       1.96848       2.14509\n",
       "rmsle                   0.173429  0.0058107  0.186281      0.167183      0.179337      0.163988      0.170357"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_mae</b></td>\n",
       "<td><b>training_deviance</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:10:42</td>\n",
       "<td> 2.444 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>3.1998458</td>\n",
       "<td>2.3539816</td>\n",
       "<td>10.2390130</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:10:42</td>\n",
       "<td> 2.466 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>3.0326376</td>\n",
       "<td>2.2251425</td>\n",
       "<td>9.1968906</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:10:42</td>\n",
       "<td> 2.483 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>2.8882489</td>\n",
       "<td>2.1165810</td>\n",
       "<td>8.3419815</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:10:42</td>\n",
       "<td> 2.491 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>2.7645542</td>\n",
       "<td>2.0222774</td>\n",
       "<td>7.6427597</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:10:42</td>\n",
       "<td> 2.496 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>2.6530099</td>\n",
       "<td>1.9381647</td>\n",
       "<td>7.0384617</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:10:42</td>\n",
       "<td> 2.870 sec</td>\n",
       "<td>46.0</td>\n",
       "<td>1.8325827</td>\n",
       "<td>1.3128536</td>\n",
       "<td>3.3583595</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:10:42</td>\n",
       "<td> 2.875 sec</td>\n",
       "<td>47.0</td>\n",
       "<td>1.8294650</td>\n",
       "<td>1.3109959</td>\n",
       "<td>3.3469424</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:10:42</td>\n",
       "<td> 2.880 sec</td>\n",
       "<td>48.0</td>\n",
       "<td>1.8281330</td>\n",
       "<td>1.3100402</td>\n",
       "<td>3.3420702</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:10:42</td>\n",
       "<td> 2.886 sec</td>\n",
       "<td>49.0</td>\n",
       "<td>1.8234853</td>\n",
       "<td>1.3067006</td>\n",
       "<td>3.3250986</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:10:42</td>\n",
       "<td> 2.891 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>1.8213438</td>\n",
       "<td>1.3052167</td>\n",
       "<td>3.3172931</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    number_of_trees    training_rmse       training_mae        training_deviance\n",
       "---  -------------------  ----------  -----------------  ------------------  ------------------  -------------------\n",
       "     2018-10-15 21:10:42  2.444 sec   0.0                3.1998457780980334  2.353981570760502   10.23901300361181\n",
       "     2018-10-15 21:10:42  2.466 sec   1.0                3.032637559041957   2.2251424855216806  9.196890564511959\n",
       "     2018-10-15 21:10:42  2.483 sec   2.0                2.888248867275909   2.116580987678785   8.341981519320571\n",
       "     2018-10-15 21:10:42  2.491 sec   3.0                2.7645541638947115  2.0222773889737473  7.642759725107588\n",
       "     2018-10-15 21:10:42  2.496 sec   4.0                2.6530099367231403  1.9381647369342256  7.038461724351721\n",
       "---  ---                  ---         ---                ---                 ---                 ---\n",
       "     2018-10-15 21:10:42  2.870 sec   46.0               1.8325827465672109  1.3128536077733697  3.3583595230158223\n",
       "     2018-10-15 21:10:42  2.875 sec   47.0               1.8294650472367708  1.3109958977748621  3.3469423590610403\n",
       "     2018-10-15 21:10:42  2.880 sec   48.0               1.828132972368606   1.3100402099632653  3.342070164661274\n",
       "     2018-10-15 21:10:42  2.886 sec   49.0               1.8234852942493835  1.3067006191229371  3.3250986183437607\n",
       "     2018-10-15 21:10:42  2.891 sec   50.0               1.8213437582459668  1.3052167180806011  3.317293085701543"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>Shell weight</td>\n",
       "<td>92881.8203125</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6762984</td></tr>\n",
       "<tr><td>Shucked weight</td>\n",
       "<td>19635.3261719</td>\n",
       "<td>0.2114012</td>\n",
       "<td>0.1429703</td></tr>\n",
       "<tr><td>Whole weight</td>\n",
       "<td>5397.2573242</td>\n",
       "<td>0.0581089</td>\n",
       "<td>0.0392989</td></tr>\n",
       "<tr><td>Diameter</td>\n",
       "<td>5102.2797852</td>\n",
       "<td>0.0549330</td>\n",
       "<td>0.0371511</td></tr>\n",
       "<tr><td>Height</td>\n",
       "<td>4506.3139648</td>\n",
       "<td>0.0485166</td>\n",
       "<td>0.0328117</td></tr>\n",
       "<tr><td>Sex</td>\n",
       "<td>4062.6452637</td>\n",
       "<td>0.0437399</td>\n",
       "<td>0.0295812</td></tr>\n",
       "<tr><td>Viscera weight</td>\n",
       "<td>2964.0942383</td>\n",
       "<td>0.0319125</td>\n",
       "<td>0.0215824</td></tr>\n",
       "<tr><td>Length</td>\n",
       "<td>2788.7900391</td>\n",
       "<td>0.0300251</td>\n",
       "<td>0.0203060</td></tr></table></div>"
      ],
      "text/plain": [
       "variable        relative_importance    scaled_importance    percentage\n",
       "--------------  ---------------------  -------------------  ------------\n",
       "Shell weight    92881.8                1                    0.676298\n",
       "Shucked weight  19635.3                0.211401             0.14297\n",
       "Whole weight    5397.26                0.0581089            0.0392989\n",
       "Diameter        5102.28                0.054933             0.0371511\n",
       "Height          4506.31                0.0485166            0.0328117\n",
       "Sex             4062.65                0.0437399            0.0295812\n",
       "Viscera weight  2964.09                0.0319125            0.0215824\n",
       "Length          2788.79                0.0300251            0.020306"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2ORegressionModel.plot of >"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\"> 10.2585 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  6.24573</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  8.47332</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 10.4736 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 11.7115 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 14.1459 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 11.5907 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 10.3413 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 11.0404 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 11.3308 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = gbm_model.predict(test)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 5.45296092431811\n",
      "RMSE: 2.3351575801898488\n",
      "MAE: 1.5932470772560687\n",
      "RMSLE: 0.1824363496380277\n",
      "Mean Residual Deviance: 5.45296092431811\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref = gbm_model.model_performance(test)\n",
    "pref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the gbm_model, the mse is 3.317293085701543 on the training data and 5.45296092431811 on the testing data. The model is overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "drf_model = H2OGradientBoostingEstimator(stopping_metric= \"deviance\",nfolds=5)\n",
    "drf_model.train(x=X, y=y, training_frame= train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_model_python_1539652131523_4\n",
      "\n",
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 3.317293085701543\n",
      "RMSE: 1.8213437582459668\n",
      "MAE: 1.3052167180806011\n",
      "RMSLE: 0.14924445040700277\n",
      "Mean Residual Deviance: 3.317293085701543\n",
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 4.581729646057437\n",
      "RMSE: 2.1404975230206262\n",
      "MAE: 1.5099966696330345\n",
      "RMSLE: 0.17335220846480087\n",
      "Mean Residual Deviance: 4.581729646057437\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>mae</td>\n",
       "<td>1.5104741</td>\n",
       "<td>0.0258619</td>\n",
       "<td>1.4802573</td>\n",
       "<td>1.5667444</td>\n",
       "<td>1.4629819</td>\n",
       "<td>1.5133291</td>\n",
       "<td>1.5290576</td></tr>\n",
       "<tr><td>mean_residual_deviance</td>\n",
       "<td>4.586427</td>\n",
       "<td>0.1153695</td>\n",
       "<td>4.538807</td>\n",
       "<td>4.659639</td>\n",
       "<td>4.292799</td>\n",
       "<td>4.6796174</td>\n",
       "<td>4.761274</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>4.586427</td>\n",
       "<td>0.1153695</td>\n",
       "<td>4.538807</td>\n",
       "<td>4.659639</td>\n",
       "<td>4.292799</td>\n",
       "<td>4.6796174</td>\n",
       "<td>4.761274</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.5509023</td>\n",
       "<td>0.0138040</td>\n",
       "<td>0.5556037</td>\n",
       "<td>0.5501315</td>\n",
       "<td>0.5699986</td>\n",
       "<td>0.5143586</td>\n",
       "<td>0.5644191</td></tr>\n",
       "<tr><td>residual_deviance</td>\n",
       "<td>4.586427</td>\n",
       "<td>0.1153695</td>\n",
       "<td>4.538807</td>\n",
       "<td>4.659639</td>\n",
       "<td>4.292799</td>\n",
       "<td>4.6796174</td>\n",
       "<td>4.761274</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>2.1412501</td>\n",
       "<td>0.0271549</td>\n",
       "<td>2.1304476</td>\n",
       "<td>2.1586196</td>\n",
       "<td>2.071907</td>\n",
       "<td>2.1632423</td>\n",
       "<td>2.1820345</td></tr>\n",
       "<tr><td>rmsle</td>\n",
       "<td>0.1733552</td>\n",
       "<td>0.0022631</td>\n",
       "<td>0.1693864</td>\n",
       "<td>0.1778753</td>\n",
       "<td>0.1734164</td>\n",
       "<td>0.1757732</td>\n",
       "<td>0.1703249</td></tr></table></div>"
      ],
      "text/plain": [
       "                        mean      sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "----------------------  --------  ---------  ------------  ------------  ------------  ------------  ------------\n",
       "mae                     1.51047   0.0258619  1.48026       1.56674       1.46298       1.51333       1.52906\n",
       "mean_residual_deviance  4.58643   0.115369   4.53881       4.65964       4.2928        4.67962       4.76127\n",
       "mse                     4.58643   0.115369   4.53881       4.65964       4.2928        4.67962       4.76127\n",
       "r2                      0.550902  0.013804   0.555604      0.550131      0.569999      0.514359      0.564419\n",
       "residual_deviance       4.58643   0.115369   4.53881       4.65964       4.2928        4.67962       4.76127\n",
       "rmse                    2.14125   0.0271549  2.13045       2.15862       2.07191       2.16324       2.18203\n",
       "rmsle                   0.173355  0.0022631  0.169386      0.177875      0.173416      0.175773      0.170325"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_mae</b></td>\n",
       "<td><b>training_deviance</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:10:59</td>\n",
       "<td> 1.153 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>3.1998458</td>\n",
       "<td>2.3539816</td>\n",
       "<td>10.2390130</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:10:59</td>\n",
       "<td> 1.165 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>3.0326376</td>\n",
       "<td>2.2251425</td>\n",
       "<td>9.1968906</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:10:59</td>\n",
       "<td> 1.169 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>2.8882489</td>\n",
       "<td>2.1165810</td>\n",
       "<td>8.3419815</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:10:59</td>\n",
       "<td> 1.175 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>2.7645542</td>\n",
       "<td>2.0222774</td>\n",
       "<td>7.6427597</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:10:59</td>\n",
       "<td> 1.180 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>2.6530099</td>\n",
       "<td>1.9381647</td>\n",
       "<td>7.0384617</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:10:59</td>\n",
       "<td> 1.380 sec</td>\n",
       "<td>46.0</td>\n",
       "<td>1.8325827</td>\n",
       "<td>1.3128536</td>\n",
       "<td>3.3583595</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:10:59</td>\n",
       "<td> 1.385 sec</td>\n",
       "<td>47.0</td>\n",
       "<td>1.8294650</td>\n",
       "<td>1.3109959</td>\n",
       "<td>3.3469424</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:10:59</td>\n",
       "<td> 1.390 sec</td>\n",
       "<td>48.0</td>\n",
       "<td>1.8281330</td>\n",
       "<td>1.3100402</td>\n",
       "<td>3.3420702</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:10:59</td>\n",
       "<td> 1.394 sec</td>\n",
       "<td>49.0</td>\n",
       "<td>1.8234853</td>\n",
       "<td>1.3067006</td>\n",
       "<td>3.3250986</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:10:59</td>\n",
       "<td> 1.398 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>1.8213438</td>\n",
       "<td>1.3052167</td>\n",
       "<td>3.3172931</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    number_of_trees    training_rmse       training_mae        training_deviance\n",
       "---  -------------------  ----------  -----------------  ------------------  ------------------  -------------------\n",
       "     2018-10-15 21:10:59  1.153 sec   0.0                3.1998457780980334  2.353981570760502   10.23901300361181\n",
       "     2018-10-15 21:10:59  1.165 sec   1.0                3.032637559041957   2.2251424855216806  9.196890564511959\n",
       "     2018-10-15 21:10:59  1.169 sec   2.0                2.888248867275909   2.116580987678785   8.341981519320571\n",
       "     2018-10-15 21:10:59  1.175 sec   3.0                2.7645541638947115  2.0222773889737473  7.642759725107588\n",
       "     2018-10-15 21:10:59  1.180 sec   4.0                2.6530099367231403  1.9381647369342256  7.038461724351721\n",
       "---  ---                  ---         ---                ---                 ---                 ---\n",
       "     2018-10-15 21:10:59  1.380 sec   46.0               1.8325827465672109  1.3128536077733697  3.3583595230158223\n",
       "     2018-10-15 21:10:59  1.385 sec   47.0               1.8294650472367708  1.3109958977748621  3.3469423590610403\n",
       "     2018-10-15 21:10:59  1.390 sec   48.0               1.828132972368606   1.3100402099632653  3.342070164661274\n",
       "     2018-10-15 21:10:59  1.394 sec   49.0               1.8234852942493835  1.3067006191229371  3.3250986183437607\n",
       "     2018-10-15 21:10:59  1.398 sec   50.0               1.8213437582459668  1.3052167180806011  3.317293085701543"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>Shell weight</td>\n",
       "<td>92881.8203125</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6762984</td></tr>\n",
       "<tr><td>Shucked weight</td>\n",
       "<td>19635.3261719</td>\n",
       "<td>0.2114012</td>\n",
       "<td>0.1429703</td></tr>\n",
       "<tr><td>Whole weight</td>\n",
       "<td>5397.2573242</td>\n",
       "<td>0.0581089</td>\n",
       "<td>0.0392989</td></tr>\n",
       "<tr><td>Diameter</td>\n",
       "<td>5102.2797852</td>\n",
       "<td>0.0549330</td>\n",
       "<td>0.0371511</td></tr>\n",
       "<tr><td>Height</td>\n",
       "<td>4506.3139648</td>\n",
       "<td>0.0485166</td>\n",
       "<td>0.0328117</td></tr>\n",
       "<tr><td>Sex</td>\n",
       "<td>4062.6452637</td>\n",
       "<td>0.0437399</td>\n",
       "<td>0.0295812</td></tr>\n",
       "<tr><td>Viscera weight</td>\n",
       "<td>2964.0942383</td>\n",
       "<td>0.0319125</td>\n",
       "<td>0.0215824</td></tr>\n",
       "<tr><td>Length</td>\n",
       "<td>2788.7900391</td>\n",
       "<td>0.0300251</td>\n",
       "<td>0.0203060</td></tr></table></div>"
      ],
      "text/plain": [
       "variable        relative_importance    scaled_importance    percentage\n",
       "--------------  ---------------------  -------------------  ------------\n",
       "Shell weight    92881.8                1                    0.676298\n",
       "Shucked weight  19635.3                0.211401             0.14297\n",
       "Whole weight    5397.26                0.0581089            0.0392989\n",
       "Diameter        5102.28                0.054933             0.0371511\n",
       "Height          4506.31                0.0485166            0.0328117\n",
       "Sex             4062.65                0.0437399            0.0295812\n",
       "Viscera weight  2964.09                0.0319125            0.0215824\n",
       "Length          2788.79                0.0300251            0.020306"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2ORegressionModel.plot of >"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drf_model.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\"> 10.2585 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  6.24573</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  8.47332</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 10.4736 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 11.7115 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 14.1459 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 11.5907 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 10.3413 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 11.0404 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 11.3308 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = drf_model.predict(test)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 5.45296092431811\n",
      "RMSE: 2.3351575801898488\n",
      "MAE: 1.5932470772560687\n",
      "RMSLE: 0.1824363496380277\n",
      "Mean Residual Deviance: 5.45296092431811\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref = drf_model.model_performance(test)\n",
    "pref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the drf model, the mse is 3.317293085701543 on the training data and 5.45296092431811 on the testing data. The model is overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "dp_model = H2ODeepLearningEstimator(\n",
    "    model_id=\"MutlDL\",\n",
    "    hidden=[50,50],           \n",
    "    epochs=50,                 \n",
    "    ignore_const_cols=False, \n",
    "    sparse=True,              \n",
    "    variable_importances=True,\n",
    "    nfolds=5\n",
    ")\n",
    "dp_model.train(x=X,y = y, training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ODeepLearningEstimator :  Deep Learning\n",
      "Model Key:  MutlDL\n",
      "\n",
      "\n",
      "ModelMetricsRegression: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 5.865668546201815\n",
      "RMSE: 2.4219142318013276\n",
      "MAE: 1.9040087211367542\n",
      "RMSLE: 0.20050844107466503\n",
      "Mean Residual Deviance: 5.865668546201815\n",
      "\n",
      "ModelMetricsRegression: deeplearning\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 5.658338409571538\n",
      "RMSE: 2.3787262157658113\n",
      "MAE: 1.847566312080502\n",
      "RMSLE: 0.19832713150960207\n",
      "Mean Residual Deviance: 5.658338409571538\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>mae</td>\n",
       "<td>1.8469305</td>\n",
       "<td>0.0919904</td>\n",
       "<td>1.7205406</td>\n",
       "<td>2.069493</td>\n",
       "<td>1.8970344</td>\n",
       "<td>1.828129</td>\n",
       "<td>1.7194554</td></tr>\n",
       "<tr><td>mean_residual_deviance</td>\n",
       "<td>5.650562</td>\n",
       "<td>0.4469230</td>\n",
       "<td>5.4046245</td>\n",
       "<td>6.7212224</td>\n",
       "<td>5.9626756</td>\n",
       "<td>5.23542</td>\n",
       "<td>4.9288664</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>5.650562</td>\n",
       "<td>0.4469230</td>\n",
       "<td>5.4046245</td>\n",
       "<td>6.7212224</td>\n",
       "<td>5.9626756</td>\n",
       "<td>5.23542</td>\n",
       "<td>4.9288664</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.4485440</td>\n",
       "<td>0.0200134</td>\n",
       "<td>0.4753934</td>\n",
       "<td>0.4130962</td>\n",
       "<td>0.4286152</td>\n",
       "<td>0.4380702</td>\n",
       "<td>0.4875452</td></tr>\n",
       "<tr><td>residual_deviance</td>\n",
       "<td>5.650562</td>\n",
       "<td>0.4469230</td>\n",
       "<td>5.4046245</td>\n",
       "<td>6.7212224</td>\n",
       "<td>5.9626756</td>\n",
       "<td>5.23542</td>\n",
       "<td>4.9288664</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>2.373477</td>\n",
       "<td>0.0926518</td>\n",
       "<td>2.3247848</td>\n",
       "<td>2.5925322</td>\n",
       "<td>2.441859</td>\n",
       "<td>2.288104</td>\n",
       "<td>2.2201052</td></tr>\n",
       "<tr><td>rmsle</td>\n",
       "<td>0.1979703</td>\n",
       "<td>0.0075302</td>\n",
       "<td>0.1883843</td>\n",
       "<td>0.2156129</td>\n",
       "<td>0.2039089</td>\n",
       "<td>0.1948892</td>\n",
       "<td>0.1870561</td></tr></table></div>"
      ],
      "text/plain": [
       "                        mean      sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "----------------------  --------  ----------  ------------  ------------  ------------  ------------  ------------\n",
       "mae                     1.84693   0.0919904   1.72054       2.06949       1.89703       1.82813       1.71946\n",
       "mean_residual_deviance  5.65056   0.446923    5.40462       6.72122       5.96268       5.23542       4.92887\n",
       "mse                     5.65056   0.446923    5.40462       6.72122       5.96268       5.23542       4.92887\n",
       "r2                      0.448544  0.0200134   0.475393      0.413096      0.428615      0.43807       0.487545\n",
       "residual_deviance       5.65056   0.446923    5.40462       6.72122       5.96268       5.23542       4.92887\n",
       "rmse                    2.37348   0.0926518   2.32478       2.59253       2.44186       2.2881        2.22011\n",
       "rmsle                   0.19797   0.00753017  0.188384      0.215613      0.203909      0.194889      0.187056"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_deviance</b></td>\n",
       "<td><b>training_mae</b></td>\n",
       "<td><b>training_r2</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:11:33</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:11:33</td>\n",
       "<td>12.739 sec</td>\n",
       "<td>62617 obs/sec</td>\n",
       "<td>5.1668878</td>\n",
       "<td>1</td>\n",
       "<td>19474.0</td>\n",
       "<td>2.4831161</td>\n",
       "<td>6.1658655</td>\n",
       "<td>2.0596874</td>\n",
       "<td>0.3978067</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:11:35</td>\n",
       "<td>14.715 sec</td>\n",
       "<td>94687 obs/sec</td>\n",
       "<td>57.2042982</td>\n",
       "<td>11</td>\n",
       "<td>215603.0</td>\n",
       "<td>2.4219142</td>\n",
       "<td>5.8656685</td>\n",
       "<td>1.9040087</td>\n",
       "<td>0.4271256</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_deviance    training_mae    training_r2\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  -------------------  --------------  -------------\n",
       "    2018-10-15 21:11:33  0.000 sec                     0         0             0          nan              nan                  nan             nan\n",
       "    2018-10-15 21:11:33  12.739 sec  62617 obs/sec     5.16689   1             19474      2.48312          6.16587              2.05969         0.397807\n",
       "    2018-10-15 21:11:35  14.715 sec  94687 obs/sec     57.2043   11            215603     2.42191          5.86567              1.90401         0.427126"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>Shucked weight</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1580821</td></tr>\n",
       "<tr><td>Whole weight</td>\n",
       "<td>0.7650543</td>\n",
       "<td>0.7650543</td>\n",
       "<td>0.1209414</td></tr>\n",
       "<tr><td>Shell weight</td>\n",
       "<td>0.6693134</td>\n",
       "<td>0.6693134</td>\n",
       "<td>0.1058065</td></tr>\n",
       "<tr><td>Sex.M</td>\n",
       "<td>0.6539977</td>\n",
       "<td>0.6539977</td>\n",
       "<td>0.1033853</td></tr>\n",
       "<tr><td>Sex.F</td>\n",
       "<td>0.6423760</td>\n",
       "<td>0.6423760</td>\n",
       "<td>0.1015482</td></tr>\n",
       "<tr><td>Sex.I</td>\n",
       "<td>0.6084121</td>\n",
       "<td>0.6084121</td>\n",
       "<td>0.0961791</td></tr>\n",
       "<tr><td>Viscera weight</td>\n",
       "<td>0.5294961</td>\n",
       "<td>0.5294961</td>\n",
       "<td>0.0837039</td></tr>\n",
       "<tr><td>Diameter</td>\n",
       "<td>0.5117155</td>\n",
       "<td>0.5117155</td>\n",
       "<td>0.0808931</td></tr>\n",
       "<tr><td>Height</td>\n",
       "<td>0.4871093</td>\n",
       "<td>0.4871093</td>\n",
       "<td>0.0770033</td></tr>\n",
       "<tr><td>Length</td>\n",
       "<td>0.4583517</td>\n",
       "<td>0.4583517</td>\n",
       "<td>0.0724572</td></tr>\n",
       "<tr><td>Sex.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "variable         relative_importance    scaled_importance    percentage\n",
       "---------------  ---------------------  -------------------  ------------\n",
       "Shucked weight   1                      1                    0.158082\n",
       "Whole weight     0.765054               0.765054             0.120941\n",
       "Shell weight     0.669313               0.669313             0.105806\n",
       "Sex.M            0.653998               0.653998             0.103385\n",
       "Sex.F            0.642376               0.642376             0.101548\n",
       "Sex.I            0.608412               0.608412             0.0961791\n",
       "Viscera weight   0.529496               0.529496             0.0837039\n",
       "Diameter         0.511716               0.511716             0.0808931\n",
       "Height           0.487109               0.487109             0.0770033\n",
       "Length           0.458352               0.458352             0.0724572\n",
       "Sex.missing(NA)  0                      0                    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2ORegressionModel.plot of >"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_model.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning prediction progress: |███████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\"> 11.8876 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  6.53234</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  8.10501</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 10.0541 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 14.9163 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 13.6421 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 12.4894 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 12.5495 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 14.3814 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 11.4631 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = dp_model.predict(test)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsRegression: deeplearning\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 6.938634787517225\n",
      "RMSE: 2.6341288479338334\n",
      "MAE: 2.069074467404063\n",
      "RMSLE: 0.2143417650625174\n",
      "Mean Residual Deviance: 6.938634787517225\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref = dp_model.model_performance(test)\n",
    "pref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the deep learning model the mse is 5.865668546201815 on the training model and 6.938634787517225 on the testing model. The model is a little bit overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aml = H2OAutoML(max_runtime_secs=run_time,project_name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "aml.train(x=X,y=y,training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aml_ld_df = aml.leaderboard.as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>mean_residual_deviance</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmsle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StackedEnsemble_AllModels_0_AutoML_20181015_21...</td>\n",
       "      <td>4.434801</td>\n",
       "      <td>2.105897</td>\n",
       "      <td>4.434801</td>\n",
       "      <td>1.502525</td>\n",
       "      <td>0.170777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StackedEnsemble_BestOfFamily_0_AutoML_20181015...</td>\n",
       "      <td>4.442140</td>\n",
       "      <td>2.107638</td>\n",
       "      <td>4.442140</td>\n",
       "      <td>1.508421</td>\n",
       "      <td>0.170951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_9</td>\n",
       "      <td>4.586179</td>\n",
       "      <td>2.141537</td>\n",
       "      <td>4.586179</td>\n",
       "      <td>1.516768</td>\n",
       "      <td>0.173465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_4</td>\n",
       "      <td>4.625781</td>\n",
       "      <td>2.150763</td>\n",
       "      <td>4.625781</td>\n",
       "      <td>1.532058</td>\n",
       "      <td>0.175533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_15</td>\n",
       "      <td>4.648548</td>\n",
       "      <td>2.156049</td>\n",
       "      <td>4.648548</td>\n",
       "      <td>1.523286</td>\n",
       "      <td>0.175621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_34</td>\n",
       "      <td>4.661976</td>\n",
       "      <td>2.159161</td>\n",
       "      <td>4.661976</td>\n",
       "      <td>1.536311</td>\n",
       "      <td>0.175357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_21</td>\n",
       "      <td>4.698083</td>\n",
       "      <td>2.167506</td>\n",
       "      <td>4.698083</td>\n",
       "      <td>1.544804</td>\n",
       "      <td>0.176705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GLM_grid_0_AutoML_20181015_211148_model_0</td>\n",
       "      <td>4.711984</td>\n",
       "      <td>2.170710</td>\n",
       "      <td>4.711984</td>\n",
       "      <td>1.574163</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_1</td>\n",
       "      <td>4.714029</td>\n",
       "      <td>2.171182</td>\n",
       "      <td>4.714029</td>\n",
       "      <td>1.533723</td>\n",
       "      <td>0.175642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_7</td>\n",
       "      <td>4.735583</td>\n",
       "      <td>2.176139</td>\n",
       "      <td>4.735583</td>\n",
       "      <td>1.536004</td>\n",
       "      <td>0.175830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_2</td>\n",
       "      <td>4.778914</td>\n",
       "      <td>2.186073</td>\n",
       "      <td>4.778914</td>\n",
       "      <td>1.537833</td>\n",
       "      <td>0.176557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_0</td>\n",
       "      <td>4.790787</td>\n",
       "      <td>2.188787</td>\n",
       "      <td>4.790787</td>\n",
       "      <td>1.543922</td>\n",
       "      <td>0.176877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_28</td>\n",
       "      <td>4.847341</td>\n",
       "      <td>2.201668</td>\n",
       "      <td>4.847341</td>\n",
       "      <td>1.557310</td>\n",
       "      <td>0.178632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_3</td>\n",
       "      <td>4.856583</td>\n",
       "      <td>2.203766</td>\n",
       "      <td>4.856583</td>\n",
       "      <td>1.557653</td>\n",
       "      <td>0.178397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_12</td>\n",
       "      <td>4.889786</td>\n",
       "      <td>2.211286</td>\n",
       "      <td>4.889786</td>\n",
       "      <td>1.565767</td>\n",
       "      <td>0.181857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DRF_0_AutoML_20181015_211148</td>\n",
       "      <td>4.944461</td>\n",
       "      <td>2.223614</td>\n",
       "      <td>4.944461</td>\n",
       "      <td>1.581250</td>\n",
       "      <td>0.180348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_6</td>\n",
       "      <td>4.966247</td>\n",
       "      <td>2.228508</td>\n",
       "      <td>4.966247</td>\n",
       "      <td>1.585641</td>\n",
       "      <td>0.180864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_29</td>\n",
       "      <td>5.021270</td>\n",
       "      <td>2.240819</td>\n",
       "      <td>5.021270</td>\n",
       "      <td>1.584417</td>\n",
       "      <td>0.181884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_26</td>\n",
       "      <td>5.056860</td>\n",
       "      <td>2.248746</td>\n",
       "      <td>5.056860</td>\n",
       "      <td>1.592842</td>\n",
       "      <td>0.183401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_8</td>\n",
       "      <td>5.069858</td>\n",
       "      <td>2.251635</td>\n",
       "      <td>5.069858</td>\n",
       "      <td>1.597888</td>\n",
       "      <td>0.185051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_23</td>\n",
       "      <td>5.089113</td>\n",
       "      <td>2.255906</td>\n",
       "      <td>5.089113</td>\n",
       "      <td>1.602023</td>\n",
       "      <td>0.182901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XRT_0_AutoML_20181015_211148</td>\n",
       "      <td>5.105202</td>\n",
       "      <td>2.259469</td>\n",
       "      <td>5.105202</td>\n",
       "      <td>1.596110</td>\n",
       "      <td>0.182105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_31</td>\n",
       "      <td>5.124915</td>\n",
       "      <td>2.263828</td>\n",
       "      <td>5.124915</td>\n",
       "      <td>1.600935</td>\n",
       "      <td>0.185716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_13</td>\n",
       "      <td>5.210577</td>\n",
       "      <td>2.282669</td>\n",
       "      <td>5.210577</td>\n",
       "      <td>1.621121</td>\n",
       "      <td>0.185890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_17</td>\n",
       "      <td>5.250402</td>\n",
       "      <td>2.291375</td>\n",
       "      <td>5.250402</td>\n",
       "      <td>1.638050</td>\n",
       "      <td>0.192153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_10</td>\n",
       "      <td>5.295023</td>\n",
       "      <td>2.301092</td>\n",
       "      <td>5.295023</td>\n",
       "      <td>1.639198</td>\n",
       "      <td>0.188509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_22</td>\n",
       "      <td>5.593729</td>\n",
       "      <td>2.365106</td>\n",
       "      <td>5.593729</td>\n",
       "      <td>1.687722</td>\n",
       "      <td>0.196735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_32</td>\n",
       "      <td>5.623431</td>\n",
       "      <td>2.371377</td>\n",
       "      <td>5.623431</td>\n",
       "      <td>1.697032</td>\n",
       "      <td>0.193976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_18</td>\n",
       "      <td>5.633183</td>\n",
       "      <td>2.373433</td>\n",
       "      <td>5.633183</td>\n",
       "      <td>1.695812</td>\n",
       "      <td>0.197327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_24</td>\n",
       "      <td>5.710828</td>\n",
       "      <td>2.389734</td>\n",
       "      <td>5.710828</td>\n",
       "      <td>1.718106</td>\n",
       "      <td>0.199978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_19</td>\n",
       "      <td>5.747187</td>\n",
       "      <td>2.397329</td>\n",
       "      <td>5.747187</td>\n",
       "      <td>1.712632</td>\n",
       "      <td>0.196090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_30</td>\n",
       "      <td>5.749491</td>\n",
       "      <td>2.397810</td>\n",
       "      <td>5.749491</td>\n",
       "      <td>1.715026</td>\n",
       "      <td>0.197125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>DeepLearning_grid_0_AutoML_20181015_211148_mod...</td>\n",
       "      <td>5.767392</td>\n",
       "      <td>2.401539</td>\n",
       "      <td>5.767392</td>\n",
       "      <td>1.866172</td>\n",
       "      <td>0.201298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>DeepLearning_0_AutoML_20181015_211148</td>\n",
       "      <td>5.804162</td>\n",
       "      <td>2.409183</td>\n",
       "      <td>5.804162</td>\n",
       "      <td>1.798363</td>\n",
       "      <td>0.200049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_11</td>\n",
       "      <td>6.091211</td>\n",
       "      <td>2.468038</td>\n",
       "      <td>6.091211</td>\n",
       "      <td>1.767787</td>\n",
       "      <td>0.204044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_5</td>\n",
       "      <td>6.149105</td>\n",
       "      <td>2.479739</td>\n",
       "      <td>6.149105</td>\n",
       "      <td>1.752827</td>\n",
       "      <td>0.201240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_33</td>\n",
       "      <td>6.599057</td>\n",
       "      <td>2.568863</td>\n",
       "      <td>6.599057</td>\n",
       "      <td>1.854063</td>\n",
       "      <td>0.215454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_20</td>\n",
       "      <td>8.782561</td>\n",
       "      <td>2.963539</td>\n",
       "      <td>8.782561</td>\n",
       "      <td>2.126520</td>\n",
       "      <td>0.248429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_16</td>\n",
       "      <td>9.973171</td>\n",
       "      <td>3.158033</td>\n",
       "      <td>9.973171</td>\n",
       "      <td>2.317923</td>\n",
       "      <td>0.283680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_14</td>\n",
       "      <td>10.020034</td>\n",
       "      <td>3.165444</td>\n",
       "      <td>10.020034</td>\n",
       "      <td>2.322849</td>\n",
       "      <td>0.284269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_25</td>\n",
       "      <td>10.032127</td>\n",
       "      <td>3.167353</td>\n",
       "      <td>10.032127</td>\n",
       "      <td>2.324104</td>\n",
       "      <td>0.284419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_211148_model_27</td>\n",
       "      <td>10.052486</td>\n",
       "      <td>3.170566</td>\n",
       "      <td>10.052486</td>\n",
       "      <td>2.326280</td>\n",
       "      <td>0.284699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             model_id  mean_residual_deviance  \\\n",
       "0   StackedEnsemble_AllModels_0_AutoML_20181015_21...                4.434801   \n",
       "1   StackedEnsemble_BestOfFamily_0_AutoML_20181015...                4.442140   \n",
       "2           GBM_grid_0_AutoML_20181015_211148_model_9                4.586179   \n",
       "3           GBM_grid_0_AutoML_20181015_211148_model_4                4.625781   \n",
       "4          GBM_grid_0_AutoML_20181015_211148_model_15                4.648548   \n",
       "5          GBM_grid_0_AutoML_20181015_211148_model_34                4.661976   \n",
       "6          GBM_grid_0_AutoML_20181015_211148_model_21                4.698083   \n",
       "7           GLM_grid_0_AutoML_20181015_211148_model_0                4.711984   \n",
       "8           GBM_grid_0_AutoML_20181015_211148_model_1                4.714029   \n",
       "9           GBM_grid_0_AutoML_20181015_211148_model_7                4.735583   \n",
       "10          GBM_grid_0_AutoML_20181015_211148_model_2                4.778914   \n",
       "11          GBM_grid_0_AutoML_20181015_211148_model_0                4.790787   \n",
       "12         GBM_grid_0_AutoML_20181015_211148_model_28                4.847341   \n",
       "13          GBM_grid_0_AutoML_20181015_211148_model_3                4.856583   \n",
       "14         GBM_grid_0_AutoML_20181015_211148_model_12                4.889786   \n",
       "15                       DRF_0_AutoML_20181015_211148                4.944461   \n",
       "16          GBM_grid_0_AutoML_20181015_211148_model_6                4.966247   \n",
       "17         GBM_grid_0_AutoML_20181015_211148_model_29                5.021270   \n",
       "18         GBM_grid_0_AutoML_20181015_211148_model_26                5.056860   \n",
       "19          GBM_grid_0_AutoML_20181015_211148_model_8                5.069858   \n",
       "20         GBM_grid_0_AutoML_20181015_211148_model_23                5.089113   \n",
       "21                       XRT_0_AutoML_20181015_211148                5.105202   \n",
       "22         GBM_grid_0_AutoML_20181015_211148_model_31                5.124915   \n",
       "23         GBM_grid_0_AutoML_20181015_211148_model_13                5.210577   \n",
       "24         GBM_grid_0_AutoML_20181015_211148_model_17                5.250402   \n",
       "25         GBM_grid_0_AutoML_20181015_211148_model_10                5.295023   \n",
       "26         GBM_grid_0_AutoML_20181015_211148_model_22                5.593729   \n",
       "27         GBM_grid_0_AutoML_20181015_211148_model_32                5.623431   \n",
       "28         GBM_grid_0_AutoML_20181015_211148_model_18                5.633183   \n",
       "29         GBM_grid_0_AutoML_20181015_211148_model_24                5.710828   \n",
       "30         GBM_grid_0_AutoML_20181015_211148_model_19                5.747187   \n",
       "31         GBM_grid_0_AutoML_20181015_211148_model_30                5.749491   \n",
       "32  DeepLearning_grid_0_AutoML_20181015_211148_mod...                5.767392   \n",
       "33              DeepLearning_0_AutoML_20181015_211148                5.804162   \n",
       "34         GBM_grid_0_AutoML_20181015_211148_model_11                6.091211   \n",
       "35          GBM_grid_0_AutoML_20181015_211148_model_5                6.149105   \n",
       "36         GBM_grid_0_AutoML_20181015_211148_model_33                6.599057   \n",
       "37         GBM_grid_0_AutoML_20181015_211148_model_20                8.782561   \n",
       "38         GBM_grid_0_AutoML_20181015_211148_model_16                9.973171   \n",
       "39         GBM_grid_0_AutoML_20181015_211148_model_14               10.020034   \n",
       "40         GBM_grid_0_AutoML_20181015_211148_model_25               10.032127   \n",
       "41         GBM_grid_0_AutoML_20181015_211148_model_27               10.052486   \n",
       "\n",
       "        rmse        mse       mae     rmsle  \n",
       "0   2.105897   4.434801  1.502525  0.170777  \n",
       "1   2.107638   4.442140  1.508421  0.170951  \n",
       "2   2.141537   4.586179  1.516768  0.173465  \n",
       "3   2.150763   4.625781  1.532058  0.175533  \n",
       "4   2.156049   4.648548  1.523286  0.175621  \n",
       "5   2.159161   4.661976  1.536311  0.175357  \n",
       "6   2.167506   4.698083  1.544804  0.176705  \n",
       "7   2.170710   4.711984  1.574163       NaN  \n",
       "8   2.171182   4.714029  1.533723  0.175642  \n",
       "9   2.176139   4.735583  1.536004  0.175830  \n",
       "10  2.186073   4.778914  1.537833  0.176557  \n",
       "11  2.188787   4.790787  1.543922  0.176877  \n",
       "12  2.201668   4.847341  1.557310  0.178632  \n",
       "13  2.203766   4.856583  1.557653  0.178397  \n",
       "14  2.211286   4.889786  1.565767  0.181857  \n",
       "15  2.223614   4.944461  1.581250  0.180348  \n",
       "16  2.228508   4.966247  1.585641  0.180864  \n",
       "17  2.240819   5.021270  1.584417  0.181884  \n",
       "18  2.248746   5.056860  1.592842  0.183401  \n",
       "19  2.251635   5.069858  1.597888  0.185051  \n",
       "20  2.255906   5.089113  1.602023  0.182901  \n",
       "21  2.259469   5.105202  1.596110  0.182105  \n",
       "22  2.263828   5.124915  1.600935  0.185716  \n",
       "23  2.282669   5.210577  1.621121  0.185890  \n",
       "24  2.291375   5.250402  1.638050  0.192153  \n",
       "25  2.301092   5.295023  1.639198  0.188509  \n",
       "26  2.365106   5.593729  1.687722  0.196735  \n",
       "27  2.371377   5.623431  1.697032  0.193976  \n",
       "28  2.373433   5.633183  1.695812  0.197327  \n",
       "29  2.389734   5.710828  1.718106  0.199978  \n",
       "30  2.397329   5.747187  1.712632  0.196090  \n",
       "31  2.397810   5.749491  1.715026  0.197125  \n",
       "32  2.401539   5.767392  1.866172  0.201298  \n",
       "33  2.409183   5.804162  1.798363  0.200049  \n",
       "34  2.468038   6.091211  1.767787  0.204044  \n",
       "35  2.479739   6.149105  1.752827  0.201240  \n",
       "36  2.568863   6.599057  1.854063  0.215454  \n",
       "37  2.963539   8.782561  2.126520  0.248429  \n",
       "38  3.158033   9.973171  2.317923  0.283680  \n",
       "39  3.165444  10.020034  2.322849  0.284269  \n",
       "40  3.167353  10.032127  2.324104  0.284419  \n",
       "41  3.170566  10.052486  2.326280  0.284699  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml_ld_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                             </th><th style=\"text-align: right;\">  mean_residual_deviance</th><th style=\"text-align: right;\">   rmse</th><th style=\"text-align: right;\">    mse</th><th style=\"text-align: right;\">    mae</th><th style=\"text-align: right;\">     rmsle</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_AllModels_0_AutoML_20181015_211148   </td><td style=\"text-align: right;\">                 4.4348 </td><td style=\"text-align: right;\">2.1059 </td><td style=\"text-align: right;\">4.4348 </td><td style=\"text-align: right;\">1.50252</td><td style=\"text-align: right;\">  0.170777</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_0_AutoML_20181015_211148</td><td style=\"text-align: right;\">                 4.44214</td><td style=\"text-align: right;\">2.10764</td><td style=\"text-align: right;\">4.44214</td><td style=\"text-align: right;\">1.50842</td><td style=\"text-align: right;\">  0.170951</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20181015_211148_model_9            </td><td style=\"text-align: right;\">                 4.58618</td><td style=\"text-align: right;\">2.14154</td><td style=\"text-align: right;\">4.58618</td><td style=\"text-align: right;\">1.51677</td><td style=\"text-align: right;\">  0.173465</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20181015_211148_model_4            </td><td style=\"text-align: right;\">                 4.62578</td><td style=\"text-align: right;\">2.15076</td><td style=\"text-align: right;\">4.62578</td><td style=\"text-align: right;\">1.53206</td><td style=\"text-align: right;\">  0.175533</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20181015_211148_model_15           </td><td style=\"text-align: right;\">                 4.64855</td><td style=\"text-align: right;\">2.15605</td><td style=\"text-align: right;\">4.64855</td><td style=\"text-align: right;\">1.52329</td><td style=\"text-align: right;\">  0.175621</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20181015_211148_model_34           </td><td style=\"text-align: right;\">                 4.66198</td><td style=\"text-align: right;\">2.15916</td><td style=\"text-align: right;\">4.66198</td><td style=\"text-align: right;\">1.53631</td><td style=\"text-align: right;\">  0.175357</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20181015_211148_model_21           </td><td style=\"text-align: right;\">                 4.69808</td><td style=\"text-align: right;\">2.16751</td><td style=\"text-align: right;\">4.69808</td><td style=\"text-align: right;\">1.5448 </td><td style=\"text-align: right;\">  0.176705</td></tr>\n",
       "<tr><td>GLM_grid_0_AutoML_20181015_211148_model_0            </td><td style=\"text-align: right;\">                 4.71198</td><td style=\"text-align: right;\">2.17071</td><td style=\"text-align: right;\">4.71198</td><td style=\"text-align: right;\">1.57416</td><td style=\"text-align: right;\">nan       </td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20181015_211148_model_1            </td><td style=\"text-align: right;\">                 4.71403</td><td style=\"text-align: right;\">2.17118</td><td style=\"text-align: right;\">4.71403</td><td style=\"text-align: right;\">1.53372</td><td style=\"text-align: right;\">  0.175642</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20181015_211148_model_7            </td><td style=\"text-align: right;\">                 4.73558</td><td style=\"text-align: right;\">2.17614</td><td style=\"text-align: right;\">4.73558</td><td style=\"text-align: right;\">1.536  </td><td style=\"text-align: right;\">  0.17583 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = aml.leaderboard\n",
    "lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                             </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_AllModels_0_AutoML_20181015_211148   </td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_0_AutoML_20181015_211148</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20181015_211148_model_9            </td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20181015_211148_model_4            </td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20181015_211148_model_15           </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb[:5,\"model_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_grid_0_AutoML_20181015_211148_model_9\n",
      "\n",
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 3.160883496030043\n",
      "RMSE: 1.7778873687694738\n",
      "MAE: 1.255954652447602\n",
      "RMSLE: 0.14364723138384602\n",
      "Mean Residual Deviance: 3.160883496030043\n",
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 4.336805954527118\n",
      "RMSE: 2.0824999290581303\n",
      "MAE: 1.4667477148576828\n",
      "RMSLE: 0.16826219529663133\n",
      "Mean Residual Deviance: 4.336805954527118\n",
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 4.586179385790485\n",
      "RMSE: 2.141536687939407\n",
      "MAE: 1.516767907604962\n",
      "RMSLE: 0.17346450096271426\n",
      "Mean Residual Deviance: 4.586179385790485\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>mae</td>\n",
       "<td>1.5167367</td>\n",
       "<td>0.0356906</td>\n",
       "<td>1.5334464</td>\n",
       "<td>1.594954</td>\n",
       "<td>1.4667878</td>\n",
       "<td>1.4566004</td>\n",
       "<td>1.5318953</td></tr>\n",
       "<tr><td>mean_residual_deviance</td>\n",
       "<td>4.585931</td>\n",
       "<td>0.2898193</td>\n",
       "<td>4.765925</td>\n",
       "<td>5.1630797</td>\n",
       "<td>4.0254464</td>\n",
       "<td>4.2221084</td>\n",
       "<td>4.7530947</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>4.585931</td>\n",
       "<td>0.2898193</td>\n",
       "<td>4.765925</td>\n",
       "<td>5.1630797</td>\n",
       "<td>4.0254464</td>\n",
       "<td>4.2221084</td>\n",
       "<td>4.7530947</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.5527904</td>\n",
       "<td>0.0188658</td>\n",
       "<td>0.5070531</td>\n",
       "<td>0.5557122</td>\n",
       "<td>0.5683597</td>\n",
       "<td>0.5869703</td>\n",
       "<td>0.5458567</td></tr>\n",
       "<tr><td>residual_deviance</td>\n",
       "<td>4.585931</td>\n",
       "<td>0.2898193</td>\n",
       "<td>4.765925</td>\n",
       "<td>5.1630797</td>\n",
       "<td>4.0254464</td>\n",
       "<td>4.2221084</td>\n",
       "<td>4.7530947</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>2.1393259</td>\n",
       "<td>0.0678828</td>\n",
       "<td>2.1830997</td>\n",
       "<td>2.272241</td>\n",
       "<td>2.0063515</td>\n",
       "<td>2.054777</td>\n",
       "<td>2.1801593</td></tr>\n",
       "<tr><td>rmsle</td>\n",
       "<td>0.1733983</td>\n",
       "<td>0.0033293</td>\n",
       "<td>0.1786909</td>\n",
       "<td>0.1751794</td>\n",
       "<td>0.1718688</td>\n",
       "<td>0.1650608</td>\n",
       "<td>0.1761914</td></tr></table></div>"
      ],
      "text/plain": [
       "                        mean      sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "----------------------  --------  ----------  ------------  ------------  ------------  ------------  ------------\n",
       "mae                     1.51674   0.0356906   1.53345       1.59495       1.46679       1.4566        1.5319\n",
       "mean_residual_deviance  4.58593   0.289819    4.76593       5.16308       4.02545       4.22211       4.75309\n",
       "mse                     4.58593   0.289819    4.76593       5.16308       4.02545       4.22211       4.75309\n",
       "r2                      0.55279   0.0188658   0.507053      0.555712      0.56836       0.58697       0.545857\n",
       "residual_deviance       4.58593   0.289819    4.76593       5.16308       4.02545       4.22211       4.75309\n",
       "rmse                    2.13933   0.0678828   2.1831        2.27224       2.00635       2.05478       2.18016\n",
       "rmsle                   0.173398  0.00332925  0.178691      0.175179      0.171869      0.165061      0.176191"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_mae</b></td>\n",
       "<td><b>training_deviance</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_mae</b></td>\n",
       "<td><b>validation_deviance</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:12:14</td>\n",
       "<td> 6.735 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>3.2054750</td>\n",
       "<td>2.3572785</td>\n",
       "<td>10.2750703</td>\n",
       "<td>3.1759926</td>\n",
       "<td>2.3400061</td>\n",
       "<td>10.0869292</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:12:14</td>\n",
       "<td> 6.753 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>2.8526917</td>\n",
       "<td>2.0896556</td>\n",
       "<td>8.1378502</td>\n",
       "<td>2.8498326</td>\n",
       "<td>2.0844215</td>\n",
       "<td>8.1215461</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:12:14</td>\n",
       "<td> 6.769 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>2.5689369</td>\n",
       "<td>1.8696084</td>\n",
       "<td>6.5994368</td>\n",
       "<td>2.5947677</td>\n",
       "<td>1.8752773</td>\n",
       "<td>6.7328194</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:12:14</td>\n",
       "<td> 6.784 sec</td>\n",
       "<td>15.0</td>\n",
       "<td>2.3652093</td>\n",
       "<td>1.7089309</td>\n",
       "<td>5.5942150</td>\n",
       "<td>2.4247055</td>\n",
       "<td>1.7379828</td>\n",
       "<td>5.8791966</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:12:14</td>\n",
       "<td> 6.799 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>2.2238209</td>\n",
       "<td>1.5965949</td>\n",
       "<td>4.9453794</td>\n",
       "<td>2.3124391</td>\n",
       "<td>1.6440709</td>\n",
       "<td>5.3473745</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:12:14</td>\n",
       "<td> 6.814 sec</td>\n",
       "<td>25.0</td>\n",
       "<td>2.1140102</td>\n",
       "<td>1.5084913</td>\n",
       "<td>4.4690392</td>\n",
       "<td>2.2382353</td>\n",
       "<td>1.5813025</td>\n",
       "<td>5.0096975</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:12:14</td>\n",
       "<td> 6.831 sec</td>\n",
       "<td>30.0</td>\n",
       "<td>2.0335399</td>\n",
       "<td>1.4424717</td>\n",
       "<td>4.1352847</td>\n",
       "<td>2.1829816</td>\n",
       "<td>1.5381064</td>\n",
       "<td>4.7654086</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:12:14</td>\n",
       "<td> 6.846 sec</td>\n",
       "<td>35.0</td>\n",
       "<td>1.9730091</td>\n",
       "<td>1.3942054</td>\n",
       "<td>3.8927648</td>\n",
       "<td>2.1472773</td>\n",
       "<td>1.5070584</td>\n",
       "<td>4.6107997</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:12:14</td>\n",
       "<td> 6.861 sec</td>\n",
       "<td>40.0</td>\n",
       "<td>1.9282414</td>\n",
       "<td>1.3589031</td>\n",
       "<td>3.7181148</td>\n",
       "<td>2.1262752</td>\n",
       "<td>1.4918552</td>\n",
       "<td>4.5210462</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:12:14</td>\n",
       "<td> 6.876 sec</td>\n",
       "<td>45.0</td>\n",
       "<td>1.8886004</td>\n",
       "<td>1.3294942</td>\n",
       "<td>3.5668115</td>\n",
       "<td>2.1068846</td>\n",
       "<td>1.4770541</td>\n",
       "<td>4.4389628</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:12:14</td>\n",
       "<td> 6.892 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>1.8617572</td>\n",
       "<td>1.3109221</td>\n",
       "<td>3.4661397</td>\n",
       "<td>2.0971202</td>\n",
       "<td>1.4711996</td>\n",
       "<td>4.3979132</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:12:14</td>\n",
       "<td> 6.906 sec</td>\n",
       "<td>55.0</td>\n",
       "<td>1.8348637</td>\n",
       "<td>1.2923231</td>\n",
       "<td>3.3667249</td>\n",
       "<td>2.0895578</td>\n",
       "<td>1.4662072</td>\n",
       "<td>4.3662517</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:12:14</td>\n",
       "<td> 6.920 sec</td>\n",
       "<td>60.0</td>\n",
       "<td>1.8117174</td>\n",
       "<td>1.2775301</td>\n",
       "<td>3.2823198</td>\n",
       "<td>2.0877285</td>\n",
       "<td>1.4672444</td>\n",
       "<td>4.3586105</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:12:14</td>\n",
       "<td> 6.936 sec</td>\n",
       "<td>65.0</td>\n",
       "<td>1.7900569</td>\n",
       "<td>1.2634885</td>\n",
       "<td>3.2043037</td>\n",
       "<td>2.0824105</td>\n",
       "<td>1.4659653</td>\n",
       "<td>4.3364333</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:12:14</td>\n",
       "<td> 6.945 sec</td>\n",
       "<td>68.0</td>\n",
       "<td>1.7778874</td>\n",
       "<td>1.2559547</td>\n",
       "<td>3.1608835</td>\n",
       "<td>2.0824999</td>\n",
       "<td>1.4667477</td>\n",
       "<td>4.3368060</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    number_of_trees    training_rmse    training_mae    training_deviance    validation_rmse    validation_mae    validation_deviance\n",
       "--  -------------------  ----------  -----------------  ---------------  --------------  -------------------  -----------------  ----------------  ---------------------\n",
       "    2018-10-15 21:12:14  6.735 sec   0                  3.20548          2.35728         10.2751              3.17599            2.34001           10.0869\n",
       "    2018-10-15 21:12:14  6.753 sec   5                  2.85269          2.08966         8.13785              2.84983            2.08442           8.12155\n",
       "    2018-10-15 21:12:14  6.769 sec   10                 2.56894          1.86961         6.59944              2.59477            1.87528           6.73282\n",
       "    2018-10-15 21:12:14  6.784 sec   15                 2.36521          1.70893         5.59421              2.42471            1.73798           5.8792\n",
       "    2018-10-15 21:12:14  6.799 sec   20                 2.22382          1.59659         4.94538              2.31244            1.64407           5.34737\n",
       "    2018-10-15 21:12:14  6.814 sec   25                 2.11401          1.50849         4.46904              2.23824            1.5813            5.0097\n",
       "    2018-10-15 21:12:14  6.831 sec   30                 2.03354          1.44247         4.13528              2.18298            1.53811           4.76541\n",
       "    2018-10-15 21:12:14  6.846 sec   35                 1.97301          1.39421         3.89276              2.14728            1.50706           4.6108\n",
       "    2018-10-15 21:12:14  6.861 sec   40                 1.92824          1.3589          3.71811              2.12628            1.49186           4.52105\n",
       "    2018-10-15 21:12:14  6.876 sec   45                 1.8886           1.32949         3.56681              2.10688            1.47705           4.43896\n",
       "    2018-10-15 21:12:14  6.892 sec   50                 1.86176          1.31092         3.46614              2.09712            1.4712            4.39791\n",
       "    2018-10-15 21:12:14  6.906 sec   55                 1.83486          1.29232         3.36672              2.08956            1.46621           4.36625\n",
       "    2018-10-15 21:12:14  6.920 sec   60                 1.81172          1.27753         3.28232              2.08773            1.46724           4.35861\n",
       "    2018-10-15 21:12:14  6.936 sec   65                 1.79006          1.26349         3.2043               2.08241            1.46597           4.33643\n",
       "    2018-10-15 21:12:14  6.945 sec   68                 1.77789          1.25595         3.16088              2.0825             1.46675           4.33681"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>Shell weight</td>\n",
       "<td>100631.7109375</td>\n",
       "<td>1.0</td>\n",
       "<td>0.4671920</td></tr>\n",
       "<tr><td>Shucked weight</td>\n",
       "<td>26057.9941406</td>\n",
       "<td>0.2589442</td>\n",
       "<td>0.1209767</td></tr>\n",
       "<tr><td>Height</td>\n",
       "<td>20855.4882812</td>\n",
       "<td>0.2072457</td>\n",
       "<td>0.0968235</td></tr>\n",
       "<tr><td>Viscera weight</td>\n",
       "<td>19895.9082031</td>\n",
       "<td>0.1977101</td>\n",
       "<td>0.0923686</td></tr>\n",
       "<tr><td>Diameter</td>\n",
       "<td>16692.7265625</td>\n",
       "<td>0.1658794</td>\n",
       "<td>0.0774975</td></tr>\n",
       "<tr><td>Whole weight</td>\n",
       "<td>16361.2871094</td>\n",
       "<td>0.1625858</td>\n",
       "<td>0.0759588</td></tr>\n",
       "<tr><td>Length</td>\n",
       "<td>9868.0888672</td>\n",
       "<td>0.0980614</td>\n",
       "<td>0.0458135</td></tr>\n",
       "<tr><td>Sex</td>\n",
       "<td>5033.6855469</td>\n",
       "<td>0.0500209</td>\n",
       "<td>0.0233694</td></tr></table></div>"
      ],
      "text/plain": [
       "variable        relative_importance    scaled_importance    percentage\n",
       "--------------  ---------------------  -------------------  ------------\n",
       "Shell weight    100632                 1                    0.467192\n",
       "Shucked weight  26058                  0.258944             0.120977\n",
       "Height          20855.5                0.207246             0.0968235\n",
       "Viscera weight  19895.9                0.19771              0.0923686\n",
       "Diameter        16692.7                0.165879             0.0774975\n",
       "Whole weight    16361.3                0.162586             0.0759588\n",
       "Length          9868.09                0.0980614            0.0458135\n",
       "Sex             5033.69                0.0500209            0.0233694"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = h2o.get_model(lb[2,\"model_id\"])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shell weight</td>\n",
       "      <td>100631.710938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.467192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shucked weight</td>\n",
       "      <td>26057.994141</td>\n",
       "      <td>0.258944</td>\n",
       "      <td>0.120977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Height</td>\n",
       "      <td>20855.488281</td>\n",
       "      <td>0.207246</td>\n",
       "      <td>0.096824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Viscera weight</td>\n",
       "      <td>19895.908203</td>\n",
       "      <td>0.197710</td>\n",
       "      <td>0.092369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diameter</td>\n",
       "      <td>16692.726562</td>\n",
       "      <td>0.165879</td>\n",
       "      <td>0.077498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Whole weight</td>\n",
       "      <td>16361.287109</td>\n",
       "      <td>0.162586</td>\n",
       "      <td>0.075959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Length</td>\n",
       "      <td>9868.088867</td>\n",
       "      <td>0.098061</td>\n",
       "      <td>0.045814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sex</td>\n",
       "      <td>5033.685547</td>\n",
       "      <td>0.050021</td>\n",
       "      <td>0.023369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         variable  relative_importance  scaled_importance  percentage\n",
       "0    Shell weight        100631.710938           1.000000    0.467192\n",
       "1  Shucked weight         26057.994141           0.258944    0.120977\n",
       "2          Height         20855.488281           0.207246    0.096824\n",
       "3  Viscera weight         19895.908203           0.197710    0.092369\n",
       "4        Diameter         16692.726562           0.165879    0.077498\n",
       "5    Whole weight         16361.287109           0.162586    0.075959\n",
       "6          Length          9868.088867           0.098061    0.045814\n",
       "7             Sex          5033.685547           0.050021    0.023369"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.varimp(use_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3UAAAJTCAYAAACvjD+/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d9f37b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m.varimp_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsRegressionGLM: stackedensemble\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 2.6793218985414757\n",
      "RMSE: 1.6368634330760388\n",
      "MAE: 1.1870386409938505\n",
      "RMSLE: 0.13359362179609738\n",
      "R^2: 0.7392405283210717\n",
      "Mean Residual Deviance: 2.6793218985414757\n",
      "Null degrees of freedom: 3046\n",
      "Residual degrees of freedom: 3034\n",
      "Null deviance: 31308.139153265463\n",
      "Residual deviance: 8163.893824855877\n",
      "AIC: 11678.024135833622\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader.model_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OStackedEnsembleEstimator :  Stacked Ensemble\n",
      "Model Key:  StackedEnsemble_AllModels_0_AutoML_20181015_211148\n",
      "No model summary for this model\n",
      "\n",
      "\n",
      "ModelMetricsRegressionGLM: stackedensemble\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 2.6793218985414757\n",
      "RMSE: 1.6368634330760388\n",
      "MAE: 1.1870386409938505\n",
      "RMSLE: 0.13359362179609738\n",
      "R^2: 0.7392405283210717\n",
      "Mean Residual Deviance: 2.6793218985414757\n",
      "Null degrees of freedom: 3046\n",
      "Residual degrees of freedom: 3034\n",
      "Null deviance: 31308.139153265463\n",
      "Residual deviance: 8163.893824855877\n",
      "AIC: 11678.024135833622\n",
      "\n",
      "ModelMetricsRegressionGLM: stackedensemble\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 4.397915659472469\n",
      "RMSE: 2.0971208023078853\n",
      "MAE: 1.4758325019046536\n",
      "RMSLE: 0.17187704454642422\n",
      "R^2: 0.5639791722560221\n",
      "Mean Residual Deviance: 4.397915659472469\n",
      "Null degrees of freedom: 721\n",
      "Residual degrees of freedom: 709\n",
      "Null deviance: 7282.762891809092\n",
      "Residual deviance: 3175.2951061391227\n",
      "AIC: 3146.323618127116\n",
      "\n",
      "ModelMetricsRegressionGLM: stackedensemble\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 4.434801464644573\n",
      "RMSE: 2.1058968314341926\n",
      "MAE: 1.5025246319873307\n",
      "RMSLE: 0.1707774195345072\n",
      "R^2: 0.5683921041547242\n",
      "Mean Residual Deviance: 4.434801464644573\n",
      "Null degrees of freedom: 3046\n",
      "Residual degrees of freedom: 3031\n",
      "Null deviance: 31338.459829179577\n",
      "Residual deviance: 13512.840062772013\n",
      "AIC: 13219.465662793733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2ORegressionModel.plot of >"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\"> 10.4622 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  6.01253</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  8.24998</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 10.3883 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 12.3177 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 13.8234 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 12.4781 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 11.198  </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 11.5442 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 11.563  </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = aml.predict(test)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsRegressionGLM: stackedensemble\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 5.128572178560316\n",
      "RMSE: 2.2646351093631654\n",
      "MAE: 1.5993990447405644\n",
      "RMSLE: 0.1786690210678624\n",
      "R^2: 0.5654877894303576\n",
      "Mean Residual Deviance: 5.128572178560316\n",
      "Null degrees of freedom: 407\n",
      "Residual degrees of freedom: 395\n",
      "Null deviance: 4820.597054633303\n",
      "Residual deviance: 2092.457448852609\n",
      "AIC: 1852.8633785069421\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref = aml.leader.model_performance(test)\n",
    "pref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For model StackedEnsemble_AllModels_0_AutoML_20181015_21 the mse is 2.6793218985414757 on the training data and 5.128572178560316 on the testing data. The model is overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path2 = 'Downloads/pokemon_alopez247.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_time = 333\n",
    "name2 = 'pokemon binary classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:27968..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_144\"; Java(TM) SE Runtime Environment (build 1.8.0_144-b01); Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)\n",
      "  Starting server from /anaconda3/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/qb/37dx26k10cn0288tblh64zg40000gn/T/tmpl3hdapwt\n",
      "  JVM stdout: /var/folders/qb/37dx26k10cn0288tblh64zg40000gn/T/tmpl3hdapwt/h2o_matt_started_from_python.out\n",
      "  JVM stderr: /var/folders/qb/37dx26k10cn0288tblh64zg40000gn/T/tmpl3hdapwt/h2o_matt_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:27968\n",
      "Connecting to H2O server at http://127.0.0.1:27968... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.20.0.8</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>24 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_matt_x5dtpx</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>5.750 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:27968</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.3 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         02 secs\n",
       "H2O cluster timezone:       America/New_York\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.20.0.8\n",
       "H2O cluster version age:    24 days\n",
       "H2O cluster name:           H2O_from_python_matt_x5dtpx\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    5.750 Gb\n",
       "H2O cluster total cores:    0\n",
       "H2O cluster allowed cores:  0\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:27968\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.3 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "port_no=random.randint(5555,55555)\n",
    "h2o.init(strict_version_check=False,min_mem_size_GB=6,port=port_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloads/pokemon_alopez247.csv\n"
     ]
    }
   ],
   "source": [
    "print(data_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "df2 = h2o.import_file(data_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  Number</th><th>Name      </th><th>Type_1  </th><th>Type_2  </th><th style=\"text-align: right;\">  Total</th><th style=\"text-align: right;\">  HP</th><th style=\"text-align: right;\">  Attack</th><th style=\"text-align: right;\">  Defense</th><th style=\"text-align: right;\">  Sp_Atk</th><th style=\"text-align: right;\">  Sp_Def</th><th style=\"text-align: right;\">  Speed</th><th style=\"text-align: right;\">  Generation</th><th>isLegendary  </th><th>Color  </th><th>hasGender  </th><th style=\"text-align: right;\">  Pr_Male</th><th>Egg_Group_1  </th><th>Egg_Group_2  </th><th>hasMegaEvolution  </th><th style=\"text-align: right;\">  Height_m</th><th style=\"text-align: right;\">  Weight_kg</th><th style=\"text-align: right;\">  Catch_Rate</th><th>Body_Style    </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td>Bulbasaur </td><td>Grass   </td><td>Poison  </td><td style=\"text-align: right;\">    318</td><td style=\"text-align: right;\">  45</td><td style=\"text-align: right;\">      49</td><td style=\"text-align: right;\">       49</td><td style=\"text-align: right;\">      65</td><td style=\"text-align: right;\">      65</td><td style=\"text-align: right;\">     45</td><td style=\"text-align: right;\">           1</td><td>False        </td><td>Green  </td><td>True       </td><td style=\"text-align: right;\">    0.875</td><td>Monster      </td><td>Grass        </td><td>False             </td><td style=\"text-align: right;\">      0.71</td><td style=\"text-align: right;\">        6.9</td><td style=\"text-align: right;\">          45</td><td>quadruped     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       2</td><td>Ivysaur   </td><td>Grass   </td><td>Poison  </td><td style=\"text-align: right;\">    405</td><td style=\"text-align: right;\">  60</td><td style=\"text-align: right;\">      62</td><td style=\"text-align: right;\">       63</td><td style=\"text-align: right;\">      80</td><td style=\"text-align: right;\">      80</td><td style=\"text-align: right;\">     60</td><td style=\"text-align: right;\">           1</td><td>False        </td><td>Green  </td><td>True       </td><td style=\"text-align: right;\">    0.875</td><td>Monster      </td><td>Grass        </td><td>False             </td><td style=\"text-align: right;\">      0.99</td><td style=\"text-align: right;\">       13  </td><td style=\"text-align: right;\">          45</td><td>quadruped     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       3</td><td>Venusaur  </td><td>Grass   </td><td>Poison  </td><td style=\"text-align: right;\">    525</td><td style=\"text-align: right;\">  80</td><td style=\"text-align: right;\">      82</td><td style=\"text-align: right;\">       83</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">     100</td><td style=\"text-align: right;\">     80</td><td style=\"text-align: right;\">           1</td><td>False        </td><td>Green  </td><td>True       </td><td style=\"text-align: right;\">    0.875</td><td>Monster      </td><td>Grass        </td><td>True              </td><td style=\"text-align: right;\">      2.01</td><td style=\"text-align: right;\">      100  </td><td style=\"text-align: right;\">          45</td><td>quadruped     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       4</td><td>Charmander</td><td>Fire    </td><td>        </td><td style=\"text-align: right;\">    309</td><td style=\"text-align: right;\">  39</td><td style=\"text-align: right;\">      52</td><td style=\"text-align: right;\">       43</td><td style=\"text-align: right;\">      60</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">     65</td><td style=\"text-align: right;\">           1</td><td>False        </td><td>Red    </td><td>True       </td><td style=\"text-align: right;\">    0.875</td><td>Monster      </td><td>Dragon       </td><td>False             </td><td style=\"text-align: right;\">      0.61</td><td style=\"text-align: right;\">        8.5</td><td style=\"text-align: right;\">          45</td><td>bipedal_tailed</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       5</td><td>Charmeleon</td><td>Fire    </td><td>        </td><td style=\"text-align: right;\">    405</td><td style=\"text-align: right;\">  58</td><td style=\"text-align: right;\">      64</td><td style=\"text-align: right;\">       58</td><td style=\"text-align: right;\">      80</td><td style=\"text-align: right;\">      65</td><td style=\"text-align: right;\">     80</td><td style=\"text-align: right;\">           1</td><td>False        </td><td>Red    </td><td>True       </td><td style=\"text-align: right;\">    0.875</td><td>Monster      </td><td>Dragon       </td><td>False             </td><td style=\"text-align: right;\">      1.09</td><td style=\"text-align: right;\">       19  </td><td style=\"text-align: right;\">          45</td><td>bipedal_tailed</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       6</td><td>Charizard </td><td>Fire    </td><td>Flying  </td><td style=\"text-align: right;\">    534</td><td style=\"text-align: right;\">  78</td><td style=\"text-align: right;\">      84</td><td style=\"text-align: right;\">       78</td><td style=\"text-align: right;\">     109</td><td style=\"text-align: right;\">      85</td><td style=\"text-align: right;\">    100</td><td style=\"text-align: right;\">           1</td><td>False        </td><td>Red    </td><td>True       </td><td style=\"text-align: right;\">    0.875</td><td>Monster      </td><td>Dragon       </td><td>True              </td><td style=\"text-align: right;\">      1.7 </td><td style=\"text-align: right;\">       90.5</td><td style=\"text-align: right;\">          45</td><td>bipedal_tailed</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       7</td><td>Squirtle  </td><td>Water   </td><td>        </td><td style=\"text-align: right;\">    314</td><td style=\"text-align: right;\">  44</td><td style=\"text-align: right;\">      48</td><td style=\"text-align: right;\">       65</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">      64</td><td style=\"text-align: right;\">     43</td><td style=\"text-align: right;\">           1</td><td>False        </td><td>Blue   </td><td>True       </td><td style=\"text-align: right;\">    0.875</td><td>Monster      </td><td>Water_1      </td><td>False             </td><td style=\"text-align: right;\">      0.51</td><td style=\"text-align: right;\">        9  </td><td style=\"text-align: right;\">          45</td><td>bipedal_tailed</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       8</td><td>Wartortle </td><td>Water   </td><td>        </td><td style=\"text-align: right;\">    405</td><td style=\"text-align: right;\">  59</td><td style=\"text-align: right;\">      63</td><td style=\"text-align: right;\">       80</td><td style=\"text-align: right;\">      65</td><td style=\"text-align: right;\">      80</td><td style=\"text-align: right;\">     58</td><td style=\"text-align: right;\">           1</td><td>False        </td><td>Blue   </td><td>True       </td><td style=\"text-align: right;\">    0.875</td><td>Monster      </td><td>Water_1      </td><td>False             </td><td style=\"text-align: right;\">      0.99</td><td style=\"text-align: right;\">       22.5</td><td style=\"text-align: right;\">          45</td><td>bipedal_tailed</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       9</td><td>Blastoise </td><td>Water   </td><td>        </td><td style=\"text-align: right;\">    530</td><td style=\"text-align: right;\">  79</td><td style=\"text-align: right;\">      83</td><td style=\"text-align: right;\">      100</td><td style=\"text-align: right;\">      85</td><td style=\"text-align: right;\">     105</td><td style=\"text-align: right;\">     78</td><td style=\"text-align: right;\">           1</td><td>False        </td><td>Blue   </td><td>True       </td><td style=\"text-align: right;\">    0.875</td><td>Monster      </td><td>Water_1      </td><td>True              </td><td style=\"text-align: right;\">      1.6 </td><td style=\"text-align: right;\">       85.5</td><td style=\"text-align: right;\">          45</td><td>bipedal_tailed</td></tr>\n",
       "<tr><td style=\"text-align: right;\">      10</td><td>Caterpie  </td><td>Bug     </td><td>        </td><td style=\"text-align: right;\">    195</td><td style=\"text-align: right;\">  45</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">       35</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">     45</td><td style=\"text-align: right;\">           1</td><td>False        </td><td>Green  </td><td>True       </td><td style=\"text-align: right;\">    0.5  </td><td>Bug          </td><td>             </td><td>False             </td><td style=\"text-align: right;\">      0.3 </td><td style=\"text-align: right;\">        2.9</td><td style=\"text-align: right;\">         255</td><td>insectoid     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:721\n",
      "Cols:23\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>Number           </th><th>Name      </th><th>Type_1  </th><th>Type_2  </th><th>Total             </th><th>HP               </th><th>Attack           </th><th>Defense           </th><th>Sp_Atk          </th><th>Sp_Def           </th><th>Speed            </th><th>Generation        </th><th>isLegendary  </th><th>Color  </th><th>hasGender  </th><th>Pr_Male            </th><th>Egg_Group_1  </th><th>Egg_Group_2  </th><th>hasMegaEvolution  </th><th>Height_m          </th><th>Weight_kg         </th><th>Catch_Rate        </th><th>Body_Style    </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>int              </td><td>string    </td><td>enum    </td><td>enum    </td><td>int               </td><td>int              </td><td>int              </td><td>int               </td><td>int             </td><td>int              </td><td>int              </td><td>int               </td><td>enum         </td><td>enum   </td><td>enum       </td><td>real               </td><td>enum         </td><td>enum         </td><td>enum              </td><td>real              </td><td>real              </td><td>int               </td><td>enum          </td></tr>\n",
       "<tr><td>mins   </td><td>1.0              </td><td>NaN       </td><td>        </td><td>        </td><td>180.0             </td><td>1.0              </td><td>5.0              </td><td>5.0               </td><td>10.0            </td><td>20.0             </td><td>5.0              </td><td>1.0               </td><td>             </td><td>       </td><td>           </td><td>0.0                </td><td>             </td><td>             </td><td>                  </td><td>0.1               </td><td>0.1               </td><td>3.0               </td><td>              </td></tr>\n",
       "<tr><td>mean   </td><td>361.0            </td><td>NaN       </td><td>        </td><td>        </td><td>417.94590846047157</td><td>68.38002773925103</td><td>75.01386962552009</td><td>70.80859916782246 </td><td>68.7378640776699</td><td>69.29126213592232</td><td>65.71428571428571</td><td>3.323162274618585 </td><td>             </td><td>       </td><td>           </td><td>0.5533773291925466 </td><td>             </td><td>             </td><td>                  </td><td>1.14497919556172  </td><td>56.773370319001394</td><td>100.24687933425797</td><td>              </td></tr>\n",
       "<tr><td>maxs   </td><td>721.0            </td><td>NaN       </td><td>        </td><td>        </td><td>720.0             </td><td>255.0            </td><td>165.0            </td><td>230.0             </td><td>154.0           </td><td>230.0            </td><td>160.0            </td><td>6.0               </td><td>             </td><td>       </td><td>           </td><td>1.0                </td><td>             </td><td>             </td><td>                  </td><td>14.5              </td><td>950.0             </td><td>255.0             </td><td>              </td></tr>\n",
       "<tr><td>sigma  </td><td>208.2790595971344</td><td>NaN       </td><td>        </td><td>        </td><td>109.66367074447545</td><td>25.84827182057517</td><td>28.98447528188689</td><td>29.296558071563616</td><td>28.7880052257176</td><td>27.01586043808999</td><td>27.27792002031901</td><td>1.6698732445299678</td><td>             </td><td>       </td><td>           </td><td>0.19996900735371828</td><td>             </td><td>             </td><td>                  </td><td>1.0443685124726578</td><td>89.09566681624158 </td><td>76.57351274971818 </td><td>              </td></tr>\n",
       "<tr><td>zeros  </td><td>0                </td><td>0         </td><td>        </td><td>        </td><td>0                 </td><td>0                </td><td>0                </td><td>0                 </td><td>0               </td><td>0                </td><td>0                </td><td>0                 </td><td>             </td><td>       </td><td>           </td><td>23                 </td><td>             </td><td>             </td><td>                  </td><td>0                 </td><td>0                 </td><td>0                 </td><td>              </td></tr>\n",
       "<tr><td>missing</td><td>0                </td><td>0         </td><td>0       </td><td>371     </td><td>0                 </td><td>0                </td><td>0                </td><td>0                 </td><td>0               </td><td>0                </td><td>0                </td><td>0                 </td><td>0            </td><td>0      </td><td>0          </td><td>77                 </td><td>0            </td><td>530          </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0             </td></tr>\n",
       "<tr><td>0      </td><td>1.0              </td><td>Bulbasaur </td><td>Grass   </td><td>Poison  </td><td>318.0             </td><td>45.0             </td><td>49.0             </td><td>49.0              </td><td>65.0            </td><td>65.0             </td><td>45.0             </td><td>1.0               </td><td>False        </td><td>Green  </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>Grass        </td><td>False             </td><td>0.71              </td><td>6.9               </td><td>45.0              </td><td>quadruped     </td></tr>\n",
       "<tr><td>1      </td><td>2.0              </td><td>Ivysaur   </td><td>Grass   </td><td>Poison  </td><td>405.0             </td><td>60.0             </td><td>62.0             </td><td>63.0              </td><td>80.0            </td><td>80.0             </td><td>60.0             </td><td>1.0               </td><td>False        </td><td>Green  </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>Grass        </td><td>False             </td><td>0.99              </td><td>13.0              </td><td>45.0              </td><td>quadruped     </td></tr>\n",
       "<tr><td>2      </td><td>3.0              </td><td>Venusaur  </td><td>Grass   </td><td>Poison  </td><td>525.0             </td><td>80.0             </td><td>82.0             </td><td>83.0              </td><td>100.0           </td><td>100.0            </td><td>80.0             </td><td>1.0               </td><td>False        </td><td>Green  </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>Grass        </td><td>True              </td><td>2.01              </td><td>100.0             </td><td>45.0              </td><td>quadruped     </td></tr>\n",
       "<tr><td>3      </td><td>4.0              </td><td>Charmander</td><td>Fire    </td><td>        </td><td>309.0             </td><td>39.0             </td><td>52.0             </td><td>43.0              </td><td>60.0            </td><td>50.0             </td><td>65.0             </td><td>1.0               </td><td>False        </td><td>Red    </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>Dragon       </td><td>False             </td><td>0.61              </td><td>8.5               </td><td>45.0              </td><td>bipedal_tailed</td></tr>\n",
       "<tr><td>4      </td><td>5.0              </td><td>Charmeleon</td><td>Fire    </td><td>        </td><td>405.0             </td><td>58.0             </td><td>64.0             </td><td>58.0              </td><td>80.0            </td><td>65.0             </td><td>80.0             </td><td>1.0               </td><td>False        </td><td>Red    </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>Dragon       </td><td>False             </td><td>1.09              </td><td>19.0              </td><td>45.0              </td><td>bipedal_tailed</td></tr>\n",
       "<tr><td>5      </td><td>6.0              </td><td>Charizard </td><td>Fire    </td><td>Flying  </td><td>534.0             </td><td>78.0             </td><td>84.0             </td><td>78.0              </td><td>109.0           </td><td>85.0             </td><td>100.0            </td><td>1.0               </td><td>False        </td><td>Red    </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>Dragon       </td><td>True              </td><td>1.7               </td><td>90.5              </td><td>45.0              </td><td>bipedal_tailed</td></tr>\n",
       "<tr><td>6      </td><td>7.0              </td><td>Squirtle  </td><td>Water   </td><td>        </td><td>314.0             </td><td>44.0             </td><td>48.0             </td><td>65.0              </td><td>50.0            </td><td>64.0             </td><td>43.0             </td><td>1.0               </td><td>False        </td><td>Blue   </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>Water_1      </td><td>False             </td><td>0.51              </td><td>9.0               </td><td>45.0              </td><td>bipedal_tailed</td></tr>\n",
       "<tr><td>7      </td><td>8.0              </td><td>Wartortle </td><td>Water   </td><td>        </td><td>405.0             </td><td>59.0             </td><td>63.0             </td><td>80.0              </td><td>65.0            </td><td>80.0             </td><td>58.0             </td><td>1.0               </td><td>False        </td><td>Blue   </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>Water_1      </td><td>False             </td><td>0.99              </td><td>22.5              </td><td>45.0              </td><td>bipedal_tailed</td></tr>\n",
       "<tr><td>8      </td><td>9.0              </td><td>Blastoise </td><td>Water   </td><td>        </td><td>530.0             </td><td>79.0             </td><td>83.0             </td><td>100.0             </td><td>85.0            </td><td>105.0            </td><td>78.0             </td><td>1.0               </td><td>False        </td><td>Blue   </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>Water_1      </td><td>True              </td><td>1.6               </td><td>85.5              </td><td>45.0              </td><td>bipedal_tailed</td></tr>\n",
       "<tr><td>9      </td><td>10.0             </td><td>Caterpie  </td><td>Bug     </td><td>        </td><td>195.0             </td><td>45.0             </td><td>30.0             </td><td>35.0              </td><td>20.0            </td><td>20.0             </td><td>45.0             </td><td>1.0               </td><td>False        </td><td>Green  </td><td>True       </td><td>0.5                </td><td>Bug          </td><td>             </td><td>False             </td><td>0.3               </td><td>2.9               </td><td>255.0             </td><td>insectoid     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df2.drop(['Number','Type_2','Egg_Group_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:721\n",
      "Cols:20\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>Name      </th><th>Type_1  </th><th>Total             </th><th>HP               </th><th>Attack           </th><th>Defense           </th><th>Sp_Atk          </th><th>Sp_Def           </th><th>Speed            </th><th>Generation        </th><th>isLegendary  </th><th>Color  </th><th>hasGender  </th><th>Pr_Male            </th><th>Egg_Group_1  </th><th>hasMegaEvolution  </th><th>Height_m          </th><th>Weight_kg         </th><th>Catch_Rate        </th><th>Body_Style    </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>string    </td><td>enum    </td><td>int               </td><td>int              </td><td>int              </td><td>int               </td><td>int             </td><td>int              </td><td>int              </td><td>int               </td><td>enum         </td><td>enum   </td><td>enum       </td><td>real               </td><td>enum         </td><td>enum              </td><td>real              </td><td>real              </td><td>int               </td><td>enum          </td></tr>\n",
       "<tr><td>mins   </td><td>NaN       </td><td>        </td><td>180.0             </td><td>1.0              </td><td>5.0              </td><td>5.0               </td><td>10.0            </td><td>20.0             </td><td>5.0              </td><td>1.0               </td><td>             </td><td>       </td><td>           </td><td>0.0                </td><td>             </td><td>                  </td><td>0.1               </td><td>0.1               </td><td>3.0               </td><td>              </td></tr>\n",
       "<tr><td>mean   </td><td>NaN       </td><td>        </td><td>417.94590846047157</td><td>68.38002773925103</td><td>75.01386962552009</td><td>70.80859916782246 </td><td>68.7378640776699</td><td>69.29126213592232</td><td>65.71428571428571</td><td>3.323162274618585 </td><td>             </td><td>       </td><td>           </td><td>0.5533773291925466 </td><td>             </td><td>                  </td><td>1.14497919556172  </td><td>56.773370319001394</td><td>100.24687933425797</td><td>              </td></tr>\n",
       "<tr><td>maxs   </td><td>NaN       </td><td>        </td><td>720.0             </td><td>255.0            </td><td>165.0            </td><td>230.0             </td><td>154.0           </td><td>230.0            </td><td>160.0            </td><td>6.0               </td><td>             </td><td>       </td><td>           </td><td>1.0                </td><td>             </td><td>                  </td><td>14.5              </td><td>950.0             </td><td>255.0             </td><td>              </td></tr>\n",
       "<tr><td>sigma  </td><td>NaN       </td><td>        </td><td>109.66367074447545</td><td>25.84827182057517</td><td>28.98447528188689</td><td>29.296558071563616</td><td>28.7880052257176</td><td>27.01586043808999</td><td>27.27792002031901</td><td>1.6698732445299678</td><td>             </td><td>       </td><td>           </td><td>0.19996900735371828</td><td>             </td><td>                  </td><td>1.0443685124726578</td><td>89.09566681624158 </td><td>76.57351274971818 </td><td>              </td></tr>\n",
       "<tr><td>zeros  </td><td>0         </td><td>        </td><td>0                 </td><td>0                </td><td>0                </td><td>0                 </td><td>0               </td><td>0                </td><td>0                </td><td>0                 </td><td>             </td><td>       </td><td>           </td><td>23                 </td><td>             </td><td>                  </td><td>0                 </td><td>0                 </td><td>0                 </td><td>              </td></tr>\n",
       "<tr><td>missing</td><td>0         </td><td>0       </td><td>0                 </td><td>0                </td><td>0                </td><td>0                 </td><td>0               </td><td>0                </td><td>0                </td><td>0                 </td><td>0            </td><td>0      </td><td>0          </td><td>77                 </td><td>0            </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0             </td></tr>\n",
       "<tr><td>0      </td><td>Bulbasaur </td><td>Grass   </td><td>318.0             </td><td>45.0             </td><td>49.0             </td><td>49.0              </td><td>65.0            </td><td>65.0             </td><td>45.0             </td><td>1.0               </td><td>False        </td><td>Green  </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>False             </td><td>0.71              </td><td>6.9               </td><td>45.0              </td><td>quadruped     </td></tr>\n",
       "<tr><td>1      </td><td>Ivysaur   </td><td>Grass   </td><td>405.0             </td><td>60.0             </td><td>62.0             </td><td>63.0              </td><td>80.0            </td><td>80.0             </td><td>60.0             </td><td>1.0               </td><td>False        </td><td>Green  </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>False             </td><td>0.99              </td><td>13.0              </td><td>45.0              </td><td>quadruped     </td></tr>\n",
       "<tr><td>2      </td><td>Venusaur  </td><td>Grass   </td><td>525.0             </td><td>80.0             </td><td>82.0             </td><td>83.0              </td><td>100.0           </td><td>100.0            </td><td>80.0             </td><td>1.0               </td><td>False        </td><td>Green  </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>True              </td><td>2.01              </td><td>100.0             </td><td>45.0              </td><td>quadruped     </td></tr>\n",
       "<tr><td>3      </td><td>Charmander</td><td>Fire    </td><td>309.0             </td><td>39.0             </td><td>52.0             </td><td>43.0              </td><td>60.0            </td><td>50.0             </td><td>65.0             </td><td>1.0               </td><td>False        </td><td>Red    </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>False             </td><td>0.61              </td><td>8.5               </td><td>45.0              </td><td>bipedal_tailed</td></tr>\n",
       "<tr><td>4      </td><td>Charmeleon</td><td>Fire    </td><td>405.0             </td><td>58.0             </td><td>64.0             </td><td>58.0              </td><td>80.0            </td><td>65.0             </td><td>80.0             </td><td>1.0               </td><td>False        </td><td>Red    </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>False             </td><td>1.09              </td><td>19.0              </td><td>45.0              </td><td>bipedal_tailed</td></tr>\n",
       "<tr><td>5      </td><td>Charizard </td><td>Fire    </td><td>534.0             </td><td>78.0             </td><td>84.0             </td><td>78.0              </td><td>109.0           </td><td>85.0             </td><td>100.0            </td><td>1.0               </td><td>False        </td><td>Red    </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>True              </td><td>1.7               </td><td>90.5              </td><td>45.0              </td><td>bipedal_tailed</td></tr>\n",
       "<tr><td>6      </td><td>Squirtle  </td><td>Water   </td><td>314.0             </td><td>44.0             </td><td>48.0             </td><td>65.0              </td><td>50.0            </td><td>64.0             </td><td>43.0             </td><td>1.0               </td><td>False        </td><td>Blue   </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>False             </td><td>0.51              </td><td>9.0               </td><td>45.0              </td><td>bipedal_tailed</td></tr>\n",
       "<tr><td>7      </td><td>Wartortle </td><td>Water   </td><td>405.0             </td><td>59.0             </td><td>63.0             </td><td>80.0              </td><td>65.0            </td><td>80.0             </td><td>58.0             </td><td>1.0               </td><td>False        </td><td>Blue   </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>False             </td><td>0.99              </td><td>22.5              </td><td>45.0              </td><td>bipedal_tailed</td></tr>\n",
       "<tr><td>8      </td><td>Blastoise </td><td>Water   </td><td>530.0             </td><td>79.0             </td><td>83.0             </td><td>100.0             </td><td>85.0            </td><td>105.0            </td><td>78.0             </td><td>1.0               </td><td>False        </td><td>Blue   </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>True              </td><td>1.6               </td><td>85.5              </td><td>45.0              </td><td>bipedal_tailed</td></tr>\n",
       "<tr><td>9      </td><td>Caterpie  </td><td>Bug     </td><td>195.0             </td><td>45.0             </td><td>30.0             </td><td>35.0              </td><td>20.0            </td><td>20.0             </td><td>45.0             </td><td>1.0               </td><td>False        </td><td>Green  </td><td>True       </td><td>0.5                </td><td>Bug          </td><td>False             </td><td>0.3               </td><td>2.9               </td><td>255.0             </td><td>insectoid     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.5533773291925466,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.impute('Pr_Male',method = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:721\n",
      "Cols:20\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>Name      </th><th>Type_1  </th><th>Total             </th><th>HP               </th><th>Attack           </th><th>Defense           </th><th>Sp_Atk          </th><th>Sp_Def           </th><th>Speed            </th><th>Generation        </th><th>isLegendary  </th><th>Color  </th><th>hasGender  </th><th>Pr_Male            </th><th>Egg_Group_1  </th><th>hasMegaEvolution  </th><th>Height_m          </th><th>Weight_kg         </th><th>Catch_Rate        </th><th>Body_Style    </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>string    </td><td>enum    </td><td>int               </td><td>int              </td><td>int              </td><td>int               </td><td>int             </td><td>int              </td><td>int              </td><td>int               </td><td>enum         </td><td>enum   </td><td>enum       </td><td>real               </td><td>enum         </td><td>enum              </td><td>real              </td><td>real              </td><td>int               </td><td>enum          </td></tr>\n",
       "<tr><td>mins   </td><td>NaN       </td><td>        </td><td>180.0             </td><td>1.0              </td><td>5.0              </td><td>5.0               </td><td>10.0            </td><td>20.0             </td><td>5.0              </td><td>1.0               </td><td>             </td><td>       </td><td>           </td><td>0.0                </td><td>             </td><td>                  </td><td>0.1               </td><td>0.1               </td><td>3.0               </td><td>              </td></tr>\n",
       "<tr><td>mean   </td><td>NaN       </td><td>        </td><td>417.94590846047157</td><td>68.38002773925103</td><td>75.01386962552009</td><td>70.80859916782246 </td><td>68.7378640776699</td><td>69.29126213592232</td><td>65.71428571428571</td><td>3.323162274618585 </td><td>             </td><td>       </td><td>           </td><td>0.5533773291925467 </td><td>             </td><td>                  </td><td>1.14497919556172  </td><td>56.773370319001394</td><td>100.24687933425797</td><td>              </td></tr>\n",
       "<tr><td>maxs   </td><td>NaN       </td><td>        </td><td>720.0             </td><td>255.0            </td><td>165.0            </td><td>230.0             </td><td>154.0           </td><td>230.0            </td><td>160.0            </td><td>6.0               </td><td>             </td><td>       </td><td>           </td><td>1.0                </td><td>             </td><td>                  </td><td>14.5              </td><td>950.0             </td><td>255.0             </td><td>              </td></tr>\n",
       "<tr><td>sigma  </td><td>NaN       </td><td>        </td><td>109.66367074447545</td><td>25.84827182057517</td><td>28.98447528188689</td><td>29.296558071563616</td><td>28.7880052257176</td><td>27.01586043808999</td><td>27.27792002031901</td><td>1.6698732445299678</td><td>             </td><td>       </td><td>           </td><td>0.18897394481267568</td><td>             </td><td>                  </td><td>1.0443685124726578</td><td>89.09566681624158 </td><td>76.57351274971818 </td><td>              </td></tr>\n",
       "<tr><td>zeros  </td><td>0         </td><td>        </td><td>0                 </td><td>0                </td><td>0                </td><td>0                 </td><td>0               </td><td>0                </td><td>0                </td><td>0                 </td><td>             </td><td>       </td><td>           </td><td>23                 </td><td>             </td><td>                  </td><td>0                 </td><td>0                 </td><td>0                 </td><td>              </td></tr>\n",
       "<tr><td>missing</td><td>0         </td><td>0       </td><td>0                 </td><td>0                </td><td>0                </td><td>0                 </td><td>0               </td><td>0                </td><td>0                </td><td>0                 </td><td>0            </td><td>0      </td><td>0          </td><td>0                  </td><td>0            </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0             </td></tr>\n",
       "<tr><td>0      </td><td>Bulbasaur </td><td>Grass   </td><td>318.0             </td><td>45.0             </td><td>49.0             </td><td>49.0              </td><td>65.0            </td><td>65.0             </td><td>45.0             </td><td>1.0               </td><td>False        </td><td>Green  </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>False             </td><td>0.71              </td><td>6.9               </td><td>45.0              </td><td>quadruped     </td></tr>\n",
       "<tr><td>1      </td><td>Ivysaur   </td><td>Grass   </td><td>405.0             </td><td>60.0             </td><td>62.0             </td><td>63.0              </td><td>80.0            </td><td>80.0             </td><td>60.0             </td><td>1.0               </td><td>False        </td><td>Green  </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>False             </td><td>0.99              </td><td>13.0              </td><td>45.0              </td><td>quadruped     </td></tr>\n",
       "<tr><td>2      </td><td>Venusaur  </td><td>Grass   </td><td>525.0             </td><td>80.0             </td><td>82.0             </td><td>83.0              </td><td>100.0           </td><td>100.0            </td><td>80.0             </td><td>1.0               </td><td>False        </td><td>Green  </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>True              </td><td>2.01              </td><td>100.0             </td><td>45.0              </td><td>quadruped     </td></tr>\n",
       "<tr><td>3      </td><td>Charmander</td><td>Fire    </td><td>309.0             </td><td>39.0             </td><td>52.0             </td><td>43.0              </td><td>60.0            </td><td>50.0             </td><td>65.0             </td><td>1.0               </td><td>False        </td><td>Red    </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>False             </td><td>0.61              </td><td>8.5               </td><td>45.0              </td><td>bipedal_tailed</td></tr>\n",
       "<tr><td>4      </td><td>Charmeleon</td><td>Fire    </td><td>405.0             </td><td>58.0             </td><td>64.0             </td><td>58.0              </td><td>80.0            </td><td>65.0             </td><td>80.0             </td><td>1.0               </td><td>False        </td><td>Red    </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>False             </td><td>1.09              </td><td>19.0              </td><td>45.0              </td><td>bipedal_tailed</td></tr>\n",
       "<tr><td>5      </td><td>Charizard </td><td>Fire    </td><td>534.0             </td><td>78.0             </td><td>84.0             </td><td>78.0              </td><td>109.0           </td><td>85.0             </td><td>100.0            </td><td>1.0               </td><td>False        </td><td>Red    </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>True              </td><td>1.7               </td><td>90.5              </td><td>45.0              </td><td>bipedal_tailed</td></tr>\n",
       "<tr><td>6      </td><td>Squirtle  </td><td>Water   </td><td>314.0             </td><td>44.0             </td><td>48.0             </td><td>65.0              </td><td>50.0            </td><td>64.0             </td><td>43.0             </td><td>1.0               </td><td>False        </td><td>Blue   </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>False             </td><td>0.51              </td><td>9.0               </td><td>45.0              </td><td>bipedal_tailed</td></tr>\n",
       "<tr><td>7      </td><td>Wartortle </td><td>Water   </td><td>405.0             </td><td>59.0             </td><td>63.0             </td><td>80.0              </td><td>65.0            </td><td>80.0             </td><td>58.0             </td><td>1.0               </td><td>False        </td><td>Blue   </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>False             </td><td>0.99              </td><td>22.5              </td><td>45.0              </td><td>bipedal_tailed</td></tr>\n",
       "<tr><td>8      </td><td>Blastoise </td><td>Water   </td><td>530.0             </td><td>79.0             </td><td>83.0             </td><td>100.0             </td><td>85.0            </td><td>105.0            </td><td>78.0             </td><td>1.0               </td><td>False        </td><td>Blue   </td><td>True       </td><td>0.875              </td><td>Monster      </td><td>True              </td><td>1.6               </td><td>85.5              </td><td>45.0              </td><td>bipedal_tailed</td></tr>\n",
       "<tr><td>9      </td><td>Caterpie  </td><td>Bug     </td><td>195.0             </td><td>45.0             </td><td>30.0             </td><td>35.0              </td><td>20.0            </td><td>20.0             </td><td>45.0             </td><td>1.0               </td><td>False        </td><td>Green  </td><td>True       </td><td>0.5                </td><td>Bug          </td><td>False             </td><td>0.3               </td><td>2.9               </td><td>255.0             </td><td>insectoid     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y='isLegendary'\n",
    "X=df2.columns\n",
    "X.remove(y)\n",
    "X.remove('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Type_1', 'Total', 'HP', 'Attack', 'Defense', 'Sp_Atk', 'Sp_Def', 'Speed', 'Generation', 'Color', 'hasGender', 'Pr_Male', 'Egg_Group_1', 'hasMegaEvolution', 'Height_m', 'Weight_kg', 'Catch_Rate', 'Body_Style']\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = df2.split_frame([0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "glm_model2 = H2OGeneralizedLinearEstimator(family= \"binomial\",nfolds=5)\n",
    "glm_model2.train(x=X, y=y, training_frame= train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGeneralizedLinearEstimator :  Generalized Linear Modeling\n",
      "Model Key:  GLM_model_python_1539652770571_1\n",
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: glm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.01628834921238369\n",
      "RMSE: 0.12762581718595847\n",
      "LogLoss: 0.06505582896315794\n",
      "Null degrees of freedom: 650\n",
      "Residual degrees of freedom: 639\n",
      "Null deviance: 306.0867169416284\n",
      "Residual deviance: 84.70268931003163\n",
      "AIC: 108.70268931003163\n",
      "AUC: 0.9973610555777689\n",
      "Gini: 0.9947221111555378\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3345862989359517: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>False</b></td>\n",
       "<td><b>True</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>False</td>\n",
       "<td>605.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0082</td>\n",
       "<td> (5.0/610.0)</td></tr>\n",
       "<tr><td>True</td>\n",
       "<td>0.0</td>\n",
       "<td>41.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/41.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>605.0</td>\n",
       "<td>46.0</td>\n",
       "<td>0.0077</td>\n",
       "<td> (5.0/651.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       False    True    Error    Rate\n",
       "-----  -------  ------  -------  -----------\n",
       "False  605      5       0.0082   (5.0/610.0)\n",
       "True   0        41      0        (0.0/41.0)\n",
       "Total  605      46      0.0077   (5.0/651.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3345863</td>\n",
       "<td>0.9425287</td>\n",
       "<td>45.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3345863</td>\n",
       "<td>0.9761905</td>\n",
       "<td>45.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3345863</td>\n",
       "<td>0.9111111</td>\n",
       "<td>45.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3345863</td>\n",
       "<td>0.9923195</td>\n",
       "<td>45.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9364321</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.3345863</td>\n",
       "<td>1.0</td>\n",
       "<td>45.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9364321</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3345863</td>\n",
       "<td>0.9402120</td>\n",
       "<td>45.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3345863</td>\n",
       "<td>0.9918033</td>\n",
       "<td>45.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3345863</td>\n",
       "<td>0.9959016</td>\n",
       "<td>45.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.334586     0.942529  45\n",
       "max f2                       0.334586     0.97619   45\n",
       "max f0point5                 0.334586     0.911111  45\n",
       "max accuracy                 0.334586     0.99232   45\n",
       "max precision                0.936432     1         0\n",
       "max recall                   0.334586     1         45\n",
       "max specificity              0.936432     1         0\n",
       "max absolute_mcc             0.334586     0.940212  45\n",
       "max min_per_class_accuracy   0.334586     0.991803  45\n",
       "max mean_per_class_accuracy  0.334586     0.995902  45"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  6.30 %, avg score:  6.30 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0107527</td>\n",
       "<td>0.8067554</td>\n",
       "<td>15.8780488</td>\n",
       "<td>15.8780488</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8730709</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8730709</td>\n",
       "<td>0.1707317</td>\n",
       "<td>0.1707317</td>\n",
       "<td>1487.8048780</td>\n",
       "<td>1487.8048780</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0215054</td>\n",
       "<td>0.6253772</td>\n",
       "<td>15.8780488</td>\n",
       "<td>15.8780488</td>\n",
       "<td>1.0</td>\n",
       "<td>0.7503178</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8116944</td>\n",
       "<td>0.1707317</td>\n",
       "<td>0.3414634</td>\n",
       "<td>1487.8048780</td>\n",
       "<td>1487.8048780</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0307220</td>\n",
       "<td>0.5519000</td>\n",
       "<td>15.8780488</td>\n",
       "<td>15.8780488</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5845586</td>\n",
       "<td>1.0</td>\n",
       "<td>0.7435536</td>\n",
       "<td>0.1463415</td>\n",
       "<td>0.4878049</td>\n",
       "<td>1487.8048780</td>\n",
       "<td>1487.8048780</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0414747</td>\n",
       "<td>0.4906044</td>\n",
       "<td>11.3414634</td>\n",
       "<td>14.7018970</td>\n",
       "<td>0.7142857</td>\n",
       "<td>0.5225900</td>\n",
       "<td>0.9259259</td>\n",
       "<td>0.6862668</td>\n",
       "<td>0.1219512</td>\n",
       "<td>0.6097561</td>\n",
       "<td>1034.1463415</td>\n",
       "<td>1370.1897019</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0506912</td>\n",
       "<td>0.4381112</td>\n",
       "<td>13.2317073</td>\n",
       "<td>14.4345898</td>\n",
       "<td>0.8333333</td>\n",
       "<td>0.4625297</td>\n",
       "<td>0.9090909</td>\n",
       "<td>0.6455873</td>\n",
       "<td>0.1219512</td>\n",
       "<td>0.7317073</td>\n",
       "<td>1223.1707317</td>\n",
       "<td>1343.4589800</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1013825</td>\n",
       "<td>0.0999496</td>\n",
       "<td>5.2926829</td>\n",
       "<td>9.8636364</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.2488677</td>\n",
       "<td>0.6212121</td>\n",
       "<td>0.4472275</td>\n",
       "<td>0.2682927</td>\n",
       "<td>1.0</td>\n",
       "<td>429.2682927</td>\n",
       "<td>886.3636364</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1505376</td>\n",
       "<td>0.0682224</td>\n",
       "<td>0.0</td>\n",
       "<td>6.6428571</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0822811</td>\n",
       "<td>0.4183673</td>\n",
       "<td>0.3280613</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>564.2857143</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2012289</td>\n",
       "<td>0.0515971</td>\n",
       "<td>0.0</td>\n",
       "<td>4.9694656</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0594103</td>\n",
       "<td>0.3129771</td>\n",
       "<td>0.2603859</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>396.9465649</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3010753</td>\n",
       "<td>0.0332791</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3214286</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0409916</td>\n",
       "<td>0.2091837</td>\n",
       "<td>0.1876276</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>232.1428571</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4009217</td>\n",
       "<td>0.0217644</td>\n",
       "<td>0.0</td>\n",
       "<td>2.4942529</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0272852</td>\n",
       "<td>0.1570881</td>\n",
       "<td>0.1476956</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>149.4252874</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5007680</td>\n",
       "<td>0.0129658</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9969325</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0173792</td>\n",
       "<td>0.1257669</td>\n",
       "<td>0.1217122</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>99.6932515</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6006144</td>\n",
       "<td>0.0076199</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6649616</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0103865</td>\n",
       "<td>0.1048593</td>\n",
       "<td>0.1032054</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.4961637</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7004608</td>\n",
       "<td>0.0034727</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4276316</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0051540</td>\n",
       "<td>0.0899123</td>\n",
       "<td>0.0892288</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.7631579</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8003072</td>\n",
       "<td>0.0020584</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2495202</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0026208</td>\n",
       "<td>0.0786948</td>\n",
       "<td>0.0784236</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.9520154</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9001536</td>\n",
       "<td>0.0011111</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1109215</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0015276</td>\n",
       "<td>0.0699659</td>\n",
       "<td>0.0698941</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.0921502</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0002142</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0006462</td>\n",
       "<td>0.0629800</td>\n",
       "<td>0.0629800</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0107527                   0.806755           15.878   15.878             1                0.873071     1                           0.873071            0.170732        0.170732                   1487.8   1487.8\n",
       "    2        0.0215054                   0.625377           15.878   15.878             1                0.750318     1                           0.811694            0.170732        0.341463                   1487.8   1487.8\n",
       "    3        0.030722                    0.5519             15.878   15.878             1                0.584559     1                           0.743554            0.146341        0.487805                   1487.8   1487.8\n",
       "    4        0.0414747                   0.490604           11.3415  14.7019            0.714286         0.52259      0.925926                    0.686267            0.121951        0.609756                   1034.15  1370.19\n",
       "    5        0.0506912                   0.438111           13.2317  14.4346            0.833333         0.46253      0.909091                    0.645587            0.121951        0.731707                   1223.17  1343.46\n",
       "    6        0.101382                    0.0999496          5.29268  9.86364            0.333333         0.248868     0.621212                    0.447227            0.268293        1                          429.268  886.364\n",
       "    7        0.150538                    0.0682224          0        6.64286            0                0.0822811    0.418367                    0.328061            0               1                          -100     564.286\n",
       "    8        0.201229                    0.0515971          0        4.96947            0                0.0594103    0.312977                    0.260386            0               1                          -100     396.947\n",
       "    9        0.301075                    0.0332791          0        3.32143            0                0.0409916    0.209184                    0.187628            0               1                          -100     232.143\n",
       "    10       0.400922                    0.0217644          0        2.49425            0                0.0272852    0.157088                    0.147696            0               1                          -100     149.425\n",
       "    11       0.500768                    0.0129658          0        1.99693            0                0.0173792    0.125767                    0.121712            0               1                          -100     99.6933\n",
       "    12       0.600614                    0.00761988         0        1.66496            0                0.0103865    0.104859                    0.103205            0               1                          -100     66.4962\n",
       "    13       0.700461                    0.00347271         0        1.42763            0                0.005154     0.0899123                   0.0892288           0               1                          -100     42.7632\n",
       "    14       0.800307                    0.00205837         0        1.24952            0                0.00262085   0.0786948                   0.0784236           0               1                          -100     24.952\n",
       "    15       0.900154                    0.00111109         0        1.11092            0                0.00152757   0.0699659                   0.0698941           0               1                          -100     11.0922\n",
       "    16       1                           0.000214249        0        1                  0                0.000646245  0.06298                     0.06298             0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: glm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.020899871502994806\n",
      "RMSE: 0.14456787853114123\n",
      "LogLoss: 0.0784703282864102\n",
      "Null degrees of freedom: 650\n",
      "Residual degrees of freedom: 640\n",
      "Null deviance: 306.88174241204695\n",
      "Residual deviance: 102.16836742890607\n",
      "AIC: 124.16836742890607\n",
      "AUC: 0.9960015993602558\n",
      "Gini: 0.9920031987205116\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2372595613447828: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>False</b></td>\n",
       "<td><b>True</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>False</td>\n",
       "<td>603.0</td>\n",
       "<td>7.0</td>\n",
       "<td>0.0115</td>\n",
       "<td> (7.0/610.0)</td></tr>\n",
       "<tr><td>True</td>\n",
       "<td>0.0</td>\n",
       "<td>41.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/41.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>603.0</td>\n",
       "<td>48.0</td>\n",
       "<td>0.0108</td>\n",
       "<td> (7.0/651.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       False    True    Error    Rate\n",
       "-----  -------  ------  -------  -----------\n",
       "False  603      7       0.0115   (7.0/610.0)\n",
       "True   0        41      0        (0.0/41.0)\n",
       "Total  603      48      0.0108   (7.0/651.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.2372596</td>\n",
       "<td>0.9213483</td>\n",
       "<td>46.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2372596</td>\n",
       "<td>0.9669811</td>\n",
       "<td>46.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3276944</td>\n",
       "<td>0.8883249</td>\n",
       "<td>37.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.2372596</td>\n",
       "<td>0.9892473</td>\n",
       "<td>46.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9421406</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.2372596</td>\n",
       "<td>1.0</td>\n",
       "<td>46.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9421406</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2372596</td>\n",
       "<td>0.9188932</td>\n",
       "<td>46.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2372596</td>\n",
       "<td>0.9885246</td>\n",
       "<td>46.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2372596</td>\n",
       "<td>0.9942623</td>\n",
       "<td>46.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.23726      0.921348  46\n",
       "max f2                       0.23726      0.966981  46\n",
       "max f0point5                 0.327694     0.888325  37\n",
       "max accuracy                 0.23726      0.989247  46\n",
       "max precision                0.942141     1         0\n",
       "max recall                   0.23726      1         46\n",
       "max specificity              0.942141     1         0\n",
       "max absolute_mcc             0.23726      0.918893  46\n",
       "max min_per_class_accuracy   0.23726      0.988525  46\n",
       "max mean_per_class_accuracy  0.23726      0.994262  46"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  6.30 %, avg score:  6.24 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0107527</td>\n",
       "<td>0.7503071</td>\n",
       "<td>15.8780488</td>\n",
       "<td>15.8780488</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8500308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8500308</td>\n",
       "<td>0.1707317</td>\n",
       "<td>0.1707317</td>\n",
       "<td>1487.8048780</td>\n",
       "<td>1487.8048780</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0215054</td>\n",
       "<td>0.5842161</td>\n",
       "<td>15.8780488</td>\n",
       "<td>15.8780488</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6749063</td>\n",
       "<td>1.0</td>\n",
       "<td>0.7624686</td>\n",
       "<td>0.1707317</td>\n",
       "<td>0.3414634</td>\n",
       "<td>1487.8048780</td>\n",
       "<td>1487.8048780</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0307220</td>\n",
       "<td>0.4951418</td>\n",
       "<td>7.9390244</td>\n",
       "<td>13.4963415</td>\n",
       "<td>0.5</td>\n",
       "<td>0.5281755</td>\n",
       "<td>0.85</td>\n",
       "<td>0.6921806</td>\n",
       "<td>0.0731707</td>\n",
       "<td>0.4146341</td>\n",
       "<td>693.9024390</td>\n",
       "<td>1249.6341463</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0414747</td>\n",
       "<td>0.4375437</td>\n",
       "<td>15.8780488</td>\n",
       "<td>14.1138211</td>\n",
       "<td>1.0</td>\n",
       "<td>0.4606050</td>\n",
       "<td>0.8888889</td>\n",
       "<td>0.6321425</td>\n",
       "<td>0.1707317</td>\n",
       "<td>0.5853659</td>\n",
       "<td>1487.8048780</td>\n",
       "<td>1311.3821138</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0506912</td>\n",
       "<td>0.3693618</td>\n",
       "<td>13.2317073</td>\n",
       "<td>13.9534368</td>\n",
       "<td>0.8333333</td>\n",
       "<td>0.3884497</td>\n",
       "<td>0.8787879</td>\n",
       "<td>0.5878347</td>\n",
       "<td>0.1219512</td>\n",
       "<td>0.7073171</td>\n",
       "<td>1223.1707317</td>\n",
       "<td>1295.3436807</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1013825</td>\n",
       "<td>0.1155496</td>\n",
       "<td>5.7738359</td>\n",
       "<td>9.8636364</td>\n",
       "<td>0.3636364</td>\n",
       "<td>0.2258789</td>\n",
       "<td>0.6212121</td>\n",
       "<td>0.4068568</td>\n",
       "<td>0.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>477.3835920</td>\n",
       "<td>886.3636364</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1505376</td>\n",
       "<td>0.0832578</td>\n",
       "<td>0.0</td>\n",
       "<td>6.6428571</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0944903</td>\n",
       "<td>0.4183673</td>\n",
       "<td>0.3048596</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>564.2857143</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2012289</td>\n",
       "<td>0.0606251</td>\n",
       "<td>0.0</td>\n",
       "<td>4.9694656</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0679849</td>\n",
       "<td>0.3129771</td>\n",
       "<td>0.2451889</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>396.9465649</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3010753</td>\n",
       "<td>0.0400490</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3214286</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0494631</td>\n",
       "<td>0.2091837</td>\n",
       "<td>0.1802798</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>232.1428571</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4009217</td>\n",
       "<td>0.0259279</td>\n",
       "<td>0.0</td>\n",
       "<td>2.4942529</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0325715</td>\n",
       "<td>0.1570881</td>\n",
       "<td>0.1434942</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>149.4252874</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5007680</td>\n",
       "<td>0.0165659</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9969325</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0211885</td>\n",
       "<td>0.1257669</td>\n",
       "<td>0.1191081</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>99.6932515</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6006144</td>\n",
       "<td>0.0106072</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6649616</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0134847</td>\n",
       "<td>0.1048593</td>\n",
       "<td>0.1015492</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.4961637</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7004608</td>\n",
       "<td>0.0048787</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4276316</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0070338</td>\n",
       "<td>0.0899123</td>\n",
       "<td>0.0880767</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.7631579</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8003072</td>\n",
       "<td>0.0030435</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2495202</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0038564</td>\n",
       "<td>0.0786948</td>\n",
       "<td>0.0775693</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.9520154</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9001536</td>\n",
       "<td>0.0017186</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1109215</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0023704</td>\n",
       "<td>0.0699659</td>\n",
       "<td>0.0692282</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.0921502</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0003608</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0010701</td>\n",
       "<td>0.0629800</td>\n",
       "<td>0.0624228</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0107527                   0.750307           15.878   15.878             1                0.850031    1                           0.850031            0.170732        0.170732                   1487.8   1487.8\n",
       "    2        0.0215054                   0.584216           15.878   15.878             1                0.674906    1                           0.762469            0.170732        0.341463                   1487.8   1487.8\n",
       "    3        0.030722                    0.495142           7.93902  13.4963            0.5              0.528176    0.85                        0.692181            0.0731707       0.414634                   693.902  1249.63\n",
       "    4        0.0414747                   0.437544           15.878   14.1138            1                0.460605    0.888889                    0.632143            0.170732        0.585366                   1487.8   1311.38\n",
       "    5        0.0506912                   0.369362           13.2317  13.9534            0.833333         0.38845     0.878788                    0.587835            0.121951        0.707317                   1223.17  1295.34\n",
       "    6        0.101382                    0.11555            5.77384  9.86364            0.363636         0.225879    0.621212                    0.406857            0.292683        1                          477.384  886.364\n",
       "    7        0.150538                    0.0832578          0        6.64286            0                0.0944903   0.418367                    0.30486             0               1                          -100     564.286\n",
       "    8        0.201229                    0.0606251          0        4.96947            0                0.0679849   0.312977                    0.245189            0               1                          -100     396.947\n",
       "    9        0.301075                    0.040049           0        3.32143            0                0.0494631   0.209184                    0.18028             0               1                          -100     232.143\n",
       "    10       0.400922                    0.0259279          0        2.49425            0                0.0325715   0.157088                    0.143494            0               1                          -100     149.425\n",
       "    11       0.500768                    0.0165659          0        1.99693            0                0.0211885   0.125767                    0.119108            0               1                          -100     99.6933\n",
       "    12       0.600614                    0.0106072          0        1.66496            0                0.0134847   0.104859                    0.101549            0               1                          -100     66.4962\n",
       "    13       0.700461                    0.00487867         0        1.42763            0                0.00703382  0.0899123                   0.0880767           0               1                          -100     42.7632\n",
       "    14       0.800307                    0.00304352         0        1.24952            0                0.00385637  0.0786948                   0.0775693           0               1                          -100     24.952\n",
       "    15       0.900154                    0.00171862         0        1.11092            0                0.00237043  0.0699659                   0.0692282           0               1                          -100     11.0922\n",
       "    16       1                           0.000360754        0        1                  0                0.0010701   0.06298                     0.0624228           0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9925371</td>\n",
       "<td>0.0033375</td>\n",
       "<td>0.9925373</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9924812</td>\n",
       "<td>0.9850746</td>\n",
       "<td>0.9925926</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9966966</td>\n",
       "<td>0.0018632</td>\n",
       "<td>0.9991935</td>\n",
       "<td>1.0</td>\n",
       "<td>0.994</td>\n",
       "<td>0.9934896</td>\n",
       "<td>0.9968</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0074629</td>\n",
       "<td>0.0033375</td>\n",
       "<td>0.0074627</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0075188</td>\n",
       "<td>0.0149254</td>\n",
       "<td>0.0074074</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>1.0</td>\n",
       "<td>0.4472136</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9340067</td>\n",
       "<td>0.0239318</td>\n",
       "<td>0.9259259</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9090909</td>\n",
       "<td>0.9090909</td>\n",
       "<td>0.9259259</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.6469798</td>\n",
       "<td>0.0435369</td>\n",
       "<td>0.7307851</td>\n",
       "<td>0.6708993</td>\n",
       "<td>0.5813249</td>\n",
       "<td>0.6814589</td>\n",
       "<td>0.5704308</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9333333</td>\n",
       "<td>0.0942809</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6666667</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>residual_deviance</td>\n",
       "<td>20.433674</td>\n",
       "<td>2.6691458</td>\n",
       "<td>19.382088</td>\n",
       "<td>17.20089</td>\n",
       "<td>23.89019</td>\n",
       "<td>15.979514</td>\n",
       "<td>25.715683</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1431455</td>\n",
       "<td>0.0130652</td>\n",
       "<td>0.1363502</td>\n",
       "<td>0.1371600</td>\n",
       "<td>0.1538462</td>\n",
       "<td>0.1167236</td>\n",
       "<td>0.1716476</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9951871</td>\n",
       "<td>0.0027788</td>\n",
       "<td>0.9919355</td>\n",
       "<td>1.0</td>\n",
       "<td>0.992</td>\n",
       "<td>1.0</td>\n",
       "<td>0.992</td></tr></table></div>"
      ],
      "text/plain": [
       "                   mean          sd            cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy           0.99253714    0.0033375078  0.9925373     1.0           0.99248123    0.98507464    0.9925926\n",
       "auc                0.99669665    0.0018631828  0.99919355    1.0           0.994         0.99348956    0.9968\n",
       "err                0.0074628526  0.0033375078  0.0074626864  0.0           0.007518797   0.014925373   0.0074074073\n",
       "err_count          1.0           0.4472136     1.0           0.0           1.0           2.0           1.0\n",
       "f0point5           0.93400675    0.023931792   0.9259259     1.0           0.90909094    0.90909094    0.9259259\n",
       "---                ---           ---           ---           ---           ---           ---           ---\n",
       "r2                 0.6469798     0.043536875   0.7307851     0.67089933    0.58132493    0.6814589     0.57043076\n",
       "recall             0.93333334    0.094280906   1.0           1.0           1.0           0.6666667     1.0\n",
       "residual_deviance  20.433674     2.6691458     19.382088     17.20089      23.89019      15.979514     25.715683\n",
       "rmse               0.14314552    0.01306522    0.13635015    0.13715999    0.15384625    0.11672357    0.17164764\n",
       "specificity        0.9951871     0.0027787809  0.9919355     1.0           0.992         1.0           0.992"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>negative_log_likelihood</b></td>\n",
       "<td><b>objective</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:20:07</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>0</td>\n",
       "<td>153.0433585</td>\n",
       "<td>0.2350896</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:20:07</td>\n",
       "<td> 0.004 sec</td>\n",
       "<td>1</td>\n",
       "<td>68.6535190</td>\n",
       "<td>0.1988892</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:20:07</td>\n",
       "<td> 0.007 sec</td>\n",
       "<td>2</td>\n",
       "<td>76.3921692</td>\n",
       "<td>0.1431330</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:20:07</td>\n",
       "<td> 0.010 sec</td>\n",
       "<td>3</td>\n",
       "<td>44.3182382</td>\n",
       "<td>0.1218385</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:20:07</td>\n",
       "<td> 0.012 sec</td>\n",
       "<td>4</td>\n",
       "<td>42.7589471</td>\n",
       "<td>0.1209043</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:20:07</td>\n",
       "<td> 0.021 sec</td>\n",
       "<td>5</td>\n",
       "<td>42.3605389</td>\n",
       "<td>0.1208884</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:20:07</td>\n",
       "<td> 0.024 sec</td>\n",
       "<td>6</td>\n",
       "<td>42.3513447</td>\n",
       "<td>0.1208884</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    iterations    negative_log_likelihood    objective\n",
       "--  -------------------  ----------  ------------  -------------------------  -----------\n",
       "    2018-10-15 21:20:07  0.000 sec   0             153.043                    0.23509\n",
       "    2018-10-15 21:20:07  0.004 sec   1             68.6535                    0.198889\n",
       "    2018-10-15 21:20:07  0.007 sec   2             76.3922                    0.143133\n",
       "    2018-10-15 21:20:07  0.010 sec   3             44.3182                    0.121838\n",
       "    2018-10-15 21:20:07  0.012 sec   4             42.7589                    0.120904\n",
       "    2018-10-15 21:20:07  0.021 sec   5             42.3605                    0.120888\n",
       "    2018-10-15 21:20:07  0.024 sec   6             42.3513                    0.120888"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2OBinomialModel.plot of >"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_model2.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>predict  </th><th style=\"text-align: right;\">   False</th><th style=\"text-align: right;\">       True</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.996043</td><td style=\"text-align: right;\">0.00395656 </td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.996697</td><td style=\"text-align: right;\">0.00330334 </td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.999549</td><td style=\"text-align: right;\">0.000450917</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.985581</td><td style=\"text-align: right;\">0.0144192  </td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.998985</td><td style=\"text-align: right;\">0.00101523 </td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.96252 </td><td style=\"text-align: right;\">0.03748    </td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.964097</td><td style=\"text-align: right;\">0.0359034  </td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.991997</td><td style=\"text-align: right;\">0.00800344 </td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.99182 </td><td style=\"text-align: right;\">0.00817999 </td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.993298</td><td style=\"text-align: right;\">0.00670187 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = glm_model2.predict(test)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomialGLM: glm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.014643906806201252\n",
      "RMSE: 0.12101201099974024\n",
      "LogLoss: 0.0585420587431145\n",
      "Null degrees of freedom: 69\n",
      "Residual degrees of freedom: 58\n",
      "Null deviance: 36.10596481040022\n",
      "Residual deviance: 8.19588822403603\n",
      "AIC: 32.19588822403603\n",
      "AUC: 0.9938461538461537\n",
      "Gini: 0.9876923076923074\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4279951312198837: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>False</b></td>\n",
       "<td><b>True</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>False</td>\n",
       "<td>64.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0154</td>\n",
       "<td> (1.0/65.0)</td></tr>\n",
       "<tr><td>True</td>\n",
       "<td>0.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/5.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>64.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.0143</td>\n",
       "<td> (1.0/70.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       False    True    Error    Rate\n",
       "-----  -------  ------  -------  ----------\n",
       "False  64       1       0.0154   (1.0/65.0)\n",
       "True   0        5       0        (0.0/5.0)\n",
       "Total  64       6       0.0143   (1.0/70.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4279951</td>\n",
       "<td>0.9090909</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.4279951</td>\n",
       "<td>0.9615385</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7694152</td>\n",
       "<td>0.8823529</td>\n",
       "<td>2.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4279951</td>\n",
       "<td>0.9857143</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9347357</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.4279951</td>\n",
       "<td>1.0</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9347357</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4279951</td>\n",
       "<td>0.9058216</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4279951</td>\n",
       "<td>0.9846154</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4279951</td>\n",
       "<td>0.9923077</td>\n",
       "<td>5.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.427995     0.909091  5\n",
       "max f2                       0.427995     0.961538  5\n",
       "max f0point5                 0.769415     0.882353  2\n",
       "max accuracy                 0.427995     0.985714  5\n",
       "max precision                0.934736     1         0\n",
       "max recall                   0.427995     1         5\n",
       "max specificity              0.934736     1         0\n",
       "max absolute_mcc             0.427995     0.905822  5\n",
       "max min_per_class_accuracy   0.427995     0.984615  5\n",
       "max mean_per_class_accuracy  0.427995     0.992308  5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  7.14 %, avg score:  7.37 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0142857</td>\n",
       "<td>0.8913981</td>\n",
       "<td>14.0</td>\n",
       "<td>14.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9347357</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9347357</td>\n",
       "<td>0.2</td>\n",
       "<td>0.2</td>\n",
       "<td>1300.0</td>\n",
       "<td>1300.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0285714</td>\n",
       "<td>0.8329729</td>\n",
       "<td>14.0</td>\n",
       "<td>14.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8719276</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9033316</td>\n",
       "<td>0.2</td>\n",
       "<td>0.4</td>\n",
       "<td>1300.0</td>\n",
       "<td>1300.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0428571</td>\n",
       "<td>0.7497175</td>\n",
       "<td>14.0</td>\n",
       "<td>14.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.7694152</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8586928</td>\n",
       "<td>0.2</td>\n",
       "<td>0.6</td>\n",
       "<td>1300.0</td>\n",
       "<td>1300.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0428571</td>\n",
       "<td>0.5555542</td>\n",
       "<td>0.0</td>\n",
       "<td>14.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8586928</td>\n",
       "<td>0.0</td>\n",
       "<td>0.6</td>\n",
       "<td>-100.0</td>\n",
       "<td>1300.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0571429</td>\n",
       "<td>0.4618060</td>\n",
       "<td>0.0</td>\n",
       "<td>10.5</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4880192</td>\n",
       "<td>0.75</td>\n",
       "<td>0.7660244</td>\n",
       "<td>0.0</td>\n",
       "<td>0.6</td>\n",
       "<td>-100.0</td>\n",
       "<td>950.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.0884872</td>\n",
       "<td>9.3333333</td>\n",
       "<td>10.0</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.3157700</td>\n",
       "<td>0.7142857</td>\n",
       "<td>0.5730582</td>\n",
       "<td>0.4</td>\n",
       "<td>1.0</td>\n",
       "<td>833.3333333</td>\n",
       "<td>900.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1571429</td>\n",
       "<td>0.0606575</td>\n",
       "<td>0.0</td>\n",
       "<td>6.3636364</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0769329</td>\n",
       "<td>0.4545455</td>\n",
       "<td>0.3926490</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>536.3636364</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.0529270</td>\n",
       "<td>0.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0571111</td>\n",
       "<td>0.3571429</td>\n",
       "<td>0.3207480</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>400.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.0327719</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3333333</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0418028</td>\n",
       "<td>0.2380952</td>\n",
       "<td>0.2277663</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>233.3333333</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0185211</td>\n",
       "<td>0.0</td>\n",
       "<td>2.5</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0244386</td>\n",
       "<td>0.1785714</td>\n",
       "<td>0.1769344</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>150.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0098990</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0135694</td>\n",
       "<td>0.1428571</td>\n",
       "<td>0.1442614</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0054943</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6666667</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0080961</td>\n",
       "<td>0.1190476</td>\n",
       "<td>0.1215672</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.0026221</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285714</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0035867</td>\n",
       "<td>0.1020408</td>\n",
       "<td>0.1047128</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0015457</td>\n",
       "<td>0.0</td>\n",
       "<td>1.25</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0019408</td>\n",
       "<td>0.0892857</td>\n",
       "<td>0.0918663</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0010911</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1111111</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0013191</td>\n",
       "<td>0.0793651</td>\n",
       "<td>0.0818055</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0004082</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0007196</td>\n",
       "<td>0.0714286</td>\n",
       "<td>0.0736969</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0142857                   0.891398           14       14                 1                0.934736     1                           0.934736            0.2             0.2                        1300     1300\n",
       "    2        0.0285714                   0.832973           14       14                 1                0.871928     1                           0.903332            0.2             0.4                        1300     1300\n",
       "    3        0.0428571                   0.749717           14       14                 1                0.769415     1                           0.858693            0.2             0.6                        1300     1300\n",
       "    4        0.0428571                   0.555554           0        14                 0                0            1                           0.858693            0               0.6                        -100     1300\n",
       "    5        0.0571429                   0.461806           0        10.5               0                0.488019     0.75                        0.766024            0               0.6                        -100     950\n",
       "    6        0.1                         0.0884872          9.33333  10                 0.666667         0.31577      0.714286                    0.573058            0.4             1                          833.333  900\n",
       "    7        0.157143                    0.0606575          0        6.36364            0                0.0769329    0.454545                    0.392649            0               1                          -100     536.364\n",
       "    8        0.2                         0.052927           0        5                  0                0.0571111    0.357143                    0.320748            0               1                          -100     400\n",
       "    9        0.3                         0.0327719          0        3.33333            0                0.0418028    0.238095                    0.227766            0               1                          -100     233.333\n",
       "    10       0.4                         0.0185211          0        2.5                0                0.0244386    0.178571                    0.176934            0               1                          -100     150\n",
       "    11       0.5                         0.00989896         0        2                  0                0.0135694    0.142857                    0.144261            0               1                          -100     100\n",
       "    12       0.6                         0.00549432         0        1.66667            0                0.00809611   0.119048                    0.121567            0               1                          -100     66.6667\n",
       "    13       0.7                         0.00262208         0        1.42857            0                0.00358671   0.102041                    0.104713            0               1                          -100     42.8571\n",
       "    14       0.8                         0.00154565         0        1.25               0                0.00194078   0.0892857                   0.0918663           0               1                          -100     25\n",
       "    15       0.9                         0.00109115         0        1.11111            0                0.00131913   0.0793651                   0.0818055           0               1                          -100     11.1111\n",
       "    16       1                           0.000408213        0        1                  0                0.000719633  0.0714286                   0.0736969           0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref = glm_model2.model_performance(test)\n",
    "pref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For GLM_model2 the AUC is 0.9973610555777689 on the training data and 0.9938461538461537 on the testing data. The model is a good fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_model2 = H2OGradientBoostingEstimator(distribution= \"bernoulli\",nfolds=5)\n",
    "gbm_model2.train(x=X, y=y, training_frame= train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_model_python_1539652770571_21\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 7.631397724256878e-05\n",
      "RMSE: 0.00873578715643695\n",
      "LogLoss: 0.0022693383695799995\n",
      "Mean Per-Class Error: 0.0\n",
      "AUC: 1.0\n",
      "Gini: 1.0\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9138771439004214: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>False</b></td>\n",
       "<td><b>True</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>False</td>\n",
       "<td>610.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/610.0)</td></tr>\n",
       "<tr><td>True</td>\n",
       "<td>0.0</td>\n",
       "<td>41.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/41.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>610.0</td>\n",
       "<td>41.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/651.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       False    True    Error    Rate\n",
       "-----  -------  ------  -------  -----------\n",
       "False  610      0       0        (0.0/610.0)\n",
       "True   0        41      0        (0.0/41.0)\n",
       "Total  610      41      0        (0.0/651.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.9138771</td>\n",
       "<td>1.0</td>\n",
       "<td>39.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.9138771</td>\n",
       "<td>1.0</td>\n",
       "<td>39.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9138771</td>\n",
       "<td>1.0</td>\n",
       "<td>39.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9138771</td>\n",
       "<td>1.0</td>\n",
       "<td>39.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9954093</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.9138771</td>\n",
       "<td>1.0</td>\n",
       "<td>39.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9954093</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.9138771</td>\n",
       "<td>1.0</td>\n",
       "<td>39.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.9138771</td>\n",
       "<td>1.0</td>\n",
       "<td>39.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.9138771</td>\n",
       "<td>1.0</td>\n",
       "<td>39.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value    idx\n",
       "---------------------------  -----------  -------  -----\n",
       "max f1                       0.913877     1        39\n",
       "max f2                       0.913877     1        39\n",
       "max f0point5                 0.913877     1        39\n",
       "max accuracy                 0.913877     1        39\n",
       "max precision                0.995409     1        0\n",
       "max recall                   0.913877     1        39\n",
       "max specificity              0.995409     1        0\n",
       "max absolute_mcc             0.913877     1        39\n",
       "max min_per_class_accuracy   0.913877     1        39\n",
       "max mean_per_class_accuracy  0.913877     1        39"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  6.30 %, avg score:  6.31 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0107527</td>\n",
       "<td>0.9927550</td>\n",
       "<td>15.8780488</td>\n",
       "<td>15.8780488</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9937920</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9937920</td>\n",
       "<td>0.1707317</td>\n",
       "<td>0.1707317</td>\n",
       "<td>1487.8048780</td>\n",
       "<td>1487.8048780</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0215054</td>\n",
       "<td>0.9917092</td>\n",
       "<td>15.8780488</td>\n",
       "<td>15.8780488</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9922856</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9930388</td>\n",
       "<td>0.1707317</td>\n",
       "<td>0.3414634</td>\n",
       "<td>1487.8048780</td>\n",
       "<td>1487.8048780</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0307220</td>\n",
       "<td>0.9889615</td>\n",
       "<td>15.8780488</td>\n",
       "<td>15.8780488</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9904214</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9922536</td>\n",
       "<td>0.1463415</td>\n",
       "<td>0.4878049</td>\n",
       "<td>1487.8048780</td>\n",
       "<td>1487.8048780</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0414747</td>\n",
       "<td>0.9855733</td>\n",
       "<td>15.8780488</td>\n",
       "<td>15.8780488</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9869721</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9908843</td>\n",
       "<td>0.1707317</td>\n",
       "<td>0.6585366</td>\n",
       "<td>1487.8048780</td>\n",
       "<td>1487.8048780</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0506912</td>\n",
       "<td>0.9772583</td>\n",
       "<td>15.8780488</td>\n",
       "<td>15.8780488</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9821252</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9892917</td>\n",
       "<td>0.1463415</td>\n",
       "<td>0.8048780</td>\n",
       "<td>1487.8048780</td>\n",
       "<td>1487.8048780</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1029186</td>\n",
       "<td>0.0023809</td>\n",
       "<td>3.7360115</td>\n",
       "<td>9.7164179</td>\n",
       "<td>0.2352941</td>\n",
       "<td>0.2388906</td>\n",
       "<td>0.6119403</td>\n",
       "<td>0.6084912</td>\n",
       "<td>0.1951220</td>\n",
       "<td>1.0</td>\n",
       "<td>273.6011478</td>\n",
       "<td>871.6417910</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1505376</td>\n",
       "<td>0.0006235</td>\n",
       "<td>0.0</td>\n",
       "<td>6.6428571</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0013865</td>\n",
       "<td>0.4183673</td>\n",
       "<td>0.4164479</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>564.2857143</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2043011</td>\n",
       "<td>0.0004228</td>\n",
       "<td>0.0</td>\n",
       "<td>4.8947368</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004617</td>\n",
       "<td>0.3082707</td>\n",
       "<td>0.3069778</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>389.4736842</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.8709677</td>\n",
       "<td>0.0004228</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1481481</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004228</td>\n",
       "<td>0.0723104</td>\n",
       "<td>0.0723308</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>14.8148148</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.9016897</td>\n",
       "<td>0.0004225</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1090290</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004226</td>\n",
       "<td>0.0698467</td>\n",
       "<td>0.0698807</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>10.9028961</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0003550</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004148</td>\n",
       "<td>0.0629800</td>\n",
       "<td>0.0630515</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0107527                   0.992755           15.878   15.878             1                0.993792     1                           0.993792            0.170732        0.170732                   1487.8   1487.8\n",
       "    2        0.0215054                   0.991709           15.878   15.878             1                0.992286     1                           0.993039            0.170732        0.341463                   1487.8   1487.8\n",
       "    3        0.030722                    0.988962           15.878   15.878             1                0.990421     1                           0.992254            0.146341        0.487805                   1487.8   1487.8\n",
       "    4        0.0414747                   0.985573           15.878   15.878             1                0.986972     1                           0.990884            0.170732        0.658537                   1487.8   1487.8\n",
       "    5        0.0506912                   0.977258           15.878   15.878             1                0.982125     1                           0.989292            0.146341        0.804878                   1487.8   1487.8\n",
       "    6        0.102919                    0.00238094         3.73601  9.71642            0.235294         0.238891     0.61194                     0.608491            0.195122        1                          273.601  871.642\n",
       "    7        0.150538                    0.000623496        0        6.64286            0                0.00138649   0.418367                    0.416448            0               1                          -100     564.286\n",
       "    8        0.204301                    0.000422802        0        4.89474            0                0.000461674  0.308271                    0.306978            0               1                          -100     389.474\n",
       "    9        0.870968                    0.000422789        0        1.14815            0                0.000422789  0.0723104                   0.0723308           0               1                          -100     14.8148\n",
       "    10       0.90169                     0.000422452        0        1.10903            0                0.000422613  0.0698467                   0.0698807           0               1                          -100     10.9029\n",
       "    11       1                           0.000355018        0        1                  0                0.000414792  0.06298                     0.0630515           0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.008531012610950937\n",
      "RMSE: 0.09236348093781944\n",
      "LogLoss: 0.03357896117304334\n",
      "Mean Per-Class Error: 0.007377049180327888\n",
      "AUC: 0.9970811675329868\n",
      "Gini: 0.9941623350659736\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5593531066779743: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>False</b></td>\n",
       "<td><b>True</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>False</td>\n",
       "<td>606.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0066</td>\n",
       "<td> (4.0/610.0)</td></tr>\n",
       "<tr><td>True</td>\n",
       "<td>1.0</td>\n",
       "<td>40.0</td>\n",
       "<td>0.0244</td>\n",
       "<td> (1.0/41.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>607.0</td>\n",
       "<td>44.0</td>\n",
       "<td>0.0077</td>\n",
       "<td> (5.0/651.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       False    True    Error    Rate\n",
       "-----  -------  ------  -------  -----------\n",
       "False  606      4       0.0066   (4.0/610.0)\n",
       "True   1        40      0.0244   (1.0/41.0)\n",
       "Total  607      44      0.0077   (5.0/651.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.5593531</td>\n",
       "<td>0.9411765</td>\n",
       "<td>43.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.5593531</td>\n",
       "<td>0.9615385</td>\n",
       "<td>43.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5593531</td>\n",
       "<td>0.9216590</td>\n",
       "<td>43.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5593531</td>\n",
       "<td>0.9923195</td>\n",
       "<td>43.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9978283</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0402810</td>\n",
       "<td>1.0</td>\n",
       "<td>49.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9978283</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.5593531</td>\n",
       "<td>0.9377421</td>\n",
       "<td>43.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0402810</td>\n",
       "<td>0.9852459</td>\n",
       "<td>49.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0402810</td>\n",
       "<td>0.9926230</td>\n",
       "<td>49.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.559353     0.941176  43\n",
       "max f2                       0.559353     0.961538  43\n",
       "max f0point5                 0.559353     0.921659  43\n",
       "max accuracy                 0.559353     0.99232   43\n",
       "max precision                0.997828     1         0\n",
       "max recall                   0.040281     1         49\n",
       "max specificity              0.997828     1         0\n",
       "max absolute_mcc             0.559353     0.937742  43\n",
       "max min_per_class_accuracy   0.040281     0.985246  49\n",
       "max mean_per_class_accuracy  0.040281     0.992623  49"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  6.30 %, avg score:  6.50 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0107527</td>\n",
       "<td>0.9952750</td>\n",
       "<td>15.8780488</td>\n",
       "<td>15.8780488</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9962044</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9962044</td>\n",
       "<td>0.1707317</td>\n",
       "<td>0.1707317</td>\n",
       "<td>1487.8048780</td>\n",
       "<td>1487.8048780</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0215054</td>\n",
       "<td>0.9920987</td>\n",
       "<td>15.8780488</td>\n",
       "<td>15.8780488</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9932862</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9947453</td>\n",
       "<td>0.1707317</td>\n",
       "<td>0.3414634</td>\n",
       "<td>1487.8048780</td>\n",
       "<td>1487.8048780</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0307220</td>\n",
       "<td>0.9846755</td>\n",
       "<td>10.5853659</td>\n",
       "<td>14.2902439</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.9874636</td>\n",
       "<td>0.9</td>\n",
       "<td>0.9925608</td>\n",
       "<td>0.0975610</td>\n",
       "<td>0.4390244</td>\n",
       "<td>958.5365854</td>\n",
       "<td>1329.0243902</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0414747</td>\n",
       "<td>0.9664002</td>\n",
       "<td>15.8780488</td>\n",
       "<td>14.7018970</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9744334</td>\n",
       "<td>0.9259259</td>\n",
       "<td>0.9878611</td>\n",
       "<td>0.1707317</td>\n",
       "<td>0.6097561</td>\n",
       "<td>1487.8048780</td>\n",
       "<td>1370.1897019</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0506912</td>\n",
       "<td>0.9282106</td>\n",
       "<td>13.2317073</td>\n",
       "<td>14.4345898</td>\n",
       "<td>0.8333333</td>\n",
       "<td>0.9471598</td>\n",
       "<td>0.9090909</td>\n",
       "<td>0.9804609</td>\n",
       "<td>0.1219512</td>\n",
       "<td>0.7317073</td>\n",
       "<td>1223.1707317</td>\n",
       "<td>1343.4589800</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1013825</td>\n",
       "<td>0.0034700</td>\n",
       "<td>5.2926829</td>\n",
       "<td>9.8636364</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.2938698</td>\n",
       "<td>0.6212121</td>\n",
       "<td>0.6371653</td>\n",
       "<td>0.2682927</td>\n",
       "<td>1.0</td>\n",
       "<td>429.2682927</td>\n",
       "<td>886.3636364</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1505376</td>\n",
       "<td>0.0007830</td>\n",
       "<td>0.0</td>\n",
       "<td>6.6428571</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0015254</td>\n",
       "<td>0.4183673</td>\n",
       "<td>0.4296094</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>564.2857143</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2012289</td>\n",
       "<td>0.0004955</td>\n",
       "<td>0.0</td>\n",
       "<td>4.9694656</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0006121</td>\n",
       "<td>0.3129771</td>\n",
       "<td>0.3215414</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>396.9465649</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3149002</td>\n",
       "<td>0.0004739</td>\n",
       "<td>0.0</td>\n",
       "<td>3.1756098</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004744</td>\n",
       "<td>0.2</td>\n",
       "<td>0.2056440</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>217.5609756</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.5069124</td>\n",
       "<td>0.0004372</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9727273</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004461</td>\n",
       "<td>0.1242424</td>\n",
       "<td>0.1279175</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>97.2727273</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.6635945</td>\n",
       "<td>0.0004239</td>\n",
       "<td>0.0</td>\n",
       "<td>1.5069444</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004267</td>\n",
       "<td>0.0949074</td>\n",
       "<td>0.0978155</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>50.6944444</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.7004608</td>\n",
       "<td>0.0004218</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4276316</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004231</td>\n",
       "<td>0.0899123</td>\n",
       "<td>0.0926896</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.7631579</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.8003072</td>\n",
       "<td>0.0004218</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2495202</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004218</td>\n",
       "<td>0.0786948</td>\n",
       "<td>0.0811783</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.9520154</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.9738863</td>\n",
       "<td>0.0003730</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0268139</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0003892</td>\n",
       "<td>0.0646688</td>\n",
       "<td>0.0667790</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>2.6813880</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0003149</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0003611</td>\n",
       "<td>0.0629800</td>\n",
       "<td>0.0650445</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0107527                   0.995275           15.878   15.878             1                0.996204     1                           0.996204            0.170732        0.170732                   1487.8   1487.8\n",
       "    2        0.0215054                   0.992099           15.878   15.878             1                0.993286     1                           0.994745            0.170732        0.341463                   1487.8   1487.8\n",
       "    3        0.030722                    0.984676           10.5854  14.2902            0.666667         0.987464     0.9                         0.992561            0.097561        0.439024                   958.537  1329.02\n",
       "    4        0.0414747                   0.9664             15.878   14.7019            1                0.974433     0.925926                    0.987861            0.170732        0.609756                   1487.8   1370.19\n",
       "    5        0.0506912                   0.928211           13.2317  14.4346            0.833333         0.94716      0.909091                    0.980461            0.121951        0.731707                   1223.17  1343.46\n",
       "    6        0.101382                    0.00346996         5.29268  9.86364            0.333333         0.29387      0.621212                    0.637165            0.268293        1                          429.268  886.364\n",
       "    7        0.150538                    0.000782975        0        6.64286            0                0.00152542   0.418367                    0.429609            0               1                          -100     564.286\n",
       "    8        0.201229                    0.00049554         0        4.96947            0                0.000612108  0.312977                    0.321541            0               1                          -100     396.947\n",
       "    9        0.3149                      0.000473868        0        3.17561            0                0.000474381  0.2                         0.205644            0               1                          -100     217.561\n",
       "    10       0.506912                    0.000437194        0        1.97273            0                0.000446053  0.124242                    0.127918            0               1                          -100     97.2727\n",
       "    11       0.663594                    0.000423874        0        1.50694            0                0.00042671   0.0949074                   0.0978155           0               1                          -100     50.6944\n",
       "    12       0.700461                    0.000421802        0        1.42763            0                0.000423114  0.0899123                   0.0926896           0               1                          -100     42.7632\n",
       "    13       0.800307                    0.000421801        0        1.24952            0                0.000421801  0.0786948                   0.0811783           0               1                          -100     24.952\n",
       "    14       0.973886                    0.000372977        0        1.02681            0                0.000389167  0.0646688                   0.066779            0               1                          -100     2.68139\n",
       "    15       1                           0.000314947        0        1                  0                0.00036114   0.06298                     0.0650445           0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9923078</td>\n",
       "<td>0.0035333</td>\n",
       "<td>1.0</td>\n",
       "<td>0.984252</td>\n",
       "<td>0.9931034</td>\n",
       "<td>0.9919355</td>\n",
       "<td>0.9922481</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9972352</td>\n",
       "<td>0.0020140</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9918699</td>\n",
       "<td>0.9990876</td>\n",
       "<td>0.9980676</td>\n",
       "<td>0.997151</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0076922</td>\n",
       "<td>0.0035333</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0157480</td>\n",
       "<td>0.0068966</td>\n",
       "<td>0.0080645</td>\n",
       "<td>0.0077519</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>1.0</td>\n",
       "<td>0.4472136</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9072973</td>\n",
       "<td>0.0717142</td>\n",
       "<td>1.0</td>\n",
       "<td>0.7142857</td>\n",
       "<td>0.9090909</td>\n",
       "<td>0.9756098</td>\n",
       "<td>0.9375</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9284706</td>\n",
       "<td>0.0478938</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8</td>\n",
       "<td>0.9411765</td>\n",
       "<td>0.9411765</td>\n",
       "<td>0.96</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.9554796</td>\n",
       "<td>0.0273537</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9090909</td>\n",
       "<td>0.9756098</td>\n",
       "<td>0.9090909</td>\n",
       "<td>0.9836066</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>18.030556</td>\n",
       "<td>5.143205</td>\n",
       "<td>15.75</td>\n",
       "<td>31.75</td>\n",
       "<td>18.125</td>\n",
       "<td>13.777778</td>\n",
       "<td>10.75</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.0337966</td>\n",
       "<td>0.0155553</td>\n",
       "<td>0.0030273</td>\n",
       "<td>0.0702021</td>\n",
       "<td>0.0233379</td>\n",
       "<td>0.0325638</td>\n",
       "<td>0.0398518</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.0286435</td>\n",
       "<td>0.0293839</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0162602</td>\n",
       "<td>0.0072993</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.0085470</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9289167</td>\n",
       "<td>0.0449545</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8098312</td>\n",
       "<td>0.9393618</td>\n",
       "<td>0.9387364</td>\n",
       "<td>0.9566543</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9856783</td>\n",
       "<td>0.0146920</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9918699</td>\n",
       "<td>0.9963504</td>\n",
       "<td>0.9444444</td>\n",
       "<td>0.9957265</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0143218</td>\n",
       "<td>0.0146920</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0081301</td>\n",
       "<td>0.0036496</td>\n",
       "<td>0.0555556</td>\n",
       "<td>0.0042735</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0085324</td>\n",
       "<td>0.0035287</td>\n",
       "<td>0.0001770</td>\n",
       "<td>0.0153887</td>\n",
       "<td>0.0076816</td>\n",
       "<td>0.0082562</td>\n",
       "<td>0.0111583</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.8957265</td>\n",
       "<td>0.0866078</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.8888889</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9230769</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.8180548</td>\n",
       "<td>0.1196832</td>\n",
       "<td>0.9970239</td>\n",
       "<td>0.4955182</td>\n",
       "<td>0.8526406</td>\n",
       "<td>0.8773456</td>\n",
       "<td>0.8677456</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9777778</td>\n",
       "<td>0.0314270</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8888889</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.0842991</td>\n",
       "<td>0.0267023</td>\n",
       "<td>0.0133027</td>\n",
       "<td>0.1240514</td>\n",
       "<td>0.0876448</td>\n",
       "<td>0.0908636</td>\n",
       "<td>0.1056328</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9935787</td>\n",
       "<td>0.0042960</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9837398</td>\n",
       "<td>0.9927008</td>\n",
       "<td>1.0</td>\n",
       "<td>0.991453</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean        sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ----------  ----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.992308    0.00353329  1             0.984252      0.993103      0.991935      0.992248\n",
       "auc                      0.997235    0.00201399  1             0.99187       0.999088      0.998068      0.997151\n",
       "err                      0.00769221  0.00353329  0             0.015748      0.00689655    0.00806452    0.00775194\n",
       "err_count                1           0.447214    0             2             1             1             1\n",
       "f0point5                 0.907297    0.0717142   1             0.714286      0.909091      0.97561       0.9375\n",
       "f1                       0.928471    0.0478938   1             0.8           0.941176      0.941176      0.96\n",
       "f2                       0.95548     0.0273537   1             0.909091      0.97561       0.909091      0.983607\n",
       "lift_top_group           18.0306     5.14321     15.75         31.75         18.125        13.7778       10.75\n",
       "logloss                  0.0337966   0.0155553   0.00302729    0.0702021     0.0233379     0.0325638     0.0398518\n",
       "max_per_class_error      0.0286435   0.0293839   0             0.0162602     0.00729927    0.111111      0.00854701\n",
       "mcc                      0.928917    0.0449545   1             0.809831      0.939362      0.938736      0.956654\n",
       "mean_per_class_accuracy  0.985678    0.014692    1             0.99187       0.99635       0.944444      0.995726\n",
       "mean_per_class_error     0.0143218   0.014692    0             0.00813008    0.00364964    0.0555556     0.0042735\n",
       "mse                      0.00853236  0.00352871  0.000176961   0.0153887     0.00768161    0.00825619    0.0111583\n",
       "precision                0.895726    0.0866078   1             0.666667      0.888889      1             0.923077\n",
       "r2                       0.818055    0.119683    0.997024      0.495518      0.852641      0.877346      0.867746\n",
       "recall                   0.977778    0.031427    1             1             1             0.888889      1\n",
       "rmse                     0.0842991   0.0267023   0.0133027     0.124051      0.0876448     0.0908636     0.105633\n",
       "specificity              0.993579    0.00429603  1             0.98374       0.992701      1             0.991453"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:20:42</td>\n",
       "<td> 5.066 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2429270</td>\n",
       "<td>0.2350896</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9370200</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:20:42</td>\n",
       "<td> 5.096 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2073077</td>\n",
       "<td>0.1583142</td>\n",
       "<td>0.9970812</td>\n",
       "<td>15.8780488</td>\n",
       "<td>0.0153610</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:20:42</td>\n",
       "<td> 5.107 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.1886669</td>\n",
       "<td>0.1339648</td>\n",
       "<td>0.9986206</td>\n",
       "<td>15.8780488</td>\n",
       "<td>0.0046083</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:20:42</td>\n",
       "<td> 5.135 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.1732335</td>\n",
       "<td>0.1171734</td>\n",
       "<td>0.9986206</td>\n",
       "<td>15.8780488</td>\n",
       "<td>0.0046083</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:20:42</td>\n",
       "<td> 5.159 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.1601203</td>\n",
       "<td>0.1043326</td>\n",
       "<td>0.9986206</td>\n",
       "<td>15.8780488</td>\n",
       "<td>0.0046083</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:20:43</td>\n",
       "<td> 5.765 sec</td>\n",
       "<td>46.0</td>\n",
       "<td>0.0106963</td>\n",
       "<td>0.0030144</td>\n",
       "<td>1.0</td>\n",
       "<td>15.8780488</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:20:43</td>\n",
       "<td> 5.789 sec</td>\n",
       "<td>47.0</td>\n",
       "<td>0.0101904</td>\n",
       "<td>0.0028269</td>\n",
       "<td>1.0</td>\n",
       "<td>15.8780488</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:20:43</td>\n",
       "<td> 5.799 sec</td>\n",
       "<td>48.0</td>\n",
       "<td>0.0096795</td>\n",
       "<td>0.0026240</td>\n",
       "<td>1.0</td>\n",
       "<td>15.8780488</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:20:43</td>\n",
       "<td> 5.816 sec</td>\n",
       "<td>49.0</td>\n",
       "<td>0.0091690</td>\n",
       "<td>0.0024365</td>\n",
       "<td>1.0</td>\n",
       "<td>15.8780488</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:20:43</td>\n",
       "<td> 5.827 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.0087358</td>\n",
       "<td>0.0022693</td>\n",
       "<td>1.0</td>\n",
       "<td>15.8780488</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    number_of_trees    training_rmse         training_logloss       training_auc        training_lift       training_classification_error\n",
       "---  -------------------  ----------  -----------------  --------------------  ---------------------  ------------------  ------------------  -------------------------------\n",
       "     2018-10-15 21:20:42  5.066 sec   0.0                0.24292703936002352   0.23508964434840887    0.5                 1.0                 0.9370199692780338\n",
       "     2018-10-15 21:20:42  5.096 sec   1.0                0.20730774117275533   0.15831423694541902    0.9970811675329868  15.878048780487806  0.015360983102918587\n",
       "     2018-10-15 21:20:42  5.107 sec   2.0                0.1886669405240542    0.13396479744979978    0.9986205517792882  15.878048780487806  0.004608294930875576\n",
       "     2018-10-15 21:20:42  5.135 sec   3.0                0.17323348734006988   0.11717340316068198    0.9986205517792882  15.878048780487806  0.004608294930875576\n",
       "     2018-10-15 21:20:42  5.159 sec   4.0                0.16012034185341872   0.10433261401125496    0.9986205517792882  15.878048780487806  0.004608294930875576\n",
       "---  ---                  ---         ---                ---                   ---                    ---                 ---                 ---\n",
       "     2018-10-15 21:20:43  5.765 sec   46.0               0.010696297265275436  0.0030143674565917596  1.0                 15.878048780487806  0.0\n",
       "     2018-10-15 21:20:43  5.789 sec   47.0               0.010190357601270435  0.002826898291221504   1.0                 15.878048780487806  0.0\n",
       "     2018-10-15 21:20:43  5.799 sec   48.0               0.009679474199220306  0.0026240118670206552  1.0                 15.878048780487806  0.0\n",
       "     2018-10-15 21:20:43  5.816 sec   49.0               0.00916901217050044   0.0024365414545321506  1.0                 15.878048780487806  0.0\n",
       "     2018-10-15 21:20:43  5.827 sec   50.0               0.00873578715643695   0.0022693383695799995  1.0                 15.878048780487806  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>Catch_Rate</td>\n",
       "<td>90.4595566</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5386675</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>34.4737740</td>\n",
       "<td>0.3810960</td>\n",
       "<td>0.2052840</td></tr>\n",
       "<tr><td>Egg_Group_1</td>\n",
       "<td>17.9367485</td>\n",
       "<td>0.1982847</td>\n",
       "<td>0.1068095</td></tr>\n",
       "<tr><td>Type_1</td>\n",
       "<td>7.0992889</td>\n",
       "<td>0.0784803</td>\n",
       "<td>0.0422748</td></tr>\n",
       "<tr><td>Body_Style</td>\n",
       "<td>6.2497134</td>\n",
       "<td>0.0690885</td>\n",
       "<td>0.0372157</td></tr>\n",
       "<tr><td>Pr_Male</td>\n",
       "<td>5.2044878</td>\n",
       "<td>0.0575339</td>\n",
       "<td>0.0309916</td></tr>\n",
       "<tr><td>Height_m</td>\n",
       "<td>4.6585808</td>\n",
       "<td>0.0514990</td>\n",
       "<td>0.0277409</td></tr>\n",
       "<tr><td>Attack</td>\n",
       "<td>0.7150988</td>\n",
       "<td>0.0079052</td>\n",
       "<td>0.0042583</td></tr>\n",
       "<tr><td>Sp_Atk</td>\n",
       "<td>0.3651821</td>\n",
       "<td>0.0040370</td>\n",
       "<td>0.0021746</td></tr>\n",
       "<tr><td>HP</td>\n",
       "<td>0.3288983</td>\n",
       "<td>0.0036359</td>\n",
       "<td>0.0019585</td></tr>\n",
       "<tr><td>Generation</td>\n",
       "<td>0.1951653</td>\n",
       "<td>0.0021575</td>\n",
       "<td>0.0011622</td></tr>\n",
       "<tr><td>Weight_kg</td>\n",
       "<td>0.1451165</td>\n",
       "<td>0.0016042</td>\n",
       "<td>0.0008641</td></tr>\n",
       "<tr><td>Defense</td>\n",
       "<td>0.0628676</td>\n",
       "<td>0.0006950</td>\n",
       "<td>0.0003744</td></tr>\n",
       "<tr><td>Color</td>\n",
       "<td>0.0360093</td>\n",
       "<td>0.0003981</td>\n",
       "<td>0.0002144</td></tr>\n",
       "<tr><td>hasGender</td>\n",
       "<td>0.0015877</td>\n",
       "<td>0.0000176</td>\n",
       "<td>0.0000095</td></tr>\n",
       "<tr><td>hasMegaEvolution</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td></tr>\n",
       "<tr><td>Sp_Def</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>Speed</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "variable          relative_importance    scaled_importance    percentage\n",
       "----------------  ---------------------  -------------------  ------------\n",
       "Catch_Rate        90.4596                1                    0.538668\n",
       "Total             34.4738                0.381096             0.205284\n",
       "Egg_Group_1       17.9367                0.198285             0.10681\n",
       "Type_1            7.09929                0.0784803            0.0422748\n",
       "Body_Style        6.24971                0.0690885            0.0372157\n",
       "Pr_Male           5.20449                0.0575339            0.0309916\n",
       "Height_m          4.65858                0.051499             0.0277409\n",
       "Attack            0.715099               0.00790518           0.00425826\n",
       "Sp_Atk            0.365182               0.00403697           0.00217458\n",
       "HP                0.328898               0.00363586           0.00195852\n",
       "Generation        0.195165               0.00215749           0.00116217\n",
       "Weight_kg         0.145117               0.00160421           0.000864138\n",
       "Defense           0.0628676              0.00069498           0.000374363\n",
       "Color             0.0360093              0.000398071          0.000214428\n",
       "hasGender         0.00158766             1.7551e-05           9.45417e-06\n",
       "hasMegaEvolution  1.10936e-11            1.22636e-13          6.60601e-14\n",
       "Sp_Def            0                      0                    0\n",
       "Speed             0                      0                    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2OBinomialModel.plot of >"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model2.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>predict  </th><th style=\"text-align: right;\">   False</th><th style=\"text-align: right;\">       True</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.999577</td><td style=\"text-align: right;\">0.000422789</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.999577</td><td style=\"text-align: right;\">0.000422789</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.999577</td><td style=\"text-align: right;\">0.000422789</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.999577</td><td style=\"text-align: right;\">0.000422789</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.999577</td><td style=\"text-align: right;\">0.000422789</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.999577</td><td style=\"text-align: right;\">0.000422789</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.999645</td><td style=\"text-align: right;\">0.000355018</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.999577</td><td style=\"text-align: right;\">0.000422789</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.999577</td><td style=\"text-align: right;\">0.000422789</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.999577</td><td style=\"text-align: right;\">0.000422789</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = gbm_model2.predict(test)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.029618486349941704\n",
      "RMSE: 0.17210022181839774\n",
      "LogLoss: 0.08394337799499696\n",
      "Mean Per-Class Error: 0.007692307692307665\n",
      "AUC: 0.9938461538461537\n",
      "Gini: 0.9876923076923074\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.1519193430827274: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>False</b></td>\n",
       "<td><b>True</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>False</td>\n",
       "<td>64.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0154</td>\n",
       "<td> (1.0/65.0)</td></tr>\n",
       "<tr><td>True</td>\n",
       "<td>0.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/5.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>64.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.0143</td>\n",
       "<td> (1.0/70.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       False    True    Error    Rate\n",
       "-----  -------  ------  -------  ----------\n",
       "False  64       1       0.0154   (1.0/65.0)\n",
       "True   0        5       0        (0.0/5.0)\n",
       "Total  64       6       0.0143   (1.0/70.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1519193</td>\n",
       "<td>0.9090909</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1519193</td>\n",
       "<td>0.9615385</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9591995</td>\n",
       "<td>0.8823529</td>\n",
       "<td>2.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.1519193</td>\n",
       "<td>0.9857143</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9956411</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.1519193</td>\n",
       "<td>1.0</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9956411</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.1519193</td>\n",
       "<td>0.9058216</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1519193</td>\n",
       "<td>0.9846154</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1519193</td>\n",
       "<td>0.9923077</td>\n",
       "<td>5.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.151919     0.909091  5\n",
       "max f2                       0.151919     0.961538  5\n",
       "max f0point5                 0.959199     0.882353  2\n",
       "max accuracy                 0.151919     0.985714  5\n",
       "max precision                0.995641     1         0\n",
       "max recall                   0.151919     1         5\n",
       "max specificity              0.995641     1         0\n",
       "max absolute_mcc             0.151919     0.905822  5\n",
       "max min_per_class_accuracy   0.151919     0.984615  5\n",
       "max mean_per_class_accuracy  0.151919     0.992308  5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  7.14 %, avg score:  6.26 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0142857</td>\n",
       "<td>0.9952077</td>\n",
       "<td>14.0</td>\n",
       "<td>14.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9956411</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9956411</td>\n",
       "<td>0.2</td>\n",
       "<td>0.2</td>\n",
       "<td>1300.0</td>\n",
       "<td>1300.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0285714</td>\n",
       "<td>0.9814039</td>\n",
       "<td>14.0</td>\n",
       "<td>14.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9950130</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9953271</td>\n",
       "<td>0.2</td>\n",
       "<td>0.4</td>\n",
       "<td>1300.0</td>\n",
       "<td>1300.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0428571</td>\n",
       "<td>0.9574822</td>\n",
       "<td>14.0</td>\n",
       "<td>14.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9591995</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9832845</td>\n",
       "<td>0.2</td>\n",
       "<td>0.6</td>\n",
       "<td>1300.0</td>\n",
       "<td>1300.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0428571</td>\n",
       "<td>0.9405549</td>\n",
       "<td>0.0</td>\n",
       "<td>14.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9832845</td>\n",
       "<td>0.0</td>\n",
       "<td>0.6</td>\n",
       "<td>-100.0</td>\n",
       "<td>1300.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0571429</td>\n",
       "<td>0.6527224</td>\n",
       "<td>0.0</td>\n",
       "<td>10.5</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9346671</td>\n",
       "<td>0.75</td>\n",
       "<td>0.9711302</td>\n",
       "<td>0.0</td>\n",
       "<td>0.6</td>\n",
       "<td>-100.0</td>\n",
       "<td>950.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.0021179</td>\n",
       "<td>9.3333333</td>\n",
       "<td>10.0</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.1552254</td>\n",
       "<td>0.7142857</td>\n",
       "<td>0.6214567</td>\n",
       "<td>0.4</td>\n",
       "<td>1.0</td>\n",
       "<td>833.3333333</td>\n",
       "<td>900.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1571429</td>\n",
       "<td>0.0004963</td>\n",
       "<td>0.0</td>\n",
       "<td>6.3636364</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0011425</td>\n",
       "<td>0.4545455</td>\n",
       "<td>0.3958879</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>536.3636364</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.0004228</td>\n",
       "<td>0.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004472</td>\n",
       "<td>0.3571429</td>\n",
       "<td>0.3111506</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>400.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.6142857</td>\n",
       "<td>0.0004228</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6279070</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004228</td>\n",
       "<td>0.1162791</td>\n",
       "<td>0.1015900</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>62.7906977</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.8571429</td>\n",
       "<td>0.0004228</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1666667</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004228</td>\n",
       "<td>0.0833333</td>\n",
       "<td>0.0729259</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>16.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.9142857</td>\n",
       "<td>0.0004228</td>\n",
       "<td>0.0</td>\n",
       "<td>1.09375</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004228</td>\n",
       "<td>0.078125</td>\n",
       "<td>0.0683945</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>9.375</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0003550</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0003971</td>\n",
       "<td>0.0714286</td>\n",
       "<td>0.0625662</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0142857                   0.995208           14       14                 1                0.995641     1                           0.995641            0.2             0.2                        1300     1300\n",
       "    2        0.0285714                   0.981404           14       14                 1                0.995013     1                           0.995327            0.2             0.4                        1300     1300\n",
       "    3        0.0428571                   0.957482           14       14                 1                0.959199     1                           0.983285            0.2             0.6                        1300     1300\n",
       "    4        0.0428571                   0.940555           0        14                 0                0            1                           0.983285            0               0.6                        -100     1300\n",
       "    5        0.0571429                   0.652722           0        10.5               0                0.934667     0.75                        0.97113             0               0.6                        -100     950\n",
       "    6        0.1                         0.00211785         9.33333  10                 0.666667         0.155225     0.714286                    0.621457            0.4             1                          833.333  900\n",
       "    7        0.157143                    0.000496272        0        6.36364            0                0.00114254   0.454545                    0.395888            0               1                          -100     536.364\n",
       "    8        0.2                         0.000422806        0        5                  0                0.000447153  0.357143                    0.311151            0               1                          -100     400\n",
       "    9        0.614286                    0.000422789        0        1.62791            0                0.00042279   0.116279                    0.10159             0               1                          -100     62.7907\n",
       "    10       0.857143                    0.000422789        0        1.16667            0                0.000422789  0.0833333                   0.0729259           0               1                          -100     16.6667\n",
       "    11       0.914286                    0.000422789        0        1.09375            0                0.000422789  0.078125                    0.0683945           0               1                          -100     9.375\n",
       "    12       1                           0.000355018        0        1                  0                0.000397081  0.0714286                   0.0625662           0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref = gbm_model2.model_performance(test)\n",
    "pref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For GBM_model2 the AUC is 1.0 on the training data and 0.9938461538461537 on the testing data. The model is a good fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "dp_model2 = H2ODeepLearningEstimator(\n",
    "    model_id=\"binarydl\",\n",
    "    hidden=[50,50],           \n",
    "    epochs=50,                 \n",
    "    ignore_const_cols=False, \n",
    "    sparse=True,              \n",
    "    variable_importances=True,\n",
    "    nfolds=5\n",
    ")\n",
    "dp_model2.train(x=X,y = y, training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0017322272893664052\n",
      "RMSE: 0.04162003471125902\n",
      "LogLoss: 0.005261979465508856\n",
      "Mean Per-Class Error: 0.0\n",
      "AUC: 1.0\n",
      "Gini: 1.0\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9980002677725678: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>False</b></td>\n",
       "<td><b>True</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>False</td>\n",
       "<td>610.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/610.0)</td></tr>\n",
       "<tr><td>True</td>\n",
       "<td>0.0</td>\n",
       "<td>41.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/41.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>610.0</td>\n",
       "<td>41.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/651.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       False    True    Error    Rate\n",
       "-----  -------  ------  -------  -----------\n",
       "False  610      0       0        (0.0/610.0)\n",
       "True   0        41      0        (0.0/41.0)\n",
       "Total  610      41      0        (0.0/651.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.9980003</td>\n",
       "<td>1.0</td>\n",
       "<td>36.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.9980003</td>\n",
       "<td>1.0</td>\n",
       "<td>36.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9980003</td>\n",
       "<td>1.0</td>\n",
       "<td>36.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9980003</td>\n",
       "<td>1.0</td>\n",
       "<td>36.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.9980003</td>\n",
       "<td>1.0</td>\n",
       "<td>36.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.9980003</td>\n",
       "<td>1.0</td>\n",
       "<td>36.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.9980003</td>\n",
       "<td>1.0</td>\n",
       "<td>36.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.9980003</td>\n",
       "<td>1.0</td>\n",
       "<td>36.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value    idx\n",
       "---------------------------  -----------  -------  -----\n",
       "max f1                       0.998        1        36\n",
       "max f2                       0.998        1        36\n",
       "max f0point5                 0.998        1        36\n",
       "max accuracy                 0.998        1        36\n",
       "max precision                1            1        0\n",
       "max recall                   0.998        1        36\n",
       "max specificity              1            1        0\n",
       "max absolute_mcc             0.998        1        36\n",
       "max min_per_class_accuracy   0.998        1        36\n",
       "max mean_per_class_accuracy  0.998        1        36"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  6.30 %, avg score:  6.55 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0107527</td>\n",
       "<td>0.9999991</td>\n",
       "<td>15.8780488</td>\n",
       "<td>15.8780488</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999998</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999998</td>\n",
       "<td>0.1707317</td>\n",
       "<td>0.1707317</td>\n",
       "<td>1487.8048780</td>\n",
       "<td>1487.8048780</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0215054</td>\n",
       "<td>0.9999976</td>\n",
       "<td>15.8780488</td>\n",
       "<td>15.8780488</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999986</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999992</td>\n",
       "<td>0.1707317</td>\n",
       "<td>0.3414634</td>\n",
       "<td>1487.8048780</td>\n",
       "<td>1487.8048780</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0307220</td>\n",
       "<td>0.9999894</td>\n",
       "<td>15.8780488</td>\n",
       "<td>15.8780488</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999977</td>\n",
       "<td>0.1463415</td>\n",
       "<td>0.4878049</td>\n",
       "<td>1487.8048780</td>\n",
       "<td>1487.8048780</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0414747</td>\n",
       "<td>0.9999410</td>\n",
       "<td>15.8780488</td>\n",
       "<td>15.8780488</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999730</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999913</td>\n",
       "<td>0.1707317</td>\n",
       "<td>0.6585366</td>\n",
       "<td>1487.8048780</td>\n",
       "<td>1487.8048780</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0506912</td>\n",
       "<td>0.9994098</td>\n",
       "<td>15.8780488</td>\n",
       "<td>15.8780488</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998373</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999633</td>\n",
       "<td>0.1463415</td>\n",
       "<td>0.8048780</td>\n",
       "<td>1487.8048780</td>\n",
       "<td>1487.8048780</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1013825</td>\n",
       "<td>0.0000246</td>\n",
       "<td>3.8492239</td>\n",
       "<td>9.8636364</td>\n",
       "<td>0.2424242</td>\n",
       "<td>0.2915615</td>\n",
       "<td>0.6212121</td>\n",
       "<td>0.6457624</td>\n",
       "<td>0.1951220</td>\n",
       "<td>1.0</td>\n",
       "<td>284.9223947</td>\n",
       "<td>886.3636364</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1505376</td>\n",
       "<td>0.0000005</td>\n",
       "<td>0.0</td>\n",
       "<td>6.6428571</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000054</td>\n",
       "<td>0.4183673</td>\n",
       "<td>0.4349030</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>564.2857143</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2012289</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>4.9694656</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000002</td>\n",
       "<td>0.3129771</td>\n",
       "<td>0.3253473</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>396.9465649</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3010753</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3214286</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.2091837</td>\n",
       "<td>0.2174515</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>232.1428571</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4009217</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>2.4942529</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1570881</td>\n",
       "<td>0.1632969</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>149.4252874</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5007680</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9969325</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1257669</td>\n",
       "<td>0.1307377</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>99.6932515</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6006144</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6649616</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1048593</td>\n",
       "<td>0.1090038</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.4961637</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7004608</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4276316</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0899123</td>\n",
       "<td>0.0934660</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.7631579</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8003072</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2495202</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0786948</td>\n",
       "<td>0.0818052</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.9520154</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9001536</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1109215</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0699659</td>\n",
       "<td>0.0727312</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.0921502</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0629800</td>\n",
       "<td>0.0654693</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0107527                   0.999999           15.878   15.878             1                1            1                           1                   0.170732        0.170732                   1487.8   1487.8\n",
       "    2        0.0215054                   0.999998           15.878   15.878             1                0.999999     1                           0.999999            0.170732        0.341463                   1487.8   1487.8\n",
       "    3        0.030722                    0.999989           15.878   15.878             1                0.999994     1                           0.999998            0.146341        0.487805                   1487.8   1487.8\n",
       "    4        0.0414747                   0.999941           15.878   15.878             1                0.999973     1                           0.999991            0.170732        0.658537                   1487.8   1487.8\n",
       "    5        0.0506912                   0.99941            15.878   15.878             1                0.999837     1                           0.999963            0.146341        0.804878                   1487.8   1487.8\n",
       "    6        0.101382                    2.45566e-05        3.84922  9.86364            0.242424         0.291562     0.621212                    0.645762            0.195122        1                          284.922  886.364\n",
       "    7        0.150538                    4.86598e-07        0        6.64286            0                5.38649e-06  0.418367                    0.434903            0               1                          -100     564.286\n",
       "    8        0.201229                    4.89834e-08        0        4.96947            0                1.89119e-07  0.312977                    0.325347            0               1                          -100     396.947\n",
       "    9        0.301075                    2.44387e-09        0        3.32143            0                1.63498e-08  0.209184                    0.217452            0               1                          -100     232.143\n",
       "    10       0.400922                    1.43716e-10        0        2.49425            0                8.08068e-10  0.157088                    0.163297            0               1                          -100     149.425\n",
       "    11       0.500768                    5.88099e-12        0        1.99693            0                3.97445e-11  0.125767                    0.130738            0               1                          -100     99.6933\n",
       "    12       0.600614                    9.56765e-14        0        1.66496            0                1.6704e-12   0.104859                    0.109004            0               1                          -100     66.4962\n",
       "    13       0.700461                    2.37226e-17        0        1.42763            0                1.05206e-14  0.0899123                   0.093466            0               1                          -100     42.7632\n",
       "    14       0.800307                    9.0541e-21         0        1.24952            0                3.61381e-18  0.0786948                   0.0818052           0               1                          -100     24.952\n",
       "    15       0.900154                    5.6261e-24         0        1.11092            0                1.25549e-21  0.0699659                   0.0727312           0               1                          -100     11.0922\n",
       "    16       1                           4.35246e-29        0        1                  0                5.67257e-25  0.06298                     0.0654693           0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_model2.model_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning prediction progress: |███████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>predict  </th><th style=\"text-align: right;\">  False</th><th style=\"text-align: right;\">       True</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">1.32022e-09</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">5.04548e-13</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">1.22693e-19</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">1.21777e-12</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">5.91311e-26</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">9.51703e-12</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">3.99544e-08</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">6.92679e-16</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">3.17491e-14</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">2.01056e-15</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = dp_model2.predict(test)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.02131580882386662\n",
      "RMSE: 0.14599934528574646\n",
      "LogLoss: 0.14965262083867245\n",
      "Mean Per-Class Error: 0.007692307692307665\n",
      "AUC: 0.9907692307692308\n",
      "Gini: 0.9815384615384617\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3364101346076135: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>False</b></td>\n",
       "<td><b>True</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>False</td>\n",
       "<td>64.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0154</td>\n",
       "<td> (1.0/65.0)</td></tr>\n",
       "<tr><td>True</td>\n",
       "<td>0.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/5.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>64.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.0143</td>\n",
       "<td> (1.0/70.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       False    True    Error    Rate\n",
       "-----  -------  ------  -------  ----------\n",
       "False  64       1       0.0154   (1.0/65.0)\n",
       "True   0        5       0        (0.0/5.0)\n",
       "Total  64       6       0.0143   (1.0/70.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3364101</td>\n",
       "<td>0.9090909</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3364101</td>\n",
       "<td>0.9615385</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3364101</td>\n",
       "<td>0.8620690</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3364101</td>\n",
       "<td>0.9857143</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.3364101</td>\n",
       "<td>1.0</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3364101</td>\n",
       "<td>0.9058216</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3364101</td>\n",
       "<td>0.9846154</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3364101</td>\n",
       "<td>0.9923077</td>\n",
       "<td>5.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.33641      0.909091  5\n",
       "max f2                       0.33641      0.961538  5\n",
       "max f0point5                 0.33641      0.862069  5\n",
       "max accuracy                 0.33641      0.985714  5\n",
       "max precision                1            1         0\n",
       "max recall                   0.33641      1         5\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.33641      0.905822  5\n",
       "max min_per_class_accuracy   0.33641      0.984615  5\n",
       "max mean_per_class_accuracy  0.33641      0.992308  5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  7.14 %, avg score:  7.17 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0142857</td>\n",
       "<td>0.9999984</td>\n",
       "<td>14.0</td>\n",
       "<td>14.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.2</td>\n",
       "<td>0.2</td>\n",
       "<td>1300.0</td>\n",
       "<td>1300.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0285714</td>\n",
       "<td>0.9999534</td>\n",
       "<td>14.0</td>\n",
       "<td>14.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999976</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999988</td>\n",
       "<td>0.2</td>\n",
       "<td>0.4</td>\n",
       "<td>1300.0</td>\n",
       "<td>1300.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0428571</td>\n",
       "<td>0.9905048</td>\n",
       "<td>0.0</td>\n",
       "<td>9.3333333</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9998812</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.9999596</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4</td>\n",
       "<td>-100.0</td>\n",
       "<td>833.3333333</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0428571</td>\n",
       "<td>0.8980805</td>\n",
       "<td>0.0</td>\n",
       "<td>9.3333333</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.9999596</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4</td>\n",
       "<td>-100.0</td>\n",
       "<td>833.3333333</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0571429</td>\n",
       "<td>0.8432645</td>\n",
       "<td>14.0</td>\n",
       "<td>10.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8659330</td>\n",
       "<td>0.75</td>\n",
       "<td>0.9664529</td>\n",
       "<td>0.2</td>\n",
       "<td>0.6</td>\n",
       "<td>1300.0</td>\n",
       "<td>950.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.0000807</td>\n",
       "<td>9.3333333</td>\n",
       "<td>10.0</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.3841011</td>\n",
       "<td>0.7142857</td>\n",
       "<td>0.7168736</td>\n",
       "<td>0.4</td>\n",
       "<td>1.0</td>\n",
       "<td>833.3333333</td>\n",
       "<td>900.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1571429</td>\n",
       "<td>0.0000005</td>\n",
       "<td>0.0</td>\n",
       "<td>6.3636364</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000258</td>\n",
       "<td>0.4545455</td>\n",
       "<td>0.4562017</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>536.3636364</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.3571429</td>\n",
       "<td>0.3584442</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>400.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3333333</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.2380952</td>\n",
       "<td>0.2389628</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>233.3333333</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>2.5</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1785714</td>\n",
       "<td>0.1792221</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>150.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1428571</td>\n",
       "<td>0.1433777</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6666667</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1190476</td>\n",
       "<td>0.1194814</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285714</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1020408</td>\n",
       "<td>0.1024126</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.25</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0892857</td>\n",
       "<td>0.0896110</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1111111</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0793651</td>\n",
       "<td>0.0796543</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0714286</td>\n",
       "<td>0.0716888</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0142857                   0.999998           14       14                 1                1            1                           1                   0.2             0.2                        1300     1300\n",
       "    2        0.0285714                   0.999953           14       14                 1                0.999998     1                           0.999999            0.2             0.4                        1300     1300\n",
       "    3        0.0428571                   0.990505           0        9.33333            0                0.999881     0.666667                    0.99996             0               0.4                        -100     833.333\n",
       "    4        0.0428571                   0.898081           0        9.33333            0                0            0.666667                    0.99996             0               0.4                        -100     833.333\n",
       "    5        0.0571429                   0.843265           14       10.5               1                0.865933     0.75                        0.966453            0.2             0.6                        1300     950\n",
       "    6        0.1                         8.06657e-05        9.33333  10                 0.666667         0.384101     0.714286                    0.716874            0.4             1                          833.333  900\n",
       "    7        0.157143                    4.8708e-07         0        6.36364            0                2.57771e-05  0.454545                    0.456202            0               1                          -100     536.364\n",
       "    8        0.2                         2.76567e-08        0        5                  0                5.93225e-08  0.357143                    0.358444            0               1                          -100     400\n",
       "    9        0.3                         1.66356e-09        0        3.33333            0                1.23802e-08  0.238095                    0.238963            0               1                          -100     233.333\n",
       "    10       0.4                         4.36816e-11        0        2.5                0                4.04129e-10  0.178571                    0.179222            0               1                          -100     150\n",
       "    11       0.5                         4.62023e-12        0        2                  0                2.42202e-11  0.142857                    0.143378            0               1                          -100     100\n",
       "    12       0.6                         5.23461e-15        0        1.66667            0                1.15132e-12  0.119048                    0.119481            0               1                          -100     66.6667\n",
       "    13       0.7                         1.84015e-16        0        1.42857            0                1.0709e-15   0.102041                    0.102413            0               1                          -100     42.8571\n",
       "    14       0.8                         1.95081e-20        0        1.25               0                7.04918e-19  0.0892857                   0.089611            0               1                          -100     25\n",
       "    15       0.9                         2.31726e-23        0        1.11111            0                1.3264e-21   0.0793651                   0.0796543           0               1                          -100     11.1111\n",
       "    16       1                           1.80532e-27        0        1                  0                5.61576e-24  0.0714286                   0.0716888           0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref = dp_model2.model_performance(test)\n",
    "pref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For deep learning model2, the auc for train data is 1.0, and for test data is 0.9907692307692308, they are pretty much the same. We can say that the model is a good fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aml = H2OAutoML(max_runtime_secs=run_time,project_name=name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "aml.train(x=X,y=y,training_frame = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aml_ld_df = aml.leaderboard.as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>auc</th>\n",
       "      <th>logloss</th>\n",
       "      <th>mean_per_class_error</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_53</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.015883</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.066598</td>\n",
       "      <td>0.004435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_101</td>\n",
       "      <td>0.999571</td>\n",
       "      <td>0.025978</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.074863</td>\n",
       "      <td>0.005605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_15</td>\n",
       "      <td>0.999510</td>\n",
       "      <td>0.017232</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.074105</td>\n",
       "      <td>0.005492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_7</td>\n",
       "      <td>0.999449</td>\n",
       "      <td>0.025085</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.074845</td>\n",
       "      <td>0.005602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_83</td>\n",
       "      <td>0.999449</td>\n",
       "      <td>0.015334</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.065632</td>\n",
       "      <td>0.004308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_5</td>\n",
       "      <td>0.999449</td>\n",
       "      <td>0.041479</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.075218</td>\n",
       "      <td>0.005658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_12</td>\n",
       "      <td>0.999388</td>\n",
       "      <td>0.018835</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.072138</td>\n",
       "      <td>0.005204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_108</td>\n",
       "      <td>0.999388</td>\n",
       "      <td>0.036729</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.079549</td>\n",
       "      <td>0.006328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_105</td>\n",
       "      <td>0.999388</td>\n",
       "      <td>0.018077</td>\n",
       "      <td>0.017172</td>\n",
       "      <td>0.072474</td>\n",
       "      <td>0.005253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_72</td>\n",
       "      <td>0.999388</td>\n",
       "      <td>0.020007</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.073390</td>\n",
       "      <td>0.005386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_49</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.017750</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.070056</td>\n",
       "      <td>0.004908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>StackedEnsemble_BestOfFamily_0_AutoML_20181015...</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.014549</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.062786</td>\n",
       "      <td>0.003942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_20</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.016681</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.063237</td>\n",
       "      <td>0.003999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_8</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.018560</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.071525</td>\n",
       "      <td>0.005116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_91</td>\n",
       "      <td>0.999265</td>\n",
       "      <td>0.017536</td>\n",
       "      <td>0.031313</td>\n",
       "      <td>0.071326</td>\n",
       "      <td>0.005087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_99</td>\n",
       "      <td>0.999265</td>\n",
       "      <td>0.017083</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.073167</td>\n",
       "      <td>0.005353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_98</td>\n",
       "      <td>0.999265</td>\n",
       "      <td>0.017615</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.070334</td>\n",
       "      <td>0.004947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_107</td>\n",
       "      <td>0.999265</td>\n",
       "      <td>0.019266</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.075014</td>\n",
       "      <td>0.005627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_109</td>\n",
       "      <td>0.999235</td>\n",
       "      <td>0.020750</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.076364</td>\n",
       "      <td>0.005832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_97</td>\n",
       "      <td>0.999204</td>\n",
       "      <td>0.023978</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.065369</td>\n",
       "      <td>0.004273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_9</td>\n",
       "      <td>0.999204</td>\n",
       "      <td>0.024283</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.073766</td>\n",
       "      <td>0.005441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_34</td>\n",
       "      <td>0.999204</td>\n",
       "      <td>0.017874</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.076792</td>\n",
       "      <td>0.005897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_59</td>\n",
       "      <td>0.999143</td>\n",
       "      <td>0.061201</td>\n",
       "      <td>0.031313</td>\n",
       "      <td>0.087077</td>\n",
       "      <td>0.007582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_87</td>\n",
       "      <td>0.999082</td>\n",
       "      <td>0.018538</td>\n",
       "      <td>0.017172</td>\n",
       "      <td>0.073218</td>\n",
       "      <td>0.005361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_66</td>\n",
       "      <td>0.999082</td>\n",
       "      <td>0.032330</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.083115</td>\n",
       "      <td>0.006908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_33</td>\n",
       "      <td>0.999082</td>\n",
       "      <td>0.018839</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.071435</td>\n",
       "      <td>0.005103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_81</td>\n",
       "      <td>0.999021</td>\n",
       "      <td>0.207232</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.234266</td>\n",
       "      <td>0.054881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_64</td>\n",
       "      <td>0.999021</td>\n",
       "      <td>0.030983</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.081954</td>\n",
       "      <td>0.006716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_69</td>\n",
       "      <td>0.999021</td>\n",
       "      <td>0.026801</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.076906</td>\n",
       "      <td>0.005915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_56</td>\n",
       "      <td>0.999021</td>\n",
       "      <td>0.019546</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.072322</td>\n",
       "      <td>0.005230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_37</td>\n",
       "      <td>0.996480</td>\n",
       "      <td>0.053632</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.105610</td>\n",
       "      <td>0.011153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_4</td>\n",
       "      <td>0.996480</td>\n",
       "      <td>0.032765</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.093957</td>\n",
       "      <td>0.008828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_60</td>\n",
       "      <td>0.996388</td>\n",
       "      <td>0.216966</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.237478</td>\n",
       "      <td>0.056396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_22</td>\n",
       "      <td>0.996143</td>\n",
       "      <td>0.046037</td>\n",
       "      <td>0.021212</td>\n",
       "      <td>0.112656</td>\n",
       "      <td>0.012691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_106</td>\n",
       "      <td>0.996113</td>\n",
       "      <td>0.216131</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.237221</td>\n",
       "      <td>0.056274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_43</td>\n",
       "      <td>0.996051</td>\n",
       "      <td>0.036770</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.097811</td>\n",
       "      <td>0.009567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_35</td>\n",
       "      <td>0.996021</td>\n",
       "      <td>0.214312</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.236645</td>\n",
       "      <td>0.056001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_92</td>\n",
       "      <td>0.995470</td>\n",
       "      <td>0.189717</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.107617</td>\n",
       "      <td>0.011581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>XRT_0_AutoML_20181015_212135</td>\n",
       "      <td>0.995133</td>\n",
       "      <td>0.049093</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.121082</td>\n",
       "      <td>0.014661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_96</td>\n",
       "      <td>0.994735</td>\n",
       "      <td>0.209981</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.235208</td>\n",
       "      <td>0.055323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_19</td>\n",
       "      <td>0.993695</td>\n",
       "      <td>0.209171</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.234923</td>\n",
       "      <td>0.055189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_54</td>\n",
       "      <td>0.992746</td>\n",
       "      <td>0.076599</td>\n",
       "      <td>0.065657</td>\n",
       "      <td>0.126432</td>\n",
       "      <td>0.015985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_55</td>\n",
       "      <td>0.991368</td>\n",
       "      <td>0.209325</td>\n",
       "      <td>0.024242</td>\n",
       "      <td>0.234926</td>\n",
       "      <td>0.055190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_46</td>\n",
       "      <td>0.991368</td>\n",
       "      <td>0.106808</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.168023</td>\n",
       "      <td>0.028232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>DeepLearning_0_AutoML_20181015_212135</td>\n",
       "      <td>0.991307</td>\n",
       "      <td>0.055087</td>\n",
       "      <td>0.025253</td>\n",
       "      <td>0.127337</td>\n",
       "      <td>0.016215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_57</td>\n",
       "      <td>0.990419</td>\n",
       "      <td>0.102001</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.162944</td>\n",
       "      <td>0.026551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_62</td>\n",
       "      <td>0.987818</td>\n",
       "      <td>0.212631</td>\n",
       "      <td>0.103030</td>\n",
       "      <td>0.236170</td>\n",
       "      <td>0.055776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_27</td>\n",
       "      <td>0.986777</td>\n",
       "      <td>0.138730</td>\n",
       "      <td>0.067677</td>\n",
       "      <td>0.197334</td>\n",
       "      <td>0.038941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_74</td>\n",
       "      <td>0.984267</td>\n",
       "      <td>0.204848</td>\n",
       "      <td>0.126263</td>\n",
       "      <td>0.233596</td>\n",
       "      <td>0.054567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_47</td>\n",
       "      <td>0.975880</td>\n",
       "      <td>0.213011</td>\n",
       "      <td>0.134343</td>\n",
       "      <td>0.236266</td>\n",
       "      <td>0.055822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_11</td>\n",
       "      <td>0.970003</td>\n",
       "      <td>0.163869</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.087045</td>\n",
       "      <td>0.007577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_24</td>\n",
       "      <td>0.940159</td>\n",
       "      <td>1.129129</td>\n",
       "      <td>0.046465</td>\n",
       "      <td>0.187986</td>\n",
       "      <td>0.035339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_18</td>\n",
       "      <td>0.916131</td>\n",
       "      <td>0.338217</td>\n",
       "      <td>0.047475</td>\n",
       "      <td>0.107978</td>\n",
       "      <td>0.011659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_51</td>\n",
       "      <td>0.903887</td>\n",
       "      <td>1.831602</td>\n",
       "      <td>0.084848</td>\n",
       "      <td>0.230283</td>\n",
       "      <td>0.053030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_45</td>\n",
       "      <td>0.903306</td>\n",
       "      <td>1.166755</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.184658</td>\n",
       "      <td>0.034098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_90</td>\n",
       "      <td>0.898806</td>\n",
       "      <td>1.844052</td>\n",
       "      <td>0.085859</td>\n",
       "      <td>0.234348</td>\n",
       "      <td>0.054919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_28</td>\n",
       "      <td>0.876645</td>\n",
       "      <td>0.228931</td>\n",
       "      <td>0.225253</td>\n",
       "      <td>0.240851</td>\n",
       "      <td>0.058009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_80</td>\n",
       "      <td>0.865014</td>\n",
       "      <td>1.439116</td>\n",
       "      <td>0.092929</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_38</td>\n",
       "      <td>0.861065</td>\n",
       "      <td>1.504530</td>\n",
       "      <td>0.108081</td>\n",
       "      <td>0.208712</td>\n",
       "      <td>0.043561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_212135_model_10</td>\n",
       "      <td>0.857361</td>\n",
       "      <td>1.308287</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.194625</td>\n",
       "      <td>0.037879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              model_id       auc   logloss  \\\n",
       "0           GBM_grid_0_AutoML_20181015_212135_model_53  0.999878  0.015883   \n",
       "1          GBM_grid_0_AutoML_20181015_212135_model_101  0.999571  0.025978   \n",
       "2           GBM_grid_0_AutoML_20181015_212135_model_15  0.999510  0.017232   \n",
       "3            GBM_grid_0_AutoML_20181015_212135_model_7  0.999449  0.025085   \n",
       "4           GBM_grid_0_AutoML_20181015_212135_model_83  0.999449  0.015334   \n",
       "5            GBM_grid_0_AutoML_20181015_212135_model_5  0.999449  0.041479   \n",
       "6           GBM_grid_0_AutoML_20181015_212135_model_12  0.999388  0.018835   \n",
       "7          GBM_grid_0_AutoML_20181015_212135_model_108  0.999388  0.036729   \n",
       "8          GBM_grid_0_AutoML_20181015_212135_model_105  0.999388  0.018077   \n",
       "9           GBM_grid_0_AutoML_20181015_212135_model_72  0.999388  0.020007   \n",
       "10          GBM_grid_0_AutoML_20181015_212135_model_49  0.999327  0.017750   \n",
       "11   StackedEnsemble_BestOfFamily_0_AutoML_20181015...  0.999327  0.014549   \n",
       "12          GBM_grid_0_AutoML_20181015_212135_model_20  0.999327  0.016681   \n",
       "13           GBM_grid_0_AutoML_20181015_212135_model_8  0.999327  0.018560   \n",
       "14          GBM_grid_0_AutoML_20181015_212135_model_91  0.999265  0.017536   \n",
       "15          GBM_grid_0_AutoML_20181015_212135_model_99  0.999265  0.017083   \n",
       "16          GBM_grid_0_AutoML_20181015_212135_model_98  0.999265  0.017615   \n",
       "17         GBM_grid_0_AutoML_20181015_212135_model_107  0.999265  0.019266   \n",
       "18         GBM_grid_0_AutoML_20181015_212135_model_109  0.999235  0.020750   \n",
       "19          GBM_grid_0_AutoML_20181015_212135_model_97  0.999204  0.023978   \n",
       "20           GBM_grid_0_AutoML_20181015_212135_model_9  0.999204  0.024283   \n",
       "21          GBM_grid_0_AutoML_20181015_212135_model_34  0.999204  0.017874   \n",
       "22          GBM_grid_0_AutoML_20181015_212135_model_59  0.999143  0.061201   \n",
       "23          GBM_grid_0_AutoML_20181015_212135_model_87  0.999082  0.018538   \n",
       "24          GBM_grid_0_AutoML_20181015_212135_model_66  0.999082  0.032330   \n",
       "25          GBM_grid_0_AutoML_20181015_212135_model_33  0.999082  0.018839   \n",
       "26          GBM_grid_0_AutoML_20181015_212135_model_81  0.999021  0.207232   \n",
       "27          GBM_grid_0_AutoML_20181015_212135_model_64  0.999021  0.030983   \n",
       "28          GBM_grid_0_AutoML_20181015_212135_model_69  0.999021  0.026801   \n",
       "29          GBM_grid_0_AutoML_20181015_212135_model_56  0.999021  0.019546   \n",
       "..                                                 ...       ...       ...   \n",
       "90          GBM_grid_0_AutoML_20181015_212135_model_37  0.996480  0.053632   \n",
       "91           GBM_grid_0_AutoML_20181015_212135_model_4  0.996480  0.032765   \n",
       "92          GBM_grid_0_AutoML_20181015_212135_model_60  0.996388  0.216966   \n",
       "93          GBM_grid_0_AutoML_20181015_212135_model_22  0.996143  0.046037   \n",
       "94         GBM_grid_0_AutoML_20181015_212135_model_106  0.996113  0.216131   \n",
       "95          GBM_grid_0_AutoML_20181015_212135_model_43  0.996051  0.036770   \n",
       "96          GBM_grid_0_AutoML_20181015_212135_model_35  0.996021  0.214312   \n",
       "97          GBM_grid_0_AutoML_20181015_212135_model_92  0.995470  0.189717   \n",
       "98                        XRT_0_AutoML_20181015_212135  0.995133  0.049093   \n",
       "99          GBM_grid_0_AutoML_20181015_212135_model_96  0.994735  0.209981   \n",
       "100         GBM_grid_0_AutoML_20181015_212135_model_19  0.993695  0.209171   \n",
       "101         GBM_grid_0_AutoML_20181015_212135_model_54  0.992746  0.076599   \n",
       "102         GBM_grid_0_AutoML_20181015_212135_model_55  0.991368  0.209325   \n",
       "103         GBM_grid_0_AutoML_20181015_212135_model_46  0.991368  0.106808   \n",
       "104              DeepLearning_0_AutoML_20181015_212135  0.991307  0.055087   \n",
       "105         GBM_grid_0_AutoML_20181015_212135_model_57  0.990419  0.102001   \n",
       "106         GBM_grid_0_AutoML_20181015_212135_model_62  0.987818  0.212631   \n",
       "107         GBM_grid_0_AutoML_20181015_212135_model_27  0.986777  0.138730   \n",
       "108         GBM_grid_0_AutoML_20181015_212135_model_74  0.984267  0.204848   \n",
       "109         GBM_grid_0_AutoML_20181015_212135_model_47  0.975880  0.213011   \n",
       "110         GBM_grid_0_AutoML_20181015_212135_model_11  0.970003  0.163869   \n",
       "111         GBM_grid_0_AutoML_20181015_212135_model_24  0.940159  1.129129   \n",
       "112         GBM_grid_0_AutoML_20181015_212135_model_18  0.916131  0.338217   \n",
       "113         GBM_grid_0_AutoML_20181015_212135_model_51  0.903887  1.831602   \n",
       "114         GBM_grid_0_AutoML_20181015_212135_model_45  0.903306  1.166755   \n",
       "115         GBM_grid_0_AutoML_20181015_212135_model_90  0.898806  1.844052   \n",
       "116         GBM_grid_0_AutoML_20181015_212135_model_28  0.876645  0.228931   \n",
       "117         GBM_grid_0_AutoML_20181015_212135_model_80  0.865014  1.439116   \n",
       "118         GBM_grid_0_AutoML_20181015_212135_model_38  0.861065  1.504530   \n",
       "119         GBM_grid_0_AutoML_20181015_212135_model_10  0.857361  1.308287   \n",
       "\n",
       "     mean_per_class_error      rmse       mse  \n",
       "0                0.015152  0.066598  0.004435  \n",
       "1                0.002020  0.074863  0.005605  \n",
       "2                0.003030  0.074105  0.005492  \n",
       "3                0.003030  0.074845  0.005602  \n",
       "4                0.002020  0.065632  0.004308  \n",
       "5                0.003030  0.075218  0.005658  \n",
       "6                0.003030  0.072138  0.005204  \n",
       "7                0.003030  0.079549  0.006328  \n",
       "8                0.017172  0.072474  0.005253  \n",
       "9                0.002020  0.073390  0.005386  \n",
       "10               0.002020  0.070056  0.004908  \n",
       "11               0.002020  0.062786  0.003942  \n",
       "12               0.002020  0.063237  0.003999  \n",
       "13               0.002020  0.071525  0.005116  \n",
       "14               0.031313  0.071326  0.005087  \n",
       "15               0.003030  0.073167  0.005353  \n",
       "16               0.002020  0.070334  0.004947  \n",
       "17               0.002020  0.075014  0.005627  \n",
       "18               0.002020  0.076364  0.005832  \n",
       "19               0.002020  0.065369  0.004273  \n",
       "20               0.002020  0.073766  0.005441  \n",
       "21               0.002020  0.076792  0.005897  \n",
       "22               0.031313  0.087077  0.007582  \n",
       "23               0.017172  0.073218  0.005361  \n",
       "24               0.003030  0.083115  0.006908  \n",
       "25               0.002020  0.071435  0.005103  \n",
       "26               0.004040  0.234266  0.054881  \n",
       "27               0.003030  0.081954  0.006716  \n",
       "28               0.003030  0.076906  0.005915  \n",
       "29               0.002020  0.072322  0.005230  \n",
       "..                    ...       ...       ...  \n",
       "90               0.004040  0.105610  0.011153  \n",
       "91               0.003030  0.093957  0.008828  \n",
       "92               0.004040  0.237478  0.056396  \n",
       "93               0.021212  0.112656  0.012691  \n",
       "94               0.004040  0.237221  0.056274  \n",
       "95               0.004040  0.097811  0.009567  \n",
       "96               0.018182  0.236645  0.056001  \n",
       "97               0.005051  0.107617  0.011581  \n",
       "98               0.006061  0.121082  0.014661  \n",
       "99               0.020202  0.235208  0.055323  \n",
       "100              0.009091  0.234923  0.055189  \n",
       "101              0.065657  0.126432  0.015985  \n",
       "102              0.024242  0.234926  0.055190  \n",
       "103              0.066667  0.168023  0.028232  \n",
       "104              0.025253  0.127337  0.016215  \n",
       "105              0.109091  0.162944  0.026551  \n",
       "106              0.103030  0.236170  0.055776  \n",
       "107              0.067677  0.197334  0.038941  \n",
       "108              0.126263  0.233596  0.054567  \n",
       "109              0.134343  0.236266  0.055822  \n",
       "110              0.018182  0.087045  0.007577  \n",
       "111              0.046465  0.187986  0.035339  \n",
       "112              0.047475  0.107978  0.011659  \n",
       "113              0.084848  0.230283  0.053030  \n",
       "114              0.060606  0.184658  0.034098  \n",
       "115              0.085859  0.234348  0.054919  \n",
       "116              0.225253  0.240851  0.058009  \n",
       "117              0.092929  0.204124  0.041667  \n",
       "118              0.108081  0.208712  0.043561  \n",
       "119              0.090909  0.194625  0.037879  \n",
       "\n",
       "[120 rows x 6 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml_ld_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                   </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">     rmse</th><th style=\"text-align: right;\">       mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GBM_grid_0_AutoML_20181015_212135_model_53 </td><td style=\"text-align: right;\">0.999878</td><td style=\"text-align: right;\">0.0158831</td><td style=\"text-align: right;\">             0.0151515</td><td style=\"text-align: right;\">0.0665984</td><td style=\"text-align: right;\">0.00443535</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20181015_212135_model_101</td><td style=\"text-align: right;\">0.999571</td><td style=\"text-align: right;\">0.0259778</td><td style=\"text-align: right;\">             0.0020202</td><td style=\"text-align: right;\">0.0748632</td><td style=\"text-align: right;\">0.0056045 </td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20181015_212135_model_15 </td><td style=\"text-align: right;\">0.99951 </td><td style=\"text-align: right;\">0.0172318</td><td style=\"text-align: right;\">             0.0030303</td><td style=\"text-align: right;\">0.0741049</td><td style=\"text-align: right;\">0.00549154</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20181015_212135_model_7  </td><td style=\"text-align: right;\">0.999449</td><td style=\"text-align: right;\">0.0250848</td><td style=\"text-align: right;\">             0.0030303</td><td style=\"text-align: right;\">0.0748447</td><td style=\"text-align: right;\">0.00560173</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20181015_212135_model_83 </td><td style=\"text-align: right;\">0.999449</td><td style=\"text-align: right;\">0.0153339</td><td style=\"text-align: right;\">             0.0020202</td><td style=\"text-align: right;\">0.0656322</td><td style=\"text-align: right;\">0.00430759</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20181015_212135_model_5  </td><td style=\"text-align: right;\">0.999449</td><td style=\"text-align: right;\">0.0414791</td><td style=\"text-align: right;\">             0.0030303</td><td style=\"text-align: right;\">0.0752182</td><td style=\"text-align: right;\">0.00565778</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20181015_212135_model_12 </td><td style=\"text-align: right;\">0.999388</td><td style=\"text-align: right;\">0.0188354</td><td style=\"text-align: right;\">             0.0030303</td><td style=\"text-align: right;\">0.0721378</td><td style=\"text-align: right;\">0.00520386</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20181015_212135_model_108</td><td style=\"text-align: right;\">0.999388</td><td style=\"text-align: right;\">0.0367293</td><td style=\"text-align: right;\">             0.0030303</td><td style=\"text-align: right;\">0.079549 </td><td style=\"text-align: right;\">0.00632804</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20181015_212135_model_105</td><td style=\"text-align: right;\">0.999388</td><td style=\"text-align: right;\">0.0180771</td><td style=\"text-align: right;\">             0.0171717</td><td style=\"text-align: right;\">0.0724745</td><td style=\"text-align: right;\">0.00525255</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20181015_212135_model_72 </td><td style=\"text-align: right;\">0.999388</td><td style=\"text-align: right;\">0.0200072</td><td style=\"text-align: right;\">             0.0020202</td><td style=\"text-align: right;\">0.0733897</td><td style=\"text-align: right;\">0.00538605</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = aml.leaderboard\n",
    "lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_grid_0_AutoML_20181015_212135_model_53\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 5.041121875219484e-05\n",
      "RMSE: 0.007100085827100602\n",
      "LogLoss: 0.0014166648012189297\n",
      "Mean Per-Class Error: 0.0\n",
      "AUC: 1.0\n",
      "Gini: 1.0\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9632190396630882: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>False</b></td>\n",
       "<td><b>True</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>False</td>\n",
       "<td>495.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/495.0)</td></tr>\n",
       "<tr><td>True</td>\n",
       "<td>0.0</td>\n",
       "<td>33.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/33.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>495.0</td>\n",
       "<td>33.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/528.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       False    True    Error    Rate\n",
       "-----  -------  ------  -------  -----------\n",
       "False  495      0       0        (0.0/495.0)\n",
       "True   0        33      0        (0.0/33.0)\n",
       "Total  495      33      0        (0.0/528.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9978697</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9978697</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value    idx\n",
       "---------------------------  -----------  -------  -----\n",
       "max f1                       0.963219     1        32\n",
       "max f2                       0.963219     1        32\n",
       "max f0point5                 0.963219     1        32\n",
       "max accuracy                 0.963219     1        32\n",
       "max precision                0.99787      1        0\n",
       "max recall                   0.963219     1        32\n",
       "max specificity              0.99787      1        0\n",
       "max absolute_mcc             0.963219     1        32\n",
       "max min_per_class_accuracy   0.963219     1        32\n",
       "max mean_per_class_accuracy  0.963219     1        32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  6.25 %, avg score:  6.25 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0113636</td>\n",
       "<td>0.9966659</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9973940</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9973940</td>\n",
       "<td>0.1818182</td>\n",
       "<td>0.1818182</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0208333</td>\n",
       "<td>0.9943748</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9956542</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966032</td>\n",
       "<td>0.1515152</td>\n",
       "<td>0.3333333</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.9930070</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9937962</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9957260</td>\n",
       "<td>0.1515152</td>\n",
       "<td>0.4848485</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0416667</td>\n",
       "<td>0.9881820</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9905856</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9943241</td>\n",
       "<td>0.1818182</td>\n",
       "<td>0.6666667</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0511364</td>\n",
       "<td>0.9802906</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9854987</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9926897</td>\n",
       "<td>0.1515152</td>\n",
       "<td>0.8181818</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1003788</td>\n",
       "<td>0.0015665</td>\n",
       "<td>3.6923077</td>\n",
       "<td>9.9622642</td>\n",
       "<td>0.2307692</td>\n",
       "<td>0.2362565</td>\n",
       "<td>0.6226415</td>\n",
       "<td>0.6216093</td>\n",
       "<td>0.1818182</td>\n",
       "<td>1.0</td>\n",
       "<td>269.2307692</td>\n",
       "<td>896.2264151</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1515152</td>\n",
       "<td>0.0002900</td>\n",
       "<td>0.0</td>\n",
       "<td>6.6</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0007361</td>\n",
       "<td>0.4125</td>\n",
       "<td>0.4120646</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>560.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2007576</td>\n",
       "<td>0.0001808</td>\n",
       "<td>0.0</td>\n",
       "<td>4.9811321</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002202</td>\n",
       "<td>0.3113208</td>\n",
       "<td>0.3110462</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>398.1132075</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3011364</td>\n",
       "<td>0.0001323</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3207547</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001522</td>\n",
       "<td>0.2075472</td>\n",
       "<td>0.2074148</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>232.0754717</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.3996212</td>\n",
       "<td>0.0001204</td>\n",
       "<td>0.0</td>\n",
       "<td>2.5023697</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001261</td>\n",
       "<td>0.1563981</td>\n",
       "<td>0.1563295</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>150.2369668</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0001124</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001161</td>\n",
       "<td>0.125</td>\n",
       "<td>0.1249684</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6022727</td>\n",
       "<td>0.0001083</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6603774</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001101</td>\n",
       "<td>0.1037736</td>\n",
       "<td>0.1037661</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.0377358</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6988636</td>\n",
       "<td>0.0001027</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4308943</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001064</td>\n",
       "<td>0.0894309</td>\n",
       "<td>0.0894391</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.0894309</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8125</td>\n",
       "<td>0.0001014</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2307692</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001015</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.0769444</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>23.0769231</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8996212</td>\n",
       "<td>0.0000969</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1115789</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001010</td>\n",
       "<td>0.0694737</td>\n",
       "<td>0.0695027</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1578947</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000503</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000739</td>\n",
       "<td>0.0625</td>\n",
       "<td>0.0625335</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0113636                   0.996666           16       16                 1                0.997394     1                           0.997394            0.181818        0.181818                   1500     1500\n",
       "    2        0.0208333                   0.994375           16       16                 1                0.995654     1                           0.996603            0.151515        0.333333                   1500     1500\n",
       "    3        0.030303                    0.993007           16       16                 1                0.993796     1                           0.995726            0.151515        0.484848                   1500     1500\n",
       "    4        0.0416667                   0.988182           16       16                 1                0.990586     1                           0.994324            0.181818        0.666667                   1500     1500\n",
       "    5        0.0511364                   0.980291           16       16                 1                0.985499     1                           0.99269             0.151515        0.818182                   1500     1500\n",
       "    6        0.100379                    0.0015665          3.69231  9.96226            0.230769         0.236257     0.622642                    0.621609            0.181818        1                          269.231  896.226\n",
       "    7        0.151515                    0.00029001         0        6.6                0                0.000736075  0.4125                      0.412065            0               1                          -100     560\n",
       "    8        0.200758                    0.000180831        0        4.98113            0                0.000220238  0.311321                    0.311046            0               1                          -100     398.113\n",
       "    9        0.301136                    0.000132268        0        3.32075            0                0.000152207  0.207547                    0.207415            0               1                          -100     232.075\n",
       "    10       0.399621                    0.000120352        0        2.50237            0                0.000126115  0.156398                    0.156329            0               1                          -100     150.237\n",
       "    11       0.5                         0.000112411        0        2                  0                0.000116061  0.125                       0.124968            0               1                          -100     100\n",
       "    12       0.602273                    0.000108349        0        1.66038            0                0.000110065  0.103774                    0.103766            0               1                          -100     66.0377\n",
       "    13       0.698864                    0.000102687        0        1.43089            0                0.000106448  0.0894309                   0.0894391           0               1                          -100     43.0894\n",
       "    14       0.8125                      0.000101439        0        1.23077            0                0.000101531  0.0769231                   0.0769444           0               1                          -100     23.0769\n",
       "    15       0.899621                    9.69048e-05        0        1.11158            0                0.000101003  0.0694737                   0.0695027           0               1                          -100     11.1579\n",
       "    16       1                           5.03292e-05        0        1                  0                7.38625e-05  0.0625                      0.0625335           0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.013627046112635556\n",
      "RMSE: 0.11673493955382662\n",
      "LogLoss: 0.04328356814974064\n",
      "Mean Per-Class Error: 0.004347826086956497\n",
      "AUC: 0.9978260869565218\n",
      "Gini: 0.9956521739130435\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.12623858990193526: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>False</b></td>\n",
       "<td><b>True</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>False</td>\n",
       "<td>114.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0087</td>\n",
       "<td> (1.0/115.0)</td></tr>\n",
       "<tr><td>True</td>\n",
       "<td>0.0</td>\n",
       "<td>8.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/8.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>114.0</td>\n",
       "<td>9.0</td>\n",
       "<td>0.0081</td>\n",
       "<td> (1.0/123.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       False    True    Error    Rate\n",
       "-----  -------  ------  -------  -----------\n",
       "False  114      1       0.0087   (1.0/115.0)\n",
       "True   0        8       0        (0.0/8.0)\n",
       "Total  114      9       0.0081   (1.0/123.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1262386</td>\n",
       "<td>0.9411765</td>\n",
       "<td>8.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1262386</td>\n",
       "<td>0.9756098</td>\n",
       "<td>8.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9639389</td>\n",
       "<td>0.9375</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.1262386</td>\n",
       "<td>0.9918699</td>\n",
       "<td>8.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9974791</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.1262386</td>\n",
       "<td>1.0</td>\n",
       "<td>8.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9974791</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.1262386</td>\n",
       "<td>0.9387009</td>\n",
       "<td>8.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1262386</td>\n",
       "<td>0.9913043</td>\n",
       "<td>8.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1262386</td>\n",
       "<td>0.9956522</td>\n",
       "<td>8.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.126239     0.941176  8\n",
       "max f2                       0.126239     0.97561   8\n",
       "max f0point5                 0.963939     0.9375    5\n",
       "max accuracy                 0.126239     0.99187   8\n",
       "max precision                0.997479     1         0\n",
       "max recall                   0.126239     1         8\n",
       "max specificity              0.997479     1         0\n",
       "max absolute_mcc             0.126239     0.938701  8\n",
       "max min_per_class_accuracy   0.126239     0.991304  8\n",
       "max mean_per_class_accuracy  0.126239     0.995652  8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  6.50 %, avg score:  6.52 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0162602</td>\n",
       "<td>0.9947546</td>\n",
       "<td>15.3750000</td>\n",
       "<td>15.3750000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9969047</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9969047</td>\n",
       "<td>0.25</td>\n",
       "<td>0.25</td>\n",
       "<td>1437.5000000</td>\n",
       "<td>1437.5000000</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0243902</td>\n",
       "<td>0.9889057</td>\n",
       "<td>15.3750000</td>\n",
       "<td>15.3750000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9891677</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9943257</td>\n",
       "<td>0.125</td>\n",
       "<td>0.375</td>\n",
       "<td>1437.5000000</td>\n",
       "<td>1437.5000000</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0325203</td>\n",
       "<td>0.9871446</td>\n",
       "<td>15.3750000</td>\n",
       "<td>15.3750000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9885722</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9928873</td>\n",
       "<td>0.125</td>\n",
       "<td>0.5</td>\n",
       "<td>1437.5000000</td>\n",
       "<td>1437.5000000</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0406504</td>\n",
       "<td>0.9666353</td>\n",
       "<td>15.3750000</td>\n",
       "<td>15.3750000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9864092</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9915917</td>\n",
       "<td>0.125</td>\n",
       "<td>0.625</td>\n",
       "<td>1437.5000000</td>\n",
       "<td>1437.5000000</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0569106</td>\n",
       "<td>0.9523567</td>\n",
       "<td>7.6875000</td>\n",
       "<td>13.1785714</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9582681</td>\n",
       "<td>0.8571429</td>\n",
       "<td>0.9820707</td>\n",
       "<td>0.125</td>\n",
       "<td>0.75</td>\n",
       "<td>668.7500000</td>\n",
       "<td>1217.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1056911</td>\n",
       "<td>0.0038664</td>\n",
       "<td>5.1250000</td>\n",
       "<td>9.4615385</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.1874245</td>\n",
       "<td>0.6153846</td>\n",
       "<td>0.6153109</td>\n",
       "<td>0.25</td>\n",
       "<td>1.0</td>\n",
       "<td>412.5000000</td>\n",
       "<td>846.1538462</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1544715</td>\n",
       "<td>0.0011057</td>\n",
       "<td>0.0</td>\n",
       "<td>6.4736842</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0021265</td>\n",
       "<td>0.4210526</td>\n",
       "<td>0.4216737</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>547.3684211</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2032520</td>\n",
       "<td>0.0002421</td>\n",
       "<td>0.0</td>\n",
       "<td>4.92</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004938</td>\n",
       "<td>0.32</td>\n",
       "<td>0.3205906</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>392.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3008130</td>\n",
       "<td>0.0001320</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3243243</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001733</td>\n",
       "<td>0.2162162</td>\n",
       "<td>0.2166714</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>232.4324324</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.3983740</td>\n",
       "<td>0.0001190</td>\n",
       "<td>0.0</td>\n",
       "<td>2.5102041</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001255</td>\n",
       "<td>0.1632653</td>\n",
       "<td>0.1636398</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>151.0204082</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5040650</td>\n",
       "<td>0.0001126</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9838710</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001154</td>\n",
       "<td>0.1290323</td>\n",
       "<td>0.1293524</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>98.3870968</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6016260</td>\n",
       "<td>0.0001086</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6621622</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001099</td>\n",
       "<td>0.1081081</td>\n",
       "<td>0.1083942</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.2162162</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7560976</td>\n",
       "<td>0.0001014</td>\n",
       "<td>0.0</td>\n",
       "<td>1.3225806</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001038</td>\n",
       "<td>0.0860215</td>\n",
       "<td>0.0862703</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>32.2580645</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7967480</td>\n",
       "<td>0.0001012</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2551020</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001014</td>\n",
       "<td>0.0816327</td>\n",
       "<td>0.0818740</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.5102041</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8943089</td>\n",
       "<td>0.0000710</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1181818</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000897</td>\n",
       "<td>0.0727273</td>\n",
       "<td>0.0729520</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.8181818</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000601</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000638</td>\n",
       "<td>0.0650407</td>\n",
       "<td>0.0652484</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift    cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain    cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  ------  -----------------\n",
       "    1        0.0162602                   0.994755           15.375  15.375             1                0.996905     1                           0.996905            0.25            0.25                       1437.5  1437.5\n",
       "    2        0.0243902                   0.988906           15.375  15.375             1                0.989168     1                           0.994326            0.125           0.375                      1437.5  1437.5\n",
       "    3        0.0325203                   0.987145           15.375  15.375             1                0.988572     1                           0.992887            0.125           0.5                        1437.5  1437.5\n",
       "    4        0.0406504                   0.966635           15.375  15.375             1                0.986409     1                           0.991592            0.125           0.625                      1437.5  1437.5\n",
       "    5        0.0569106                   0.952357           7.6875  13.1786            0.5              0.958268     0.857143                    0.982071            0.125           0.75                       668.75  1217.86\n",
       "    6        0.105691                    0.00386637         5.125   9.46154            0.333333         0.187424     0.615385                    0.615311            0.25            1                          412.5   846.154\n",
       "    7        0.154472                    0.0011057          0       6.47368            0                0.0021265    0.421053                    0.421674            0               1                          -100    547.368\n",
       "    8        0.203252                    0.000242064        0       4.92               0                0.000493849  0.32                        0.320591            0               1                          -100    392\n",
       "    9        0.300813                    0.00013201         0       3.32432            0                0.000173257  0.216216                    0.216671            0               1                          -100    232.432\n",
       "    10       0.398374                    0.000119007        0       2.5102             0                0.000125536  0.163265                    0.16364             0               1                          -100    151.02\n",
       "    11       0.504065                    0.000112649        0       1.98387            0                0.000115434  0.129032                    0.129352            0               1                          -100    98.3871\n",
       "    12       0.601626                    0.000108646        0       1.66216            0                0.000109917  0.108108                    0.108394            0               1                          -100    66.2162\n",
       "    13       0.756098                    0.000101439        0       1.32258            0                0.000103761  0.0860215                   0.0862703           0               1                          -100    32.2581\n",
       "    14       0.796748                    0.000101246        0       1.2551             0                0.000101361  0.0816327                   0.081874            0               1                          -100    25.5102\n",
       "    15       0.894309                    7.09915e-05        0       1.11818            0                8.96956e-05  0.0727273                   0.072952            0               1                          -100    11.8182\n",
       "    16       1                           6.01315e-05        0       1                  0                6.37869e-05  0.0650407                   0.0652484           0               1                          -100    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.004435346806724833\n",
      "RMSE: 0.06659839943065324\n",
      "LogLoss: 0.015883101472134616\n",
      "Mean Per-Class Error: 0.002020202020202033\n",
      "AUC: 0.9998775635139271\n",
      "Gini: 0.9997551270278542\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8984000881321323: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>False</b></td>\n",
       "<td><b>True</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>False</td>\n",
       "<td>495.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/495.0)</td></tr>\n",
       "<tr><td>True</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td>\n",
       "<td>0.0303</td>\n",
       "<td> (1.0/33.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>496.0</td>\n",
       "<td>32.0</td>\n",
       "<td>0.0019</td>\n",
       "<td> (1.0/528.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       False    True    Error    Rate\n",
       "-----  -------  ------  -------  -----------\n",
       "False  495      0       0        (0.0/495.0)\n",
       "True   1        32      0.0303   (1.0/33.0)\n",
       "Total  496      32      0.0019   (1.0/528.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.8984001</td>\n",
       "<td>0.9846154</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.7186424</td>\n",
       "<td>0.9880240</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.8984001</td>\n",
       "<td>0.9937888</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.8984001</td>\n",
       "<td>0.9981061</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9996015</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.7186424</td>\n",
       "<td>1.0</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9996015</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.8984001</td>\n",
       "<td>0.9837388</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.7186424</td>\n",
       "<td>0.9959596</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.7186424</td>\n",
       "<td>0.9979798</td>\n",
       "<td>34.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.8984       0.984615  31\n",
       "max f2                       0.718642     0.988024  34\n",
       "max f0point5                 0.8984       0.993789  31\n",
       "max accuracy                 0.8984       0.998106  31\n",
       "max precision                0.999602     1         0\n",
       "max recall                   0.718642     1         34\n",
       "max specificity              0.999602     1         0\n",
       "max absolute_mcc             0.8984       0.983739  31\n",
       "max min_per_class_accuracy   0.718642     0.99596   34\n",
       "max mean_per_class_accuracy  0.718642     0.99798   34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  6.25 %, avg score:  6.66 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0113636</td>\n",
       "<td>0.9974372</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9986911</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9986911</td>\n",
       "<td>0.1818182</td>\n",
       "<td>0.1818182</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0208333</td>\n",
       "<td>0.9874622</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9920829</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9956874</td>\n",
       "<td>0.1515152</td>\n",
       "<td>0.3333333</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.9716484</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9805329</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9909516</td>\n",
       "<td>0.1515152</td>\n",
       "<td>0.4848485</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0416667</td>\n",
       "<td>0.9419888</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9611758</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9828309</td>\n",
       "<td>0.1818182</td>\n",
       "<td>0.6666667</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0511364</td>\n",
       "<td>0.9003515</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9061497</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9686307</td>\n",
       "<td>0.1515152</td>\n",
       "<td>0.8181818</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1003788</td>\n",
       "<td>0.0088755</td>\n",
       "<td>3.6923077</td>\n",
       "<td>9.9622642</td>\n",
       "<td>0.2307692</td>\n",
       "<td>0.3323907</td>\n",
       "<td>0.6226415</td>\n",
       "<td>0.6565129</td>\n",
       "<td>0.1818182</td>\n",
       "<td>1.0</td>\n",
       "<td>269.2307692</td>\n",
       "<td>896.2264151</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1515152</td>\n",
       "<td>0.0023086</td>\n",
       "<td>0.0</td>\n",
       "<td>6.6</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0043522</td>\n",
       "<td>0.4125</td>\n",
       "<td>0.4364087</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>560.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2045455</td>\n",
       "<td>0.0020855</td>\n",
       "<td>0.0</td>\n",
       "<td>4.8888889</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0021814</td>\n",
       "<td>0.3055556</td>\n",
       "<td>0.3238312</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>388.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3011364</td>\n",
       "<td>0.0013274</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3207547</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0018736</td>\n",
       "<td>0.2075472</td>\n",
       "<td>0.2205618</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>232.0754717</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.3996212</td>\n",
       "<td>0.0007244</td>\n",
       "<td>0.0</td>\n",
       "<td>2.5023697</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0008317</td>\n",
       "<td>0.1563981</td>\n",
       "<td>0.1664103</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>150.2369668</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0001763</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0005669</td>\n",
       "<td>0.125</td>\n",
       "<td>0.1331160</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6022727</td>\n",
       "<td>0.0001096</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6603774</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001307</td>\n",
       "<td>0.1037736</td>\n",
       "<td>0.1105336</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.0377358</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6988636</td>\n",
       "<td>0.0000326</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4308943</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000733</td>\n",
       "<td>0.0894309</td>\n",
       "<td>0.0952667</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.0894309</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7992424</td>\n",
       "<td>0.0000220</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2511848</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000265</td>\n",
       "<td>0.0781991</td>\n",
       "<td>0.0833053</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1184834</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8996212</td>\n",
       "<td>0.0000021</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1115789</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000089</td>\n",
       "<td>0.0694737</td>\n",
       "<td>0.0740111</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1578947</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000007</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000015</td>\n",
       "<td>0.0625</td>\n",
       "<td>0.0665821</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0113636                   0.997437           16       16                 1                0.998691     1                           0.998691            0.181818        0.181818                   1500     1500\n",
       "    2        0.0208333                   0.987462           16       16                 1                0.992083     1                           0.995687            0.151515        0.333333                   1500     1500\n",
       "    3        0.030303                    0.971648           16       16                 1                0.980533     1                           0.990952            0.151515        0.484848                   1500     1500\n",
       "    4        0.0416667                   0.941989           16       16                 1                0.961176     1                           0.982831            0.181818        0.666667                   1500     1500\n",
       "    5        0.0511364                   0.900351           16       16                 1                0.90615      1                           0.968631            0.151515        0.818182                   1500     1500\n",
       "    6        0.100379                    0.00887554         3.69231  9.96226            0.230769         0.332391     0.622642                    0.656513            0.181818        1                          269.231  896.226\n",
       "    7        0.151515                    0.00230865         0        6.6                0                0.00435218   0.4125                      0.436409            0               1                          -100     560\n",
       "    8        0.204545                    0.00208548         0        4.88889            0                0.00218142   0.305556                    0.323831            0               1                          -100     388.889\n",
       "    9        0.301136                    0.00132738         0        3.32075            0                0.00187357   0.207547                    0.220562            0               1                          -100     232.075\n",
       "    10       0.399621                    0.000724373        0        2.50237            0                0.000831678  0.156398                    0.16641             0               1                          -100     150.237\n",
       "    11       0.5                         0.000176309        0        2                  0                0.000566911  0.125                       0.133116            0               1                          -100     100\n",
       "    12       0.602273                    0.000109615        0        1.66038            0                0.000130665  0.103774                    0.110534            0               1                          -100     66.0377\n",
       "    13       0.698864                    3.2614e-05         0        1.43089            0                7.32703e-05  0.0894309                   0.0952667           0               1                          -100     43.0894\n",
       "    14       0.799242                    2.20421e-05        0        1.25118            0                2.65405e-05  0.0781991                   0.0833053           0               1                          -100     25.1185\n",
       "    15       0.899621                    2.0635e-06         0        1.11158            0                8.89062e-06  0.0694737                   0.0740111           0               1                          -100     11.1579\n",
       "    16       1                           7.15738e-07        0        1                  0                1.54744e-06  0.0625                      0.0665821           0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9981132</td>\n",
       "<td>0.0026683</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.990566</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9997114</td>\n",
       "<td>0.0004081</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.998557</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0018868</td>\n",
       "<td>0.0026683</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0094340</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>0.2</td>\n",
       "<td>0.2828427</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9794872</td>\n",
       "<td>0.0290095</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8974359</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9866667</td>\n",
       "<td>0.0188562</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9333333</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.9944444</td>\n",
       "<td>0.0078567</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9722222</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>16.415476</td>\n",
       "<td>1.9144108</td>\n",
       "<td>15.142858</td>\n",
       "<td>17.666666</td>\n",
       "<td>15.142858</td>\n",
       "<td>13.125</td>\n",
       "<td>21.0</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.0158835</td>\n",
       "<td>0.0106358</td>\n",
       "<td>0.0015761</td>\n",
       "<td>0.0031036</td>\n",
       "<td>0.0427675</td>\n",
       "<td>0.0114903</td>\n",
       "<td>0.0204800</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.0020202</td>\n",
       "<td>0.0028570</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0101010</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9861356</td>\n",
       "<td>0.0196072</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9306781</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9989899</td>\n",
       "<td>0.0014285</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9949495</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0010101</td>\n",
       "<td>0.0014285</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0050505</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0044364</td>\n",
       "<td>0.0032859</td>\n",
       "<td>0.0001108</td>\n",
       "<td>0.0002610</td>\n",
       "<td>0.0123979</td>\n",
       "<td>0.0026692</td>\n",
       "<td>0.0067429</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.975</td>\n",
       "<td>0.0353553</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.875</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.9211395</td>\n",
       "<td>0.0573440</td>\n",
       "<td>0.9982041</td>\n",
       "<td>0.9951123</td>\n",
       "<td>0.7989858</td>\n",
       "<td>0.9620767</td>\n",
       "<td>0.8513185</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.0543612</td>\n",
       "<td>0.0272142</td>\n",
       "<td>0.0105244</td>\n",
       "<td>0.0161556</td>\n",
       "<td>0.1113459</td>\n",
       "<td>0.0516648</td>\n",
       "<td>0.0821153</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9979798</td>\n",
       "<td>0.0028570</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.989899</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean        sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ----------  -----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.998113    0.00266833   1             1             0.990566      1             1\n",
       "auc                      0.999711    0.000408142  1             1             0.998557      1             1\n",
       "err                      0.00188679  0.00266833   0             0             0.00943396    0             0\n",
       "err_count                0.2         0.282843     0             0             1             0             0\n",
       "f0point5                 0.979487    0.0290095    1             1             0.897436      1             1\n",
       "f1                       0.986667    0.0188562    1             1             0.933333      1             1\n",
       "f2                       0.994444    0.00785674   1             1             0.972222      1             1\n",
       "lift_top_group           16.4155     1.91441      15.1429       17.6667       15.1429       13.125        21\n",
       "logloss                  0.0158835   0.0106358    0.0015761     0.0031036     0.0427675     0.0114903     0.02048\n",
       "max_per_class_error      0.0020202   0.002857     0             0             0.010101      0             0\n",
       "mcc                      0.986136    0.0196072    1             1             0.930678      1             1\n",
       "mean_per_class_accuracy  0.99899     0.0014285    1             1             0.99495       1             1\n",
       "mean_per_class_error     0.0010101   0.0014285    0             0             0.00505051    0             0\n",
       "mse                      0.00443637  0.00328593   0.000110763   0.000261003   0.0123979     0.00266925    0.00674293\n",
       "precision                0.975       0.0353553    1             1             0.875         1             1\n",
       "r2                       0.921139    0.057344     0.998204      0.995112      0.798986      0.962077      0.851318\n",
       "recall                   1           0            1             1             1             1             1\n",
       "rmse                     0.0543612   0.0272142    0.0105244     0.0161556     0.111346      0.0516648     0.0821153\n",
       "specificity              0.99798     0.002857     1             1             0.989899      1             1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:23:59</td>\n",
       "<td> 2 min  5.644 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2420615</td>\n",
       "<td>0.2337917</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9375</td>\n",
       "<td>0.2466107</td>\n",
       "<td>0.2406719</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9349593</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:23:59</td>\n",
       "<td> 2 min  5.651 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.1971347</td>\n",
       "<td>0.1405340</td>\n",
       "<td>0.9999694</td>\n",
       "<td>16.0</td>\n",
       "<td>0.0018939</td>\n",
       "<td>0.2088069</td>\n",
       "<td>0.1557027</td>\n",
       "<td>0.9918478</td>\n",
       "<td>7.6875000</td>\n",
       "<td>0.0162602</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:23:59</td>\n",
       "<td> 2 min  5.659 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.1605996</td>\n",
       "<td>0.1015051</td>\n",
       "<td>1.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1784812</td>\n",
       "<td>0.1178625</td>\n",
       "<td>0.9929348</td>\n",
       "<td>15.3750000</td>\n",
       "<td>0.0162602</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:23:59</td>\n",
       "<td> 2 min  5.667 sec</td>\n",
       "<td>15.0</td>\n",
       "<td>0.1328976</td>\n",
       "<td>0.0780790</td>\n",
       "<td>1.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1576261</td>\n",
       "<td>0.0962951</td>\n",
       "<td>0.9940217</td>\n",
       "<td>15.3750000</td>\n",
       "<td>0.0162602</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:23:59</td>\n",
       "<td> 2 min  5.674 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.1091887</td>\n",
       "<td>0.0606583</td>\n",
       "<td>1.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1428991</td>\n",
       "<td>0.0818004</td>\n",
       "<td>0.9923913</td>\n",
       "<td>15.3750000</td>\n",
       "<td>0.0162602</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:23:59</td>\n",
       "<td> 2 min  5.891 sec</td>\n",
       "<td>135.0</td>\n",
       "<td>0.0091357</td>\n",
       "<td>0.0019880</td>\n",
       "<td>1.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1152574</td>\n",
       "<td>0.0422666</td>\n",
       "<td>0.9978261</td>\n",
       "<td>15.3750000</td>\n",
       "<td>0.0081301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:23:59</td>\n",
       "<td> 2 min  5.900 sec</td>\n",
       "<td>140.0</td>\n",
       "<td>0.0085130</td>\n",
       "<td>0.0017648</td>\n",
       "<td>1.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1156279</td>\n",
       "<td>0.0422919</td>\n",
       "<td>0.9978261</td>\n",
       "<td>15.3750000</td>\n",
       "<td>0.0081301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:23:59</td>\n",
       "<td> 2 min  5.910 sec</td>\n",
       "<td>145.0</td>\n",
       "<td>0.0080213</td>\n",
       "<td>0.0016132</td>\n",
       "<td>1.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1154632</td>\n",
       "<td>0.0421379</td>\n",
       "<td>0.9978261</td>\n",
       "<td>15.3750000</td>\n",
       "<td>0.0081301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:23:59</td>\n",
       "<td> 2 min  5.919 sec</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0072162</td>\n",
       "<td>0.0014365</td>\n",
       "<td>1.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1166632</td>\n",
       "<td>0.0432905</td>\n",
       "<td>0.9978261</td>\n",
       "<td>15.3750000</td>\n",
       "<td>0.0081301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:23:59</td>\n",
       "<td> 2 min  5.925 sec</td>\n",
       "<td>151.0</td>\n",
       "<td>0.0071001</td>\n",
       "<td>0.0014167</td>\n",
       "<td>1.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1167349</td>\n",
       "<td>0.0432836</td>\n",
       "<td>0.9978261</td>\n",
       "<td>15.3750000</td>\n",
       "<td>0.0081301</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration          number_of_trees    training_rmse         training_logloss       training_auc        training_lift    training_classification_error    validation_rmse      validation_logloss    validation_auc      validation_lift     validation_classification_error\n",
       "---  -------------------  ----------------  -----------------  --------------------  ---------------------  ------------------  ---------------  -------------------------------  -------------------  --------------------  ------------------  ------------------  ---------------------------------\n",
       "     2018-10-15 21:23:59  2 min  5.644 sec  0.0                0.24206145913796356   0.23379165870645927    0.5                 1.0              0.9375                           0.24661066300079373  0.24067186755072303   0.5                 1.0                 0.9349593495934959\n",
       "     2018-10-15 21:23:59  2 min  5.651 sec  5.0                0.19713470034617417   0.14053402034468251    0.9999693908784818  16.0             0.001893939393939394             0.2088069078521661   0.15570268317073127   0.9918478260869565  7.687499999999999   0.016260162601626018\n",
       "     2018-10-15 21:23:59  2 min  5.659 sec  10.0               0.16059956223191962   0.10150511198547736    1.0                 16.0             0.0                              0.17848123293794116  0.117862451254678     0.9929347826086956  15.374999999999998  0.016260162601626018\n",
       "     2018-10-15 21:23:59  2 min  5.667 sec  15.0               0.1328976342440515    0.07807901843152104    1.0                 16.0             0.0                              0.15762613213914484  0.09629509911057878   0.9940217391304348  15.374999999999998  0.016260162601626018\n",
       "     2018-10-15 21:23:59  2 min  5.674 sec  20.0               0.10918870736263894   0.060658304772669584   1.0                 16.0             0.0                              0.14289906095665117  0.08180041960459403   0.9923913043478261  15.374999999999998  0.016260162601626018\n",
       "---  ---                  ---               ---                ---                   ---                    ---                 ---              ---                              ---                  ---                   ---                 ---                 ---\n",
       "     2018-10-15 21:23:59  2 min  5.891 sec  135.0              0.009135722806684716  0.0019879642369712183  1.0                 16.0             0.0                              0.11525743929387003  0.042266621688389745  0.9978260869565218  15.374999999999998  0.008130081300813009\n",
       "     2018-10-15 21:23:59  2 min  5.900 sec  140.0              0.008512967730759774  0.001764794894481358   1.0                 16.0             0.0                              0.11562793649887537  0.04229193375140358   0.9978260869565218  15.374999999999998  0.008130081300813009\n",
       "     2018-10-15 21:23:59  2 min  5.910 sec  145.0              0.008021295019668114  0.0016132388822185386  1.0                 16.0             0.0                              0.11546323287211266  0.04213786376616998   0.9978260869565218  15.374999999999998  0.008130081300813009\n",
       "     2018-10-15 21:23:59  2 min  5.919 sec  150.0              0.007216161377692652  0.0014365129027453202  1.0                 16.0             0.0                              0.11666315966587308  0.04329051650455503   0.9978260869565218  15.374999999999998  0.008130081300813009\n",
       "     2018-10-15 21:23:59  2 min  5.925 sec  151.0              0.007100085827100602  0.0014166648012189297  1.0                 16.0             0.0                              0.11673493955382662  0.04328356814974064   0.9978260869565218  15.374999999999998  0.008130081300813009"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>48.8985329</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1936618</td></tr>\n",
       "<tr><td>Egg_Group_1</td>\n",
       "<td>48.6230888</td>\n",
       "<td>0.9943670</td>\n",
       "<td>0.1925709</td></tr>\n",
       "<tr><td>Catch_Rate</td>\n",
       "<td>43.7949829</td>\n",
       "<td>0.8956298</td>\n",
       "<td>0.1734493</td></tr>\n",
       "<tr><td>hasGender</td>\n",
       "<td>24.8252621</td>\n",
       "<td>0.5076893</td>\n",
       "<td>0.0983200</td></tr>\n",
       "<tr><td>Weight_kg</td>\n",
       "<td>24.3187714</td>\n",
       "<td>0.4973313</td>\n",
       "<td>0.0963141</td></tr>\n",
       "<tr><td>Sp_Atk</td>\n",
       "<td>18.1800365</td>\n",
       "<td>0.3717910</td>\n",
       "<td>0.0720017</td></tr>\n",
       "<tr><td>Height_m</td>\n",
       "<td>8.8033495</td>\n",
       "<td>0.1800330</td>\n",
       "<td>0.0348655</td></tr>\n",
       "<tr><td>Pr_Male</td>\n",
       "<td>7.8636870</td>\n",
       "<td>0.1608164</td>\n",
       "<td>0.0311440</td></tr>\n",
       "<tr><td>Defense</td>\n",
       "<td>5.6841083</td>\n",
       "<td>0.1162429</td>\n",
       "<td>0.0225118</td></tr>\n",
       "<tr><td>Body_Style</td>\n",
       "<td>4.9551687</td>\n",
       "<td>0.1013357</td>\n",
       "<td>0.0196249</td></tr>\n",
       "<tr><td>Speed</td>\n",
       "<td>4.7389112</td>\n",
       "<td>0.0969132</td>\n",
       "<td>0.0187684</td></tr>\n",
       "<tr><td>Type_1</td>\n",
       "<td>4.2406125</td>\n",
       "<td>0.0867227</td>\n",
       "<td>0.0167949</td></tr>\n",
       "<tr><td>Sp_Def</td>\n",
       "<td>3.9272740</td>\n",
       "<td>0.0803148</td>\n",
       "<td>0.0155539</td></tr>\n",
       "<tr><td>Color</td>\n",
       "<td>2.0592716</td>\n",
       "<td>0.0421132</td>\n",
       "<td>0.0081557</td></tr>\n",
       "<tr><td>HP</td>\n",
       "<td>1.2484794</td>\n",
       "<td>0.0255320</td>\n",
       "<td>0.0049446</td></tr>\n",
       "<tr><td>Attack</td>\n",
       "<td>0.2956084</td>\n",
       "<td>0.0060453</td>\n",
       "<td>0.0011708</td></tr>\n",
       "<tr><td>Generation</td>\n",
       "<td>0.0373554</td>\n",
       "<td>0.0007639</td>\n",
       "<td>0.0001479</td></tr>\n",
       "<tr><td>hasMegaEvolution</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "variable          relative_importance    scaled_importance    percentage\n",
       "----------------  ---------------------  -------------------  ------------\n",
       "Total             48.8985                1                    0.193662\n",
       "Egg_Group_1       48.6231                0.994367             0.192571\n",
       "Catch_Rate        43.795                 0.89563              0.173449\n",
       "hasGender         24.8253                0.507689             0.09832\n",
       "Weight_kg         24.3188                0.497331             0.0963141\n",
       "Sp_Atk            18.18                  0.371791             0.0720017\n",
       "Height_m          8.80335                0.180033             0.0348655\n",
       "Pr_Male           7.86369                0.160816             0.031144\n",
       "Defense           5.68411                0.116243             0.0225118\n",
       "Body_Style        4.95517                0.101336             0.0196249\n",
       "Speed             4.73891                0.0969132            0.0187684\n",
       "Type_1            4.24061                0.0867227            0.0167949\n",
       "Sp_Def            3.92727                0.0803148            0.0155539\n",
       "Color             2.05927                0.0421132            0.00815571\n",
       "HP                1.24848                0.025532             0.00494458\n",
       "Attack            0.295608               0.00604534           0.00117075\n",
       "Generation        0.0373554              0.000763937          0.000147945\n",
       "hasMegaEvolution  0                      0                    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = h2o.get_model(lb[0,\"model_id\"])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total</td>\n",
       "      <td>48.898533</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.193662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Egg_Group_1</td>\n",
       "      <td>48.623089</td>\n",
       "      <td>0.994367</td>\n",
       "      <td>0.192571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Catch_Rate</td>\n",
       "      <td>43.794983</td>\n",
       "      <td>0.895630</td>\n",
       "      <td>0.173449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hasGender</td>\n",
       "      <td>24.825262</td>\n",
       "      <td>0.507689</td>\n",
       "      <td>0.098320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weight_kg</td>\n",
       "      <td>24.318771</td>\n",
       "      <td>0.497331</td>\n",
       "      <td>0.096314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sp_Atk</td>\n",
       "      <td>18.180037</td>\n",
       "      <td>0.371791</td>\n",
       "      <td>0.072002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Height_m</td>\n",
       "      <td>8.803349</td>\n",
       "      <td>0.180033</td>\n",
       "      <td>0.034866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pr_Male</td>\n",
       "      <td>7.863687</td>\n",
       "      <td>0.160816</td>\n",
       "      <td>0.031144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Defense</td>\n",
       "      <td>5.684108</td>\n",
       "      <td>0.116243</td>\n",
       "      <td>0.022512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Body_Style</td>\n",
       "      <td>4.955169</td>\n",
       "      <td>0.101336</td>\n",
       "      <td>0.019625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Speed</td>\n",
       "      <td>4.738911</td>\n",
       "      <td>0.096913</td>\n",
       "      <td>0.018768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Type_1</td>\n",
       "      <td>4.240613</td>\n",
       "      <td>0.086723</td>\n",
       "      <td>0.016795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sp_Def</td>\n",
       "      <td>3.927274</td>\n",
       "      <td>0.080315</td>\n",
       "      <td>0.015554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Color</td>\n",
       "      <td>2.059272</td>\n",
       "      <td>0.042113</td>\n",
       "      <td>0.008156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HP</td>\n",
       "      <td>1.248479</td>\n",
       "      <td>0.025532</td>\n",
       "      <td>0.004945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Attack</td>\n",
       "      <td>0.295608</td>\n",
       "      <td>0.006045</td>\n",
       "      <td>0.001171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Generation</td>\n",
       "      <td>0.037355</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hasMegaEvolution</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            variable  relative_importance  scaled_importance  percentage\n",
       "0              Total            48.898533           1.000000    0.193662\n",
       "1        Egg_Group_1            48.623089           0.994367    0.192571\n",
       "2         Catch_Rate            43.794983           0.895630    0.173449\n",
       "3          hasGender            24.825262           0.507689    0.098320\n",
       "4          Weight_kg            24.318771           0.497331    0.096314\n",
       "5             Sp_Atk            18.180037           0.371791    0.072002\n",
       "6           Height_m             8.803349           0.180033    0.034866\n",
       "7            Pr_Male             7.863687           0.160816    0.031144\n",
       "8            Defense             5.684108           0.116243    0.022512\n",
       "9         Body_Style             4.955169           0.101336    0.019625\n",
       "10             Speed             4.738911           0.096913    0.018768\n",
       "11            Type_1             4.240613           0.086723    0.016795\n",
       "12            Sp_Def             3.927274           0.080315    0.015554\n",
       "13             Color             2.059272           0.042113    0.008156\n",
       "14                HP             1.248479           0.025532    0.004945\n",
       "15            Attack             0.295608           0.006045    0.001171\n",
       "16        Generation             0.037355           0.000764    0.000148\n",
       "17  hasMegaEvolution             0.000000           0.000000    0.000000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.varimp(use_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAAJTCAYAAACM125qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLlyGDgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10eefabe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m.varimp_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 5.041121875219484e-05\n",
      "RMSE: 0.007100085827100602\n",
      "LogLoss: 0.0014166648012189297\n",
      "Mean Per-Class Error: 0.0\n",
      "AUC: 1.0\n",
      "Gini: 1.0\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9632190396630882: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>False</b></td>\n",
       "<td><b>True</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>False</td>\n",
       "<td>495.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/495.0)</td></tr>\n",
       "<tr><td>True</td>\n",
       "<td>0.0</td>\n",
       "<td>33.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/33.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>495.0</td>\n",
       "<td>33.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/528.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       False    True    Error    Rate\n",
       "-----  -------  ------  -------  -----------\n",
       "False  495      0       0        (0.0/495.0)\n",
       "True   0        33      0        (0.0/33.0)\n",
       "Total  495      33      0        (0.0/528.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9978697</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9978697</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value    idx\n",
       "---------------------------  -----------  -------  -----\n",
       "max f1                       0.963219     1        32\n",
       "max f2                       0.963219     1        32\n",
       "max f0point5                 0.963219     1        32\n",
       "max accuracy                 0.963219     1        32\n",
       "max precision                0.99787      1        0\n",
       "max recall                   0.963219     1        32\n",
       "max specificity              0.99787      1        0\n",
       "max absolute_mcc             0.963219     1        32\n",
       "max min_per_class_accuracy   0.963219     1        32\n",
       "max mean_per_class_accuracy  0.963219     1        32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  6.25 %, avg score:  6.25 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0113636</td>\n",
       "<td>0.9966659</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9973940</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9973940</td>\n",
       "<td>0.1818182</td>\n",
       "<td>0.1818182</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0208333</td>\n",
       "<td>0.9943748</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9956542</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966032</td>\n",
       "<td>0.1515152</td>\n",
       "<td>0.3333333</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.9930070</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9937962</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9957260</td>\n",
       "<td>0.1515152</td>\n",
       "<td>0.4848485</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0416667</td>\n",
       "<td>0.9881820</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9905856</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9943241</td>\n",
       "<td>0.1818182</td>\n",
       "<td>0.6666667</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0511364</td>\n",
       "<td>0.9802906</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9854987</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9926897</td>\n",
       "<td>0.1515152</td>\n",
       "<td>0.8181818</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1003788</td>\n",
       "<td>0.0015665</td>\n",
       "<td>3.6923077</td>\n",
       "<td>9.9622642</td>\n",
       "<td>0.2307692</td>\n",
       "<td>0.2362565</td>\n",
       "<td>0.6226415</td>\n",
       "<td>0.6216093</td>\n",
       "<td>0.1818182</td>\n",
       "<td>1.0</td>\n",
       "<td>269.2307692</td>\n",
       "<td>896.2264151</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1515152</td>\n",
       "<td>0.0002900</td>\n",
       "<td>0.0</td>\n",
       "<td>6.6</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0007361</td>\n",
       "<td>0.4125</td>\n",
       "<td>0.4120646</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>560.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2007576</td>\n",
       "<td>0.0001808</td>\n",
       "<td>0.0</td>\n",
       "<td>4.9811321</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002202</td>\n",
       "<td>0.3113208</td>\n",
       "<td>0.3110462</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>398.1132075</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3011364</td>\n",
       "<td>0.0001323</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3207547</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001522</td>\n",
       "<td>0.2075472</td>\n",
       "<td>0.2074148</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>232.0754717</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.3996212</td>\n",
       "<td>0.0001204</td>\n",
       "<td>0.0</td>\n",
       "<td>2.5023697</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001261</td>\n",
       "<td>0.1563981</td>\n",
       "<td>0.1563295</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>150.2369668</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0001124</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001161</td>\n",
       "<td>0.125</td>\n",
       "<td>0.1249684</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6022727</td>\n",
       "<td>0.0001083</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6603774</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001101</td>\n",
       "<td>0.1037736</td>\n",
       "<td>0.1037661</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.0377358</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6988636</td>\n",
       "<td>0.0001027</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4308943</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001064</td>\n",
       "<td>0.0894309</td>\n",
       "<td>0.0894391</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.0894309</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8125</td>\n",
       "<td>0.0001014</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2307692</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001015</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.0769444</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>23.0769231</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8996212</td>\n",
       "<td>0.0000969</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1115789</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001010</td>\n",
       "<td>0.0694737</td>\n",
       "<td>0.0695027</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1578947</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000503</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000739</td>\n",
       "<td>0.0625</td>\n",
       "<td>0.0625335</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0113636                   0.996666           16       16                 1                0.997394     1                           0.997394            0.181818        0.181818                   1500     1500\n",
       "    2        0.0208333                   0.994375           16       16                 1                0.995654     1                           0.996603            0.151515        0.333333                   1500     1500\n",
       "    3        0.030303                    0.993007           16       16                 1                0.993796     1                           0.995726            0.151515        0.484848                   1500     1500\n",
       "    4        0.0416667                   0.988182           16       16                 1                0.990586     1                           0.994324            0.181818        0.666667                   1500     1500\n",
       "    5        0.0511364                   0.980291           16       16                 1                0.985499     1                           0.99269             0.151515        0.818182                   1500     1500\n",
       "    6        0.100379                    0.0015665          3.69231  9.96226            0.230769         0.236257     0.622642                    0.621609            0.181818        1                          269.231  896.226\n",
       "    7        0.151515                    0.00029001         0        6.6                0                0.000736075  0.4125                      0.412065            0               1                          -100     560\n",
       "    8        0.200758                    0.000180831        0        4.98113            0                0.000220238  0.311321                    0.311046            0               1                          -100     398.113\n",
       "    9        0.301136                    0.000132268        0        3.32075            0                0.000152207  0.207547                    0.207415            0               1                          -100     232.075\n",
       "    10       0.399621                    0.000120352        0        2.50237            0                0.000126115  0.156398                    0.156329            0               1                          -100     150.237\n",
       "    11       0.5                         0.000112411        0        2                  0                0.000116061  0.125                       0.124968            0               1                          -100     100\n",
       "    12       0.602273                    0.000108349        0        1.66038            0                0.000110065  0.103774                    0.103766            0               1                          -100     66.0377\n",
       "    13       0.698864                    0.000102687        0        1.43089            0                0.000106448  0.0894309                   0.0894391           0               1                          -100     43.0894\n",
       "    14       0.8125                      0.000101439        0        1.23077            0                0.000101531  0.0769231                   0.0769444           0               1                          -100     23.0769\n",
       "    15       0.899621                    9.69048e-05        0        1.11158            0                0.000101003  0.0694737                   0.0695027           0               1                          -100     11.1579\n",
       "    16       1                           5.03292e-05        0        1                  0                7.38625e-05  0.0625                      0.0625335           0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader.model_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_grid_0_AutoML_20181015_212135_model_53\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 5.041121875219484e-05\n",
      "RMSE: 0.007100085827100602\n",
      "LogLoss: 0.0014166648012189297\n",
      "Mean Per-Class Error: 0.0\n",
      "AUC: 1.0\n",
      "Gini: 1.0\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9632190396630882: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>False</b></td>\n",
       "<td><b>True</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>False</td>\n",
       "<td>495.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/495.0)</td></tr>\n",
       "<tr><td>True</td>\n",
       "<td>0.0</td>\n",
       "<td>33.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/33.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>495.0</td>\n",
       "<td>33.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/528.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       False    True    Error    Rate\n",
       "-----  -------  ------  -------  -----------\n",
       "False  495      0       0        (0.0/495.0)\n",
       "True   0        33      0        (0.0/33.0)\n",
       "Total  495      33      0        (0.0/528.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9978697</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9978697</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.9632190</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value    idx\n",
       "---------------------------  -----------  -------  -----\n",
       "max f1                       0.963219     1        32\n",
       "max f2                       0.963219     1        32\n",
       "max f0point5                 0.963219     1        32\n",
       "max accuracy                 0.963219     1        32\n",
       "max precision                0.99787      1        0\n",
       "max recall                   0.963219     1        32\n",
       "max specificity              0.99787      1        0\n",
       "max absolute_mcc             0.963219     1        32\n",
       "max min_per_class_accuracy   0.963219     1        32\n",
       "max mean_per_class_accuracy  0.963219     1        32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  6.25 %, avg score:  6.25 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0113636</td>\n",
       "<td>0.9966659</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9973940</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9973940</td>\n",
       "<td>0.1818182</td>\n",
       "<td>0.1818182</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0208333</td>\n",
       "<td>0.9943748</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9956542</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966032</td>\n",
       "<td>0.1515152</td>\n",
       "<td>0.3333333</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.9930070</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9937962</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9957260</td>\n",
       "<td>0.1515152</td>\n",
       "<td>0.4848485</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0416667</td>\n",
       "<td>0.9881820</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9905856</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9943241</td>\n",
       "<td>0.1818182</td>\n",
       "<td>0.6666667</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0511364</td>\n",
       "<td>0.9802906</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9854987</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9926897</td>\n",
       "<td>0.1515152</td>\n",
       "<td>0.8181818</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1003788</td>\n",
       "<td>0.0015665</td>\n",
       "<td>3.6923077</td>\n",
       "<td>9.9622642</td>\n",
       "<td>0.2307692</td>\n",
       "<td>0.2362565</td>\n",
       "<td>0.6226415</td>\n",
       "<td>0.6216093</td>\n",
       "<td>0.1818182</td>\n",
       "<td>1.0</td>\n",
       "<td>269.2307692</td>\n",
       "<td>896.2264151</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1515152</td>\n",
       "<td>0.0002900</td>\n",
       "<td>0.0</td>\n",
       "<td>6.6</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0007361</td>\n",
       "<td>0.4125</td>\n",
       "<td>0.4120646</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>560.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2007576</td>\n",
       "<td>0.0001808</td>\n",
       "<td>0.0</td>\n",
       "<td>4.9811321</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002202</td>\n",
       "<td>0.3113208</td>\n",
       "<td>0.3110462</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>398.1132075</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3011364</td>\n",
       "<td>0.0001323</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3207547</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001522</td>\n",
       "<td>0.2075472</td>\n",
       "<td>0.2074148</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>232.0754717</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.3996212</td>\n",
       "<td>0.0001204</td>\n",
       "<td>0.0</td>\n",
       "<td>2.5023697</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001261</td>\n",
       "<td>0.1563981</td>\n",
       "<td>0.1563295</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>150.2369668</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0001124</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001161</td>\n",
       "<td>0.125</td>\n",
       "<td>0.1249684</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6022727</td>\n",
       "<td>0.0001083</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6603774</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001101</td>\n",
       "<td>0.1037736</td>\n",
       "<td>0.1037661</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.0377358</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6988636</td>\n",
       "<td>0.0001027</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4308943</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001064</td>\n",
       "<td>0.0894309</td>\n",
       "<td>0.0894391</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.0894309</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8125</td>\n",
       "<td>0.0001014</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2307692</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001015</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.0769444</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>23.0769231</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8996212</td>\n",
       "<td>0.0000969</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1115789</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001010</td>\n",
       "<td>0.0694737</td>\n",
       "<td>0.0695027</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1578947</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000503</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000739</td>\n",
       "<td>0.0625</td>\n",
       "<td>0.0625335</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0113636                   0.996666           16       16                 1                0.997394     1                           0.997394            0.181818        0.181818                   1500     1500\n",
       "    2        0.0208333                   0.994375           16       16                 1                0.995654     1                           0.996603            0.151515        0.333333                   1500     1500\n",
       "    3        0.030303                    0.993007           16       16                 1                0.993796     1                           0.995726            0.151515        0.484848                   1500     1500\n",
       "    4        0.0416667                   0.988182           16       16                 1                0.990586     1                           0.994324            0.181818        0.666667                   1500     1500\n",
       "    5        0.0511364                   0.980291           16       16                 1                0.985499     1                           0.99269             0.151515        0.818182                   1500     1500\n",
       "    6        0.100379                    0.0015665          3.69231  9.96226            0.230769         0.236257     0.622642                    0.621609            0.181818        1                          269.231  896.226\n",
       "    7        0.151515                    0.00029001         0        6.6                0                0.000736075  0.4125                      0.412065            0               1                          -100     560\n",
       "    8        0.200758                    0.000180831        0        4.98113            0                0.000220238  0.311321                    0.311046            0               1                          -100     398.113\n",
       "    9        0.301136                    0.000132268        0        3.32075            0                0.000152207  0.207547                    0.207415            0               1                          -100     232.075\n",
       "    10       0.399621                    0.000120352        0        2.50237            0                0.000126115  0.156398                    0.156329            0               1                          -100     150.237\n",
       "    11       0.5                         0.000112411        0        2                  0                0.000116061  0.125                       0.124968            0               1                          -100     100\n",
       "    12       0.602273                    0.000108349        0        1.66038            0                0.000110065  0.103774                    0.103766            0               1                          -100     66.0377\n",
       "    13       0.698864                    0.000102687        0        1.43089            0                0.000106448  0.0894309                   0.0894391           0               1                          -100     43.0894\n",
       "    14       0.8125                      0.000101439        0        1.23077            0                0.000101531  0.0769231                   0.0769444           0               1                          -100     23.0769\n",
       "    15       0.899621                    9.69048e-05        0        1.11158            0                0.000101003  0.0694737                   0.0695027           0               1                          -100     11.1579\n",
       "    16       1                           5.03292e-05        0        1                  0                7.38625e-05  0.0625                      0.0625335           0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.013627046112635556\n",
      "RMSE: 0.11673493955382662\n",
      "LogLoss: 0.04328356814974064\n",
      "Mean Per-Class Error: 0.004347826086956497\n",
      "AUC: 0.9978260869565218\n",
      "Gini: 0.9956521739130435\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.12623858990193526: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>False</b></td>\n",
       "<td><b>True</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>False</td>\n",
       "<td>114.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0087</td>\n",
       "<td> (1.0/115.0)</td></tr>\n",
       "<tr><td>True</td>\n",
       "<td>0.0</td>\n",
       "<td>8.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/8.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>114.0</td>\n",
       "<td>9.0</td>\n",
       "<td>0.0081</td>\n",
       "<td> (1.0/123.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       False    True    Error    Rate\n",
       "-----  -------  ------  -------  -----------\n",
       "False  114      1       0.0087   (1.0/115.0)\n",
       "True   0        8       0        (0.0/8.0)\n",
       "Total  114      9       0.0081   (1.0/123.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1262386</td>\n",
       "<td>0.9411765</td>\n",
       "<td>8.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1262386</td>\n",
       "<td>0.9756098</td>\n",
       "<td>8.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9639389</td>\n",
       "<td>0.9375</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.1262386</td>\n",
       "<td>0.9918699</td>\n",
       "<td>8.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9974791</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.1262386</td>\n",
       "<td>1.0</td>\n",
       "<td>8.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9974791</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.1262386</td>\n",
       "<td>0.9387009</td>\n",
       "<td>8.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1262386</td>\n",
       "<td>0.9913043</td>\n",
       "<td>8.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1262386</td>\n",
       "<td>0.9956522</td>\n",
       "<td>8.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.126239     0.941176  8\n",
       "max f2                       0.126239     0.97561   8\n",
       "max f0point5                 0.963939     0.9375    5\n",
       "max accuracy                 0.126239     0.99187   8\n",
       "max precision                0.997479     1         0\n",
       "max recall                   0.126239     1         8\n",
       "max specificity              0.997479     1         0\n",
       "max absolute_mcc             0.126239     0.938701  8\n",
       "max min_per_class_accuracy   0.126239     0.991304  8\n",
       "max mean_per_class_accuracy  0.126239     0.995652  8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  6.50 %, avg score:  6.52 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0162602</td>\n",
       "<td>0.9947546</td>\n",
       "<td>15.3750000</td>\n",
       "<td>15.3750000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9969047</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9969047</td>\n",
       "<td>0.25</td>\n",
       "<td>0.25</td>\n",
       "<td>1437.5000000</td>\n",
       "<td>1437.5000000</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0243902</td>\n",
       "<td>0.9889057</td>\n",
       "<td>15.3750000</td>\n",
       "<td>15.3750000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9891677</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9943257</td>\n",
       "<td>0.125</td>\n",
       "<td>0.375</td>\n",
       "<td>1437.5000000</td>\n",
       "<td>1437.5000000</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0325203</td>\n",
       "<td>0.9871446</td>\n",
       "<td>15.3750000</td>\n",
       "<td>15.3750000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9885722</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9928873</td>\n",
       "<td>0.125</td>\n",
       "<td>0.5</td>\n",
       "<td>1437.5000000</td>\n",
       "<td>1437.5000000</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0406504</td>\n",
       "<td>0.9666353</td>\n",
       "<td>15.3750000</td>\n",
       "<td>15.3750000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9864092</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9915917</td>\n",
       "<td>0.125</td>\n",
       "<td>0.625</td>\n",
       "<td>1437.5000000</td>\n",
       "<td>1437.5000000</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0569106</td>\n",
       "<td>0.9523567</td>\n",
       "<td>7.6875000</td>\n",
       "<td>13.1785714</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9582681</td>\n",
       "<td>0.8571429</td>\n",
       "<td>0.9820707</td>\n",
       "<td>0.125</td>\n",
       "<td>0.75</td>\n",
       "<td>668.7500000</td>\n",
       "<td>1217.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1056911</td>\n",
       "<td>0.0038664</td>\n",
       "<td>5.1250000</td>\n",
       "<td>9.4615385</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.1874245</td>\n",
       "<td>0.6153846</td>\n",
       "<td>0.6153109</td>\n",
       "<td>0.25</td>\n",
       "<td>1.0</td>\n",
       "<td>412.5000000</td>\n",
       "<td>846.1538462</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1544715</td>\n",
       "<td>0.0011057</td>\n",
       "<td>0.0</td>\n",
       "<td>6.4736842</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0021265</td>\n",
       "<td>0.4210526</td>\n",
       "<td>0.4216737</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>547.3684211</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2032520</td>\n",
       "<td>0.0002421</td>\n",
       "<td>0.0</td>\n",
       "<td>4.92</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004938</td>\n",
       "<td>0.32</td>\n",
       "<td>0.3205906</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>392.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3008130</td>\n",
       "<td>0.0001320</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3243243</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001733</td>\n",
       "<td>0.2162162</td>\n",
       "<td>0.2166714</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>232.4324324</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.3983740</td>\n",
       "<td>0.0001190</td>\n",
       "<td>0.0</td>\n",
       "<td>2.5102041</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001255</td>\n",
       "<td>0.1632653</td>\n",
       "<td>0.1636398</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>151.0204082</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5040650</td>\n",
       "<td>0.0001126</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9838710</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001154</td>\n",
       "<td>0.1290323</td>\n",
       "<td>0.1293524</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>98.3870968</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6016260</td>\n",
       "<td>0.0001086</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6621622</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001099</td>\n",
       "<td>0.1081081</td>\n",
       "<td>0.1083942</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.2162162</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7560976</td>\n",
       "<td>0.0001014</td>\n",
       "<td>0.0</td>\n",
       "<td>1.3225806</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001038</td>\n",
       "<td>0.0860215</td>\n",
       "<td>0.0862703</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>32.2580645</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7967480</td>\n",
       "<td>0.0001012</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2551020</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001014</td>\n",
       "<td>0.0816327</td>\n",
       "<td>0.0818740</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.5102041</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8943089</td>\n",
       "<td>0.0000710</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1181818</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000897</td>\n",
       "<td>0.0727273</td>\n",
       "<td>0.0729520</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.8181818</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000601</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000638</td>\n",
       "<td>0.0650407</td>\n",
       "<td>0.0652484</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift    cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain    cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  ------  -----------------\n",
       "    1        0.0162602                   0.994755           15.375  15.375             1                0.996905     1                           0.996905            0.25            0.25                       1437.5  1437.5\n",
       "    2        0.0243902                   0.988906           15.375  15.375             1                0.989168     1                           0.994326            0.125           0.375                      1437.5  1437.5\n",
       "    3        0.0325203                   0.987145           15.375  15.375             1                0.988572     1                           0.992887            0.125           0.5                        1437.5  1437.5\n",
       "    4        0.0406504                   0.966635           15.375  15.375             1                0.986409     1                           0.991592            0.125           0.625                      1437.5  1437.5\n",
       "    5        0.0569106                   0.952357           7.6875  13.1786            0.5              0.958268     0.857143                    0.982071            0.125           0.75                       668.75  1217.86\n",
       "    6        0.105691                    0.00386637         5.125   9.46154            0.333333         0.187424     0.615385                    0.615311            0.25            1                          412.5   846.154\n",
       "    7        0.154472                    0.0011057          0       6.47368            0                0.0021265    0.421053                    0.421674            0               1                          -100    547.368\n",
       "    8        0.203252                    0.000242064        0       4.92               0                0.000493849  0.32                        0.320591            0               1                          -100    392\n",
       "    9        0.300813                    0.00013201         0       3.32432            0                0.000173257  0.216216                    0.216671            0               1                          -100    232.432\n",
       "    10       0.398374                    0.000119007        0       2.5102             0                0.000125536  0.163265                    0.16364             0               1                          -100    151.02\n",
       "    11       0.504065                    0.000112649        0       1.98387            0                0.000115434  0.129032                    0.129352            0               1                          -100    98.3871\n",
       "    12       0.601626                    0.000108646        0       1.66216            0                0.000109917  0.108108                    0.108394            0               1                          -100    66.2162\n",
       "    13       0.756098                    0.000101439        0       1.32258            0                0.000103761  0.0860215                   0.0862703           0               1                          -100    32.2581\n",
       "    14       0.796748                    0.000101246        0       1.2551             0                0.000101361  0.0816327                   0.081874            0               1                          -100    25.5102\n",
       "    15       0.894309                    7.09915e-05        0       1.11818            0                8.96956e-05  0.0727273                   0.072952            0               1                          -100    11.8182\n",
       "    16       1                           6.01315e-05        0       1                  0                6.37869e-05  0.0650407                   0.0652484           0               1                          -100    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.004435346806724833\n",
      "RMSE: 0.06659839943065324\n",
      "LogLoss: 0.015883101472134616\n",
      "Mean Per-Class Error: 0.002020202020202033\n",
      "AUC: 0.9998775635139271\n",
      "Gini: 0.9997551270278542\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8984000881321323: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>False</b></td>\n",
       "<td><b>True</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>False</td>\n",
       "<td>495.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/495.0)</td></tr>\n",
       "<tr><td>True</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td>\n",
       "<td>0.0303</td>\n",
       "<td> (1.0/33.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>496.0</td>\n",
       "<td>32.0</td>\n",
       "<td>0.0019</td>\n",
       "<td> (1.0/528.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       False    True    Error    Rate\n",
       "-----  -------  ------  -------  -----------\n",
       "False  495      0       0        (0.0/495.0)\n",
       "True   1        32      0.0303   (1.0/33.0)\n",
       "Total  496      32      0.0019   (1.0/528.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.8984001</td>\n",
       "<td>0.9846154</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.7186424</td>\n",
       "<td>0.9880240</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.8984001</td>\n",
       "<td>0.9937888</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.8984001</td>\n",
       "<td>0.9981061</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9996015</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.7186424</td>\n",
       "<td>1.0</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9996015</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.8984001</td>\n",
       "<td>0.9837388</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.7186424</td>\n",
       "<td>0.9959596</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.7186424</td>\n",
       "<td>0.9979798</td>\n",
       "<td>34.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.8984       0.984615  31\n",
       "max f2                       0.718642     0.988024  34\n",
       "max f0point5                 0.8984       0.993789  31\n",
       "max accuracy                 0.8984       0.998106  31\n",
       "max precision                0.999602     1         0\n",
       "max recall                   0.718642     1         34\n",
       "max specificity              0.999602     1         0\n",
       "max absolute_mcc             0.8984       0.983739  31\n",
       "max min_per_class_accuracy   0.718642     0.99596   34\n",
       "max mean_per_class_accuracy  0.718642     0.99798   34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  6.25 %, avg score:  6.66 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0113636</td>\n",
       "<td>0.9974372</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9986911</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9986911</td>\n",
       "<td>0.1818182</td>\n",
       "<td>0.1818182</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0208333</td>\n",
       "<td>0.9874622</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9920829</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9956874</td>\n",
       "<td>0.1515152</td>\n",
       "<td>0.3333333</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.9716484</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9805329</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9909516</td>\n",
       "<td>0.1515152</td>\n",
       "<td>0.4848485</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0416667</td>\n",
       "<td>0.9419888</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9611758</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9828309</td>\n",
       "<td>0.1818182</td>\n",
       "<td>0.6666667</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0511364</td>\n",
       "<td>0.9003515</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9061497</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9686307</td>\n",
       "<td>0.1515152</td>\n",
       "<td>0.8181818</td>\n",
       "<td>1500.0</td>\n",
       "<td>1500.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1003788</td>\n",
       "<td>0.0088755</td>\n",
       "<td>3.6923077</td>\n",
       "<td>9.9622642</td>\n",
       "<td>0.2307692</td>\n",
       "<td>0.3323907</td>\n",
       "<td>0.6226415</td>\n",
       "<td>0.6565129</td>\n",
       "<td>0.1818182</td>\n",
       "<td>1.0</td>\n",
       "<td>269.2307692</td>\n",
       "<td>896.2264151</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1515152</td>\n",
       "<td>0.0023086</td>\n",
       "<td>0.0</td>\n",
       "<td>6.6</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0043522</td>\n",
       "<td>0.4125</td>\n",
       "<td>0.4364087</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>560.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2045455</td>\n",
       "<td>0.0020855</td>\n",
       "<td>0.0</td>\n",
       "<td>4.8888889</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0021814</td>\n",
       "<td>0.3055556</td>\n",
       "<td>0.3238312</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>388.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3011364</td>\n",
       "<td>0.0013274</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3207547</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0018736</td>\n",
       "<td>0.2075472</td>\n",
       "<td>0.2205618</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>232.0754717</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.3996212</td>\n",
       "<td>0.0007244</td>\n",
       "<td>0.0</td>\n",
       "<td>2.5023697</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0008317</td>\n",
       "<td>0.1563981</td>\n",
       "<td>0.1664103</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>150.2369668</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0001763</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0005669</td>\n",
       "<td>0.125</td>\n",
       "<td>0.1331160</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6022727</td>\n",
       "<td>0.0001096</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6603774</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001307</td>\n",
       "<td>0.1037736</td>\n",
       "<td>0.1105336</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.0377358</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6988636</td>\n",
       "<td>0.0000326</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4308943</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000733</td>\n",
       "<td>0.0894309</td>\n",
       "<td>0.0952667</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.0894309</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7992424</td>\n",
       "<td>0.0000220</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2511848</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000265</td>\n",
       "<td>0.0781991</td>\n",
       "<td>0.0833053</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1184834</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8996212</td>\n",
       "<td>0.0000021</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1115789</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000089</td>\n",
       "<td>0.0694737</td>\n",
       "<td>0.0740111</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1578947</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000007</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000015</td>\n",
       "<td>0.0625</td>\n",
       "<td>0.0665821</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0113636                   0.997437           16       16                 1                0.998691     1                           0.998691            0.181818        0.181818                   1500     1500\n",
       "    2        0.0208333                   0.987462           16       16                 1                0.992083     1                           0.995687            0.151515        0.333333                   1500     1500\n",
       "    3        0.030303                    0.971648           16       16                 1                0.980533     1                           0.990952            0.151515        0.484848                   1500     1500\n",
       "    4        0.0416667                   0.941989           16       16                 1                0.961176     1                           0.982831            0.181818        0.666667                   1500     1500\n",
       "    5        0.0511364                   0.900351           16       16                 1                0.90615      1                           0.968631            0.151515        0.818182                   1500     1500\n",
       "    6        0.100379                    0.00887554         3.69231  9.96226            0.230769         0.332391     0.622642                    0.656513            0.181818        1                          269.231  896.226\n",
       "    7        0.151515                    0.00230865         0        6.6                0                0.00435218   0.4125                      0.436409            0               1                          -100     560\n",
       "    8        0.204545                    0.00208548         0        4.88889            0                0.00218142   0.305556                    0.323831            0               1                          -100     388.889\n",
       "    9        0.301136                    0.00132738         0        3.32075            0                0.00187357   0.207547                    0.220562            0               1                          -100     232.075\n",
       "    10       0.399621                    0.000724373        0        2.50237            0                0.000831678  0.156398                    0.16641             0               1                          -100     150.237\n",
       "    11       0.5                         0.000176309        0        2                  0                0.000566911  0.125                       0.133116            0               1                          -100     100\n",
       "    12       0.602273                    0.000109615        0        1.66038            0                0.000130665  0.103774                    0.110534            0               1                          -100     66.0377\n",
       "    13       0.698864                    3.2614e-05         0        1.43089            0                7.32703e-05  0.0894309                   0.0952667           0               1                          -100     43.0894\n",
       "    14       0.799242                    2.20421e-05        0        1.25118            0                2.65405e-05  0.0781991                   0.0833053           0               1                          -100     25.1185\n",
       "    15       0.899621                    2.0635e-06         0        1.11158            0                8.89062e-06  0.0694737                   0.0740111           0               1                          -100     11.1579\n",
       "    16       1                           7.15738e-07        0        1                  0                1.54744e-06  0.0625                      0.0665821           0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9981132</td>\n",
       "<td>0.0026683</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.990566</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9997114</td>\n",
       "<td>0.0004081</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.998557</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0018868</td>\n",
       "<td>0.0026683</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0094340</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>0.2</td>\n",
       "<td>0.2828427</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9794872</td>\n",
       "<td>0.0290095</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8974359</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9866667</td>\n",
       "<td>0.0188562</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9333333</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.9944444</td>\n",
       "<td>0.0078567</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9722222</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>16.415476</td>\n",
       "<td>1.9144108</td>\n",
       "<td>15.142858</td>\n",
       "<td>17.666666</td>\n",
       "<td>15.142858</td>\n",
       "<td>13.125</td>\n",
       "<td>21.0</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.0158835</td>\n",
       "<td>0.0106358</td>\n",
       "<td>0.0015761</td>\n",
       "<td>0.0031036</td>\n",
       "<td>0.0427675</td>\n",
       "<td>0.0114903</td>\n",
       "<td>0.0204800</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.0020202</td>\n",
       "<td>0.0028570</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0101010</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9861356</td>\n",
       "<td>0.0196072</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9306781</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9989899</td>\n",
       "<td>0.0014285</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9949495</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0010101</td>\n",
       "<td>0.0014285</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0050505</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0044364</td>\n",
       "<td>0.0032859</td>\n",
       "<td>0.0001108</td>\n",
       "<td>0.0002610</td>\n",
       "<td>0.0123979</td>\n",
       "<td>0.0026692</td>\n",
       "<td>0.0067429</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.975</td>\n",
       "<td>0.0353553</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.875</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.9211395</td>\n",
       "<td>0.0573440</td>\n",
       "<td>0.9982041</td>\n",
       "<td>0.9951123</td>\n",
       "<td>0.7989858</td>\n",
       "<td>0.9620767</td>\n",
       "<td>0.8513185</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.0543612</td>\n",
       "<td>0.0272142</td>\n",
       "<td>0.0105244</td>\n",
       "<td>0.0161556</td>\n",
       "<td>0.1113459</td>\n",
       "<td>0.0516648</td>\n",
       "<td>0.0821153</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9979798</td>\n",
       "<td>0.0028570</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.989899</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean        sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ----------  -----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.998113    0.00266833   1             1             0.990566      1             1\n",
       "auc                      0.999711    0.000408142  1             1             0.998557      1             1\n",
       "err                      0.00188679  0.00266833   0             0             0.00943396    0             0\n",
       "err_count                0.2         0.282843     0             0             1             0             0\n",
       "f0point5                 0.979487    0.0290095    1             1             0.897436      1             1\n",
       "f1                       0.986667    0.0188562    1             1             0.933333      1             1\n",
       "f2                       0.994444    0.00785674   1             1             0.972222      1             1\n",
       "lift_top_group           16.4155     1.91441      15.1429       17.6667       15.1429       13.125        21\n",
       "logloss                  0.0158835   0.0106358    0.0015761     0.0031036     0.0427675     0.0114903     0.02048\n",
       "max_per_class_error      0.0020202   0.002857     0             0             0.010101      0             0\n",
       "mcc                      0.986136    0.0196072    1             1             0.930678      1             1\n",
       "mean_per_class_accuracy  0.99899     0.0014285    1             1             0.99495       1             1\n",
       "mean_per_class_error     0.0010101   0.0014285    0             0             0.00505051    0             0\n",
       "mse                      0.00443637  0.00328593   0.000110763   0.000261003   0.0123979     0.00266925    0.00674293\n",
       "precision                0.975       0.0353553    1             1             0.875         1             1\n",
       "r2                       0.921139    0.057344     0.998204      0.995112      0.798986      0.962077      0.851318\n",
       "recall                   1           0            1             1             1             1             1\n",
       "rmse                     0.0543612   0.0272142    0.0105244     0.0161556     0.111346      0.0516648     0.0821153\n",
       "specificity              0.99798     0.002857     1             1             0.989899      1             1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:23:59</td>\n",
       "<td> 2 min  5.644 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2420615</td>\n",
       "<td>0.2337917</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9375</td>\n",
       "<td>0.2466107</td>\n",
       "<td>0.2406719</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9349593</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:23:59</td>\n",
       "<td> 2 min  5.651 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.1971347</td>\n",
       "<td>0.1405340</td>\n",
       "<td>0.9999694</td>\n",
       "<td>16.0</td>\n",
       "<td>0.0018939</td>\n",
       "<td>0.2088069</td>\n",
       "<td>0.1557027</td>\n",
       "<td>0.9918478</td>\n",
       "<td>7.6875000</td>\n",
       "<td>0.0162602</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:23:59</td>\n",
       "<td> 2 min  5.659 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.1605996</td>\n",
       "<td>0.1015051</td>\n",
       "<td>1.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1784812</td>\n",
       "<td>0.1178625</td>\n",
       "<td>0.9929348</td>\n",
       "<td>15.3750000</td>\n",
       "<td>0.0162602</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:23:59</td>\n",
       "<td> 2 min  5.667 sec</td>\n",
       "<td>15.0</td>\n",
       "<td>0.1328976</td>\n",
       "<td>0.0780790</td>\n",
       "<td>1.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1576261</td>\n",
       "<td>0.0962951</td>\n",
       "<td>0.9940217</td>\n",
       "<td>15.3750000</td>\n",
       "<td>0.0162602</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:23:59</td>\n",
       "<td> 2 min  5.674 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.1091887</td>\n",
       "<td>0.0606583</td>\n",
       "<td>1.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1428991</td>\n",
       "<td>0.0818004</td>\n",
       "<td>0.9923913</td>\n",
       "<td>15.3750000</td>\n",
       "<td>0.0162602</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:23:59</td>\n",
       "<td> 2 min  5.891 sec</td>\n",
       "<td>135.0</td>\n",
       "<td>0.0091357</td>\n",
       "<td>0.0019880</td>\n",
       "<td>1.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1152574</td>\n",
       "<td>0.0422666</td>\n",
       "<td>0.9978261</td>\n",
       "<td>15.3750000</td>\n",
       "<td>0.0081301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:23:59</td>\n",
       "<td> 2 min  5.900 sec</td>\n",
       "<td>140.0</td>\n",
       "<td>0.0085130</td>\n",
       "<td>0.0017648</td>\n",
       "<td>1.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1156279</td>\n",
       "<td>0.0422919</td>\n",
       "<td>0.9978261</td>\n",
       "<td>15.3750000</td>\n",
       "<td>0.0081301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:23:59</td>\n",
       "<td> 2 min  5.910 sec</td>\n",
       "<td>145.0</td>\n",
       "<td>0.0080213</td>\n",
       "<td>0.0016132</td>\n",
       "<td>1.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1154632</td>\n",
       "<td>0.0421379</td>\n",
       "<td>0.9978261</td>\n",
       "<td>15.3750000</td>\n",
       "<td>0.0081301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:23:59</td>\n",
       "<td> 2 min  5.919 sec</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0072162</td>\n",
       "<td>0.0014365</td>\n",
       "<td>1.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1166632</td>\n",
       "<td>0.0432905</td>\n",
       "<td>0.9978261</td>\n",
       "<td>15.3750000</td>\n",
       "<td>0.0081301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:23:59</td>\n",
       "<td> 2 min  5.925 sec</td>\n",
       "<td>151.0</td>\n",
       "<td>0.0071001</td>\n",
       "<td>0.0014167</td>\n",
       "<td>1.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1167349</td>\n",
       "<td>0.0432836</td>\n",
       "<td>0.9978261</td>\n",
       "<td>15.3750000</td>\n",
       "<td>0.0081301</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration          number_of_trees    training_rmse         training_logloss       training_auc        training_lift    training_classification_error    validation_rmse      validation_logloss    validation_auc      validation_lift     validation_classification_error\n",
       "---  -------------------  ----------------  -----------------  --------------------  ---------------------  ------------------  ---------------  -------------------------------  -------------------  --------------------  ------------------  ------------------  ---------------------------------\n",
       "     2018-10-15 21:23:59  2 min  5.644 sec  0.0                0.24206145913796356   0.23379165870645927    0.5                 1.0              0.9375                           0.24661066300079373  0.24067186755072303   0.5                 1.0                 0.9349593495934959\n",
       "     2018-10-15 21:23:59  2 min  5.651 sec  5.0                0.19713470034617417   0.14053402034468251    0.9999693908784818  16.0             0.001893939393939394             0.2088069078521661   0.15570268317073127   0.9918478260869565  7.687499999999999   0.016260162601626018\n",
       "     2018-10-15 21:23:59  2 min  5.659 sec  10.0               0.16059956223191962   0.10150511198547736    1.0                 16.0             0.0                              0.17848123293794116  0.117862451254678     0.9929347826086956  15.374999999999998  0.016260162601626018\n",
       "     2018-10-15 21:23:59  2 min  5.667 sec  15.0               0.1328976342440515    0.07807901843152104    1.0                 16.0             0.0                              0.15762613213914484  0.09629509911057878   0.9940217391304348  15.374999999999998  0.016260162601626018\n",
       "     2018-10-15 21:23:59  2 min  5.674 sec  20.0               0.10918870736263894   0.060658304772669584   1.0                 16.0             0.0                              0.14289906095665117  0.08180041960459403   0.9923913043478261  15.374999999999998  0.016260162601626018\n",
       "---  ---                  ---               ---                ---                   ---                    ---                 ---              ---                              ---                  ---                   ---                 ---                 ---\n",
       "     2018-10-15 21:23:59  2 min  5.891 sec  135.0              0.009135722806684716  0.0019879642369712183  1.0                 16.0             0.0                              0.11525743929387003  0.042266621688389745  0.9978260869565218  15.374999999999998  0.008130081300813009\n",
       "     2018-10-15 21:23:59  2 min  5.900 sec  140.0              0.008512967730759774  0.001764794894481358   1.0                 16.0             0.0                              0.11562793649887537  0.04229193375140358   0.9978260869565218  15.374999999999998  0.008130081300813009\n",
       "     2018-10-15 21:23:59  2 min  5.910 sec  145.0              0.008021295019668114  0.0016132388822185386  1.0                 16.0             0.0                              0.11546323287211266  0.04213786376616998   0.9978260869565218  15.374999999999998  0.008130081300813009\n",
       "     2018-10-15 21:23:59  2 min  5.919 sec  150.0              0.007216161377692652  0.0014365129027453202  1.0                 16.0             0.0                              0.11666315966587308  0.04329051650455503   0.9978260869565218  15.374999999999998  0.008130081300813009\n",
       "     2018-10-15 21:23:59  2 min  5.925 sec  151.0              0.007100085827100602  0.0014166648012189297  1.0                 16.0             0.0                              0.11673493955382662  0.04328356814974064   0.9978260869565218  15.374999999999998  0.008130081300813009"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>48.8985329</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1936618</td></tr>\n",
       "<tr><td>Egg_Group_1</td>\n",
       "<td>48.6230888</td>\n",
       "<td>0.9943670</td>\n",
       "<td>0.1925709</td></tr>\n",
       "<tr><td>Catch_Rate</td>\n",
       "<td>43.7949829</td>\n",
       "<td>0.8956298</td>\n",
       "<td>0.1734493</td></tr>\n",
       "<tr><td>hasGender</td>\n",
       "<td>24.8252621</td>\n",
       "<td>0.5076893</td>\n",
       "<td>0.0983200</td></tr>\n",
       "<tr><td>Weight_kg</td>\n",
       "<td>24.3187714</td>\n",
       "<td>0.4973313</td>\n",
       "<td>0.0963141</td></tr>\n",
       "<tr><td>Sp_Atk</td>\n",
       "<td>18.1800365</td>\n",
       "<td>0.3717910</td>\n",
       "<td>0.0720017</td></tr>\n",
       "<tr><td>Height_m</td>\n",
       "<td>8.8033495</td>\n",
       "<td>0.1800330</td>\n",
       "<td>0.0348655</td></tr>\n",
       "<tr><td>Pr_Male</td>\n",
       "<td>7.8636870</td>\n",
       "<td>0.1608164</td>\n",
       "<td>0.0311440</td></tr>\n",
       "<tr><td>Defense</td>\n",
       "<td>5.6841083</td>\n",
       "<td>0.1162429</td>\n",
       "<td>0.0225118</td></tr>\n",
       "<tr><td>Body_Style</td>\n",
       "<td>4.9551687</td>\n",
       "<td>0.1013357</td>\n",
       "<td>0.0196249</td></tr>\n",
       "<tr><td>Speed</td>\n",
       "<td>4.7389112</td>\n",
       "<td>0.0969132</td>\n",
       "<td>0.0187684</td></tr>\n",
       "<tr><td>Type_1</td>\n",
       "<td>4.2406125</td>\n",
       "<td>0.0867227</td>\n",
       "<td>0.0167949</td></tr>\n",
       "<tr><td>Sp_Def</td>\n",
       "<td>3.9272740</td>\n",
       "<td>0.0803148</td>\n",
       "<td>0.0155539</td></tr>\n",
       "<tr><td>Color</td>\n",
       "<td>2.0592716</td>\n",
       "<td>0.0421132</td>\n",
       "<td>0.0081557</td></tr>\n",
       "<tr><td>HP</td>\n",
       "<td>1.2484794</td>\n",
       "<td>0.0255320</td>\n",
       "<td>0.0049446</td></tr>\n",
       "<tr><td>Attack</td>\n",
       "<td>0.2956084</td>\n",
       "<td>0.0060453</td>\n",
       "<td>0.0011708</td></tr>\n",
       "<tr><td>Generation</td>\n",
       "<td>0.0373554</td>\n",
       "<td>0.0007639</td>\n",
       "<td>0.0001479</td></tr>\n",
       "<tr><td>hasMegaEvolution</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "variable          relative_importance    scaled_importance    percentage\n",
       "----------------  ---------------------  -------------------  ------------\n",
       "Total             48.8985                1                    0.193662\n",
       "Egg_Group_1       48.6231                0.994367             0.192571\n",
       "Catch_Rate        43.795                 0.89563              0.173449\n",
       "hasGender         24.8253                0.507689             0.09832\n",
       "Weight_kg         24.3188                0.497331             0.0963141\n",
       "Sp_Atk            18.18                  0.371791             0.0720017\n",
       "Height_m          8.80335                0.180033             0.0348655\n",
       "Pr_Male           7.86369                0.160816             0.031144\n",
       "Defense           5.68411                0.116243             0.0225118\n",
       "Body_Style        4.95517                0.101336             0.0196249\n",
       "Speed             4.73891                0.0969132            0.0187684\n",
       "Type_1            4.24061                0.0867227            0.0167949\n",
       "Sp_Def            3.92727                0.0803148            0.0155539\n",
       "Color             2.05927                0.0421132            0.00815571\n",
       "HP                1.24848                0.025532             0.00494458\n",
       "Attack            0.295608               0.00604534           0.00117075\n",
       "Generation        0.0373554              0.000763937          0.000147945\n",
       "hasMegaEvolution  0                      0                    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2OBinomialModel.plot of >"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>predict  </th><th style=\"text-align: right;\">   False</th><th style=\"text-align: right;\">       True</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.999899</td><td style=\"text-align: right;\">0.000101423</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.999899</td><td style=\"text-align: right;\">0.000101423</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.999941</td><td style=\"text-align: right;\">5.92181e-05</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.999939</td><td style=\"text-align: right;\">6.1262e-05 </td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.999905</td><td style=\"text-align: right;\">9.49815e-05</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.999904</td><td style=\"text-align: right;\">9.62494e-05</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.999725</td><td style=\"text-align: right;\">0.000274607</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.999877</td><td style=\"text-align: right;\">0.000123367</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.99994 </td><td style=\"text-align: right;\">6.00748e-05</td></tr>\n",
       "<tr><td>False    </td><td style=\"text-align: right;\">0.999873</td><td style=\"text-align: right;\">0.000126932</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = aml.predict(test)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.022326803735845484\n",
      "RMSE: 0.14942156382478897\n",
      "LogLoss: 0.08444826881201595\n",
      "Mean Per-Class Error: 0.007692307692307665\n",
      "AUC: 0.9907692307692308\n",
      "Gini: 0.9815384615384617\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.41137175869039677: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>False</b></td>\n",
       "<td><b>True</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>False</td>\n",
       "<td>64.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0154</td>\n",
       "<td> (1.0/65.0)</td></tr>\n",
       "<tr><td>True</td>\n",
       "<td>0.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/5.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>64.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.0143</td>\n",
       "<td> (1.0/70.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       False    True    Error    Rate\n",
       "-----  -------  ------  -------  ----------\n",
       "False  64       1       0.0154   (1.0/65.0)\n",
       "True   0        5       0        (0.0/5.0)\n",
       "Total  64       6       0.0143   (1.0/70.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4113718</td>\n",
       "<td>0.9090909</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.4113718</td>\n",
       "<td>0.9615385</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.4113718</td>\n",
       "<td>0.8620690</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4113718</td>\n",
       "<td>0.9857143</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9990058</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.4113718</td>\n",
       "<td>1.0</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9990058</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4113718</td>\n",
       "<td>0.9058216</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4113718</td>\n",
       "<td>0.9846154</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4113718</td>\n",
       "<td>0.9923077</td>\n",
       "<td>5.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.411372     0.909091  5\n",
       "max f2                       0.411372     0.961538  5\n",
       "max f0point5                 0.411372     0.862069  5\n",
       "max accuracy                 0.411372     0.985714  5\n",
       "max precision                0.999006     1         0\n",
       "max recall                   0.411372     1         5\n",
       "max specificity              0.999006     1         0\n",
       "max absolute_mcc             0.411372     0.905822  5\n",
       "max min_per_class_accuracy   0.411372     0.984615  5\n",
       "max mean_per_class_accuracy  0.411372     0.992308  5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  7.14 %, avg score:  6.98 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0142857</td>\n",
       "<td>0.9934207</td>\n",
       "<td>14.0</td>\n",
       "<td>14.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9990058</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9990058</td>\n",
       "<td>0.2</td>\n",
       "<td>0.2</td>\n",
       "<td>1300.0</td>\n",
       "<td>1300.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0285714</td>\n",
       "<td>0.9891986</td>\n",
       "<td>14.0</td>\n",
       "<td>14.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9909114</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9949586</td>\n",
       "<td>0.2</td>\n",
       "<td>0.4</td>\n",
       "<td>1300.0</td>\n",
       "<td>1300.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0428571</td>\n",
       "<td>0.9858112</td>\n",
       "<td>0.0</td>\n",
       "<td>9.3333333</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9864039</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.9921070</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4</td>\n",
       "<td>-100.0</td>\n",
       "<td>833.3333333</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0428571</td>\n",
       "<td>0.9799687</td>\n",
       "<td>0.0</td>\n",
       "<td>9.3333333</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.9921070</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4</td>\n",
       "<td>-100.0</td>\n",
       "<td>833.3333333</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0571429</td>\n",
       "<td>0.7661217</td>\n",
       "<td>14.0</td>\n",
       "<td>10.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9779366</td>\n",
       "<td>0.75</td>\n",
       "<td>0.9885644</td>\n",
       "<td>0.2</td>\n",
       "<td>0.6</td>\n",
       "<td>1300.0</td>\n",
       "<td>950.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.0018950</td>\n",
       "<td>9.3333333</td>\n",
       "<td>10.0</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.3071701</td>\n",
       "<td>0.7142857</td>\n",
       "<td>0.6965383</td>\n",
       "<td>0.4</td>\n",
       "<td>1.0</td>\n",
       "<td>833.3333333</td>\n",
       "<td>900.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1571429</td>\n",
       "<td>0.0003682</td>\n",
       "<td>0.0</td>\n",
       "<td>6.3636364</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0009642</td>\n",
       "<td>0.4545455</td>\n",
       "<td>0.4436022</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>536.3636364</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.0002493</td>\n",
       "<td>0.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0003016</td>\n",
       "<td>0.3571429</td>\n",
       "<td>0.3486092</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>400.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.0001324</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3333333</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001690</td>\n",
       "<td>0.2380952</td>\n",
       "<td>0.2324625</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>233.3333333</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0001217</td>\n",
       "<td>0.0</td>\n",
       "<td>2.5</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001248</td>\n",
       "<td>0.1785714</td>\n",
       "<td>0.1743781</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>150.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0001133</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001182</td>\n",
       "<td>0.1428571</td>\n",
       "<td>0.1395261</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0001072</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6666667</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001089</td>\n",
       "<td>0.1190476</td>\n",
       "<td>0.1162899</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.0001018</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285714</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001055</td>\n",
       "<td>0.1020408</td>\n",
       "<td>0.0996921</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8285714</td>\n",
       "<td>0.0001014</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2068966</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001014</td>\n",
       "<td>0.0862069</td>\n",
       "<td>0.0842384</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>20.6896552</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0000961</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1111111</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000992</td>\n",
       "<td>0.0793651</td>\n",
       "<td>0.0775607</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000591</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000676</td>\n",
       "<td>0.0714286</td>\n",
       "<td>0.0698114</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0142857                   0.993421           14       14                 1                0.999006     1                           0.999006            0.2             0.2                        1300     1300\n",
       "    2        0.0285714                   0.989199           14       14                 1                0.990911     1                           0.994959            0.2             0.4                        1300     1300\n",
       "    3        0.0428571                   0.985811           0        9.33333            0                0.986404     0.666667                    0.992107            0               0.4                        -100     833.333\n",
       "    4        0.0428571                   0.979969           0        9.33333            0                0            0.666667                    0.992107            0               0.4                        -100     833.333\n",
       "    5        0.0571429                   0.766122           14       10.5               1                0.977937     0.75                        0.988564            0.2             0.6                        1300     950\n",
       "    6        0.1                         0.00189501         9.33333  10                 0.666667         0.30717      0.714286                    0.696538            0.4             1                          833.333  900\n",
       "    7        0.157143                    0.000368244        0        6.36364            0                0.000964154  0.454545                    0.443602            0               1                          -100     536.364\n",
       "    8        0.2                         0.000249302        0        5                  0                0.000301553  0.357143                    0.348609            0               1                          -100     400\n",
       "    9        0.3                         0.000132394        0        3.33333            0                0.000168975  0.238095                    0.232462            0               1                          -100     233.333\n",
       "    10       0.4                         0.000121658        0        2.5                0                0.00012477   0.178571                    0.174378            0               1                          -100     150\n",
       "    11       0.5                         0.000113307        0        2                  0                0.000118175  0.142857                    0.139526            0               1                          -100     100\n",
       "    12       0.6                         0.000107201        0        1.66667            0                0.000108918  0.119048                    0.11629             0               1                          -100     66.6667\n",
       "    13       0.7                         0.000101808        0        1.42857            0                0.000105529  0.102041                    0.0996921           0               1                          -100     42.8571\n",
       "    14       0.828571                    0.000101423        0        1.2069             0                0.00010143   0.0862069                   0.0842384           0               1                          -100     20.6897\n",
       "    15       0.9                         9.61226e-05        0        1.11111            0                9.91712e-05  0.0793651                   0.0775607           0               1                          -100     11.1111\n",
       "    16       1                           5.90725e-05        0        1                  0                6.75684e-05  0.0714286                   0.0698114           0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref = aml.leader.model_performance(test)\n",
    "pref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For model GBM_grid_0_AutoML_20181015_212135_model_53 the AUC is 0.999878 on training data and 0.9907692307692308 on testing data. The model is a good fit.\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 MultiClass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_time = 333\n",
    "name3 = 'abalone classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path3 = '/Users/matt/Desktop/abalone.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:37306..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_144\"; Java(TM) SE Runtime Environment (build 1.8.0_144-b01); Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)\n",
      "  Starting server from /anaconda3/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/qb/37dx26k10cn0288tblh64zg40000gn/T/tmpgb_bqo6q\n",
      "  JVM stdout: /var/folders/qb/37dx26k10cn0288tblh64zg40000gn/T/tmpgb_bqo6q/h2o_matt_started_from_python.out\n",
      "  JVM stderr: /var/folders/qb/37dx26k10cn0288tblh64zg40000gn/T/tmpgb_bqo6q/h2o_matt_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:37306\n",
      "Connecting to H2O server at http://127.0.0.1:37306... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.20.0.8</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>24 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_matt_9p4ln6</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>5.750 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:37306</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.3 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         02 secs\n",
       "H2O cluster timezone:       America/New_York\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.20.0.8\n",
       "H2O cluster version age:    24 days\n",
       "H2O cluster name:           H2O_from_python_matt_9p4ln6\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    5.750 Gb\n",
       "H2O cluster total cores:    0\n",
       "H2O cluster allowed cores:  0\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:37306\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.3 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "port_no=random.randint(5555,55555)\n",
    "h2o.init(strict_version_check=False,min_mem_size_GB=6,port=port_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/matt/Desktop/abalone.csv\n"
     ]
    }
   ],
   "source": [
    "print(data_path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "df3 = h2o.import_file(data_path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Sex  </th><th style=\"text-align: right;\">  Length</th><th style=\"text-align: right;\">  Diameter</th><th style=\"text-align: right;\">  Height</th><th style=\"text-align: right;\">  Whole weight</th><th style=\"text-align: right;\">  Shucked weight</th><th style=\"text-align: right;\">  Viscera weight</th><th style=\"text-align: right;\">  Shell weight</th><th style=\"text-align: right;\">  Rings</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>M    </td><td style=\"text-align: right;\">   0.455</td><td style=\"text-align: right;\">     0.365</td><td style=\"text-align: right;\">   0.095</td><td style=\"text-align: right;\">        0.514 </td><td style=\"text-align: right;\">          0.2245</td><td style=\"text-align: right;\">          0.101 </td><td style=\"text-align: right;\">         0.15 </td><td style=\"text-align: right;\">     15</td></tr>\n",
       "<tr><td>M    </td><td style=\"text-align: right;\">   0.35 </td><td style=\"text-align: right;\">     0.265</td><td style=\"text-align: right;\">   0.09 </td><td style=\"text-align: right;\">        0.2255</td><td style=\"text-align: right;\">          0.0995</td><td style=\"text-align: right;\">          0.0485</td><td style=\"text-align: right;\">         0.07 </td><td style=\"text-align: right;\">      7</td></tr>\n",
       "<tr><td>F    </td><td style=\"text-align: right;\">   0.53 </td><td style=\"text-align: right;\">     0.42 </td><td style=\"text-align: right;\">   0.135</td><td style=\"text-align: right;\">        0.677 </td><td style=\"text-align: right;\">          0.2565</td><td style=\"text-align: right;\">          0.1415</td><td style=\"text-align: right;\">         0.21 </td><td style=\"text-align: right;\">      9</td></tr>\n",
       "<tr><td>M    </td><td style=\"text-align: right;\">   0.44 </td><td style=\"text-align: right;\">     0.365</td><td style=\"text-align: right;\">   0.125</td><td style=\"text-align: right;\">        0.516 </td><td style=\"text-align: right;\">          0.2155</td><td style=\"text-align: right;\">          0.114 </td><td style=\"text-align: right;\">         0.155</td><td style=\"text-align: right;\">     10</td></tr>\n",
       "<tr><td>I    </td><td style=\"text-align: right;\">   0.33 </td><td style=\"text-align: right;\">     0.255</td><td style=\"text-align: right;\">   0.08 </td><td style=\"text-align: right;\">        0.205 </td><td style=\"text-align: right;\">          0.0895</td><td style=\"text-align: right;\">          0.0395</td><td style=\"text-align: right;\">         0.055</td><td style=\"text-align: right;\">      7</td></tr>\n",
       "<tr><td>I    </td><td style=\"text-align: right;\">   0.425</td><td style=\"text-align: right;\">     0.3  </td><td style=\"text-align: right;\">   0.095</td><td style=\"text-align: right;\">        0.3515</td><td style=\"text-align: right;\">          0.141 </td><td style=\"text-align: right;\">          0.0775</td><td style=\"text-align: right;\">         0.12 </td><td style=\"text-align: right;\">      8</td></tr>\n",
       "<tr><td>F    </td><td style=\"text-align: right;\">   0.53 </td><td style=\"text-align: right;\">     0.415</td><td style=\"text-align: right;\">   0.15 </td><td style=\"text-align: right;\">        0.7775</td><td style=\"text-align: right;\">          0.237 </td><td style=\"text-align: right;\">          0.1415</td><td style=\"text-align: right;\">         0.33 </td><td style=\"text-align: right;\">     20</td></tr>\n",
       "<tr><td>F    </td><td style=\"text-align: right;\">   0.545</td><td style=\"text-align: right;\">     0.425</td><td style=\"text-align: right;\">   0.125</td><td style=\"text-align: right;\">        0.768 </td><td style=\"text-align: right;\">          0.294 </td><td style=\"text-align: right;\">          0.1495</td><td style=\"text-align: right;\">         0.26 </td><td style=\"text-align: right;\">     16</td></tr>\n",
       "<tr><td>M    </td><td style=\"text-align: right;\">   0.475</td><td style=\"text-align: right;\">     0.37 </td><td style=\"text-align: right;\">   0.125</td><td style=\"text-align: right;\">        0.5095</td><td style=\"text-align: right;\">          0.2165</td><td style=\"text-align: right;\">          0.1125</td><td style=\"text-align: right;\">         0.165</td><td style=\"text-align: right;\">      9</td></tr>\n",
       "<tr><td>F    </td><td style=\"text-align: right;\">   0.55 </td><td style=\"text-align: right;\">     0.44 </td><td style=\"text-align: right;\">   0.15 </td><td style=\"text-align: right;\">        0.8945</td><td style=\"text-align: right;\">          0.3145</td><td style=\"text-align: right;\">          0.151 </td><td style=\"text-align: right;\">         0.32 </td><td style=\"text-align: right;\">     19</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:4177\n",
      "Cols:9\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>Sex  </th><th>Length             </th><th>Diameter           </th><th>Height             </th><th>Whole weight      </th><th>Shucked weight     </th><th>Viscera weight     </th><th>Shell weight       </th><th>Rings             </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>enum </td><td>real               </td><td>real               </td><td>real               </td><td>real              </td><td>real               </td><td>real               </td><td>real               </td><td>int               </td></tr>\n",
       "<tr><td>mins   </td><td>     </td><td>0.075              </td><td>0.055              </td><td>0.0                </td><td>0.002             </td><td>0.001              </td><td>0.0005             </td><td>0.0015             </td><td>1.0               </td></tr>\n",
       "<tr><td>mean   </td><td>     </td><td>0.5239920995930094 </td><td>0.40788125448886764</td><td>0.13951639932966242</td><td>0.8287421594445776</td><td>0.35936748862820206</td><td>0.18059360785252573</td><td>0.23883085946851806</td><td>9.933684462532918 </td></tr>\n",
       "<tr><td>maxs   </td><td>     </td><td>0.815              </td><td>0.65               </td><td>1.13               </td><td>2.8255            </td><td>1.488              </td><td>0.76               </td><td>1.005              </td><td>29.0              </td></tr>\n",
       "<tr><td>sigma  </td><td>     </td><td>0.12009291256479956</td><td>0.09923986613365944</td><td>0.04182705660725727</td><td>0.4903890182309976</td><td>0.2219629490332201 </td><td>0.10961425025968448</td><td>0.1392026695223861 </td><td>3.2241690320681275</td></tr>\n",
       "<tr><td>zeros  </td><td>     </td><td>0                  </td><td>0                  </td><td>2                  </td><td>0                 </td><td>0                  </td><td>0                  </td><td>0                  </td><td>0                 </td></tr>\n",
       "<tr><td>missing</td><td>0    </td><td>0                  </td><td>0                  </td><td>0                  </td><td>0                 </td><td>0                  </td><td>0                  </td><td>0                  </td><td>0                 </td></tr>\n",
       "<tr><td>0      </td><td>M    </td><td>0.455              </td><td>0.365              </td><td>0.095              </td><td>0.514             </td><td>0.2245             </td><td>0.101              </td><td>0.15               </td><td>15.0              </td></tr>\n",
       "<tr><td>1      </td><td>M    </td><td>0.35               </td><td>0.265              </td><td>0.09               </td><td>0.2255            </td><td>0.0995             </td><td>0.0485             </td><td>0.07               </td><td>7.0               </td></tr>\n",
       "<tr><td>2      </td><td>F    </td><td>0.53               </td><td>0.42               </td><td>0.135              </td><td>0.677             </td><td>0.2565             </td><td>0.1415             </td><td>0.21               </td><td>9.0               </td></tr>\n",
       "<tr><td>3      </td><td>M    </td><td>0.44               </td><td>0.365              </td><td>0.125              </td><td>0.516             </td><td>0.2155             </td><td>0.114              </td><td>0.155              </td><td>10.0              </td></tr>\n",
       "<tr><td>4      </td><td>I    </td><td>0.33               </td><td>0.255              </td><td>0.08               </td><td>0.205             </td><td>0.0895             </td><td>0.0395             </td><td>0.055              </td><td>7.0               </td></tr>\n",
       "<tr><td>5      </td><td>I    </td><td>0.425              </td><td>0.3                </td><td>0.095              </td><td>0.3515            </td><td>0.141              </td><td>0.0775             </td><td>0.12               </td><td>8.0               </td></tr>\n",
       "<tr><td>6      </td><td>F    </td><td>0.53               </td><td>0.415              </td><td>0.15               </td><td>0.7775            </td><td>0.237              </td><td>0.1415             </td><td>0.33               </td><td>20.0              </td></tr>\n",
       "<tr><td>7      </td><td>F    </td><td>0.545              </td><td>0.425              </td><td>0.125              </td><td>0.768             </td><td>0.294              </td><td>0.1495             </td><td>0.26               </td><td>16.0              </td></tr>\n",
       "<tr><td>8      </td><td>M    </td><td>0.475              </td><td>0.37               </td><td>0.125              </td><td>0.5095            </td><td>0.2165             </td><td>0.1125             </td><td>0.165              </td><td>9.0               </td></tr>\n",
       "<tr><td>9      </td><td>F    </td><td>0.55               </td><td>0.44               </td><td>0.15               </td><td>0.8945            </td><td>0.3145             </td><td>0.151              </td><td>0.32               </td><td>19.0              </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = 'Sex'\n",
    "X = df3.columns\n",
    "X.remove(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Length', 'Diameter', 'Height', 'Whole weight', 'Shucked weight', 'Viscera weight', 'Shell weight', 'Rings']\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = df3.split_frame([0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "glm_model3 = H2OGeneralizedLinearEstimator(family= \"multinomial\",nfolds = 5)\n",
    "glm_model3.train(x=X, y=y, training_frame= train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGeneralizedLinearEstimator :  Generalized Linear Modeling\n",
      "Model Key:  GLM_model_python_1539653458732_1\n",
      "\n",
      "\n",
      "ModelMetricsMultinomialGLM: glm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.309516262281894\n",
      "RMSE: 0.5563418573879679\n",
      "\n",
      "ModelMetricsMultinomialGLM: glm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.3115925232395728\n",
      "RMSE: 0.5582047323693815\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.5641593</td>\n",
       "<td>0.0131661</td>\n",
       "<td>0.5887851</td>\n",
       "<td>0.5838838</td>\n",
       "<td>0.5549738</td>\n",
       "<td>0.5423729</td>\n",
       "<td>0.5507812</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.4358406</td>\n",
       "<td>0.0131661</td>\n",
       "<td>0.4112150</td>\n",
       "<td>0.4161162</td>\n",
       "<td>0.4450262</td>\n",
       "<td>0.4576271</td>\n",
       "<td>0.4492188</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>326.4</td>\n",
       "<td>10.025967</td>\n",
       "<td>308.0</td>\n",
       "<td>315.0</td>\n",
       "<td>340.0</td>\n",
       "<td>324.0</td>\n",
       "<td>345.0</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.8601338</td>\n",
       "<td>0.0135487</td>\n",
       "<td>0.8533300</td>\n",
       "<td>0.8356780</td>\n",
       "<td>0.8472558</td>\n",
       "<td>0.8771334</td>\n",
       "<td>0.8872719</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.6397707</td>\n",
       "<td>0.0159395</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.6443515</td>\n",
       "<td>0.6066946</td>\n",
       "<td>0.6592920</td>\n",
       "<td>0.6218488</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.5644320</td>\n",
       "<td>0.0105201</td>\n",
       "<td>0.5826761</td>\n",
       "<td>0.5766275</td>\n",
       "<td>0.5660064</td>\n",
       "<td>0.5410015</td>\n",
       "<td>0.5558484</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.4355680</td>\n",
       "<td>0.0105201</td>\n",
       "<td>0.4173240</td>\n",
       "<td>0.4233725</td>\n",
       "<td>0.4339936</td>\n",
       "<td>0.4589985</td>\n",
       "<td>0.4441516</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.3116404</td>\n",
       "<td>0.0047623</td>\n",
       "<td>0.3077312</td>\n",
       "<td>0.3006228</td>\n",
       "<td>0.3134065</td>\n",
       "<td>0.3177694</td>\n",
       "<td>0.3186720</td></tr>\n",
       "<tr><td>null_deviance</td>\n",
       "<td>1643.4924</td>\n",
       "<td>32.63097</td>\n",
       "<td>1640.9673</td>\n",
       "<td>1666.8479</td>\n",
       "<td>1672.3676</td>\n",
       "<td>1555.2881</td>\n",
       "<td>1681.9913</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.5368651</td>\n",
       "<td>0.0055822</td>\n",
       "<td>0.5375294</td>\n",
       "<td>0.5390134</td>\n",
       "<td>0.5495787</td>\n",
       "<td>0.5256101</td>\n",
       "<td>0.5325937</td></tr>\n",
       "<tr><td>residual_deviance</td>\n",
       "<td>1288.5964</td>\n",
       "<td>28.934113</td>\n",
       "<td>1278.2883</td>\n",
       "<td>1265.2166</td>\n",
       "<td>1294.6068</td>\n",
       "<td>1242.0209</td>\n",
       "<td>1362.8497</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.5582148</td>\n",
       "<td>0.0042782</td>\n",
       "<td>0.5547352</td>\n",
       "<td>0.5482908</td>\n",
       "<td>0.5598272</td>\n",
       "<td>0.5637104</td>\n",
       "<td>0.5645105</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean      sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  --------  ----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.564159  0.0131661   0.588785      0.583884      0.554974      0.542373      0.550781\n",
       "err                      0.435841  0.0131661   0.411215      0.416116      0.445026      0.457627      0.449219\n",
       "err_count                326.4     10.026      308           315           340           324           345\n",
       "logloss                  0.860134  0.0135487   0.85333       0.835678      0.847256      0.877133      0.887272\n",
       "max_per_class_error      0.639771  0.0159395   0.666667      0.644351      0.606695      0.659292      0.621849\n",
       "mean_per_class_accuracy  0.564432  0.0105201   0.582676      0.576627      0.566006      0.541002      0.555848\n",
       "mean_per_class_error     0.435568  0.0105201   0.417324      0.423372      0.433994      0.458998      0.444152\n",
       "mse                      0.31164   0.00476231  0.307731      0.300623      0.313406      0.317769      0.318672\n",
       "null_deviance            1643.49   32.631      1640.97       1666.85       1672.37       1555.29       1681.99\n",
       "r2                       0.536865  0.00558221  0.537529      0.539013      0.549579      0.52561       0.532594\n",
       "residual_deviance        1288.6    28.9341     1278.29       1265.22       1294.61       1242.02       1362.85\n",
       "rmse                     0.558215  0.00427819  0.554735      0.548291      0.559827      0.56371       0.56451"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>negative_log_likelihood</b></td>\n",
       "<td><b>objective</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:31:57</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>0</td>\n",
       "<td>4106.6891901</td>\n",
       "<td>1.0962865</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:31:57</td>\n",
       "<td> 0.104 sec</td>\n",
       "<td>1</td>\n",
       "<td>3270.1218366</td>\n",
       "<td>0.8751396</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:31:57</td>\n",
       "<td> 0.214 sec</td>\n",
       "<td>2</td>\n",
       "<td>3206.7421621</td>\n",
       "<td>0.8589842</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:31:57</td>\n",
       "<td> 0.309 sec</td>\n",
       "<td>3</td>\n",
       "<td>3199.9491016</td>\n",
       "<td>0.8574083</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:31:57</td>\n",
       "<td> 0.413 sec</td>\n",
       "<td>4</td>\n",
       "<td>3199.8052714</td>\n",
       "<td>0.8573864</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    iterations    negative_log_likelihood    objective\n",
       "--  -------------------  ----------  ------------  -------------------------  -----------\n",
       "    2018-10-15 21:31:57  0.000 sec   0             4106.69                    1.09629\n",
       "    2018-10-15 21:31:57  0.104 sec   1             3270.12                    0.87514\n",
       "    2018-10-15 21:31:57  0.214 sec   2             3206.74                    0.858984\n",
       "    2018-10-15 21:31:57  0.309 sec   3             3199.95                    0.857408\n",
       "    2018-10-15 21:31:57  0.413 sec   4             3199.81                    0.857386"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2OMultinomialModel.plot of >"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_model3.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>predict  </th><th style=\"text-align: right;\">        F</th><th style=\"text-align: right;\">          I</th><th style=\"text-align: right;\">       M</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.421853 </td><td style=\"text-align: right;\">0.0803587  </td><td style=\"text-align: right;\">0.497788</td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.377292 </td><td style=\"text-align: right;\">0.220177   </td><td style=\"text-align: right;\">0.402531</td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.446195 </td><td style=\"text-align: right;\">0.000386688</td><td style=\"text-align: right;\">0.553419</td></tr>\n",
       "<tr><td>F        </td><td style=\"text-align: right;\">0.595729 </td><td style=\"text-align: right;\">0.0014399  </td><td style=\"text-align: right;\">0.402831</td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.426658 </td><td style=\"text-align: right;\">0.112852   </td><td style=\"text-align: right;\">0.46049 </td></tr>\n",
       "<tr><td>I        </td><td style=\"text-align: right;\">0.0854066</td><td style=\"text-align: right;\">0.760416   </td><td style=\"text-align: right;\">0.154177</td></tr>\n",
       "<tr><td>I        </td><td style=\"text-align: right;\">0.195995 </td><td style=\"text-align: right;\">0.577871   </td><td style=\"text-align: right;\">0.226133</td></tr>\n",
       "<tr><td>I        </td><td style=\"text-align: right;\">0.137022 </td><td style=\"text-align: right;\">0.649954   </td><td style=\"text-align: right;\">0.213024</td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.364545 </td><td style=\"text-align: right;\">0.261411   </td><td style=\"text-align: right;\">0.374045</td></tr>\n",
       "<tr><td>F        </td><td style=\"text-align: right;\">0.535491 </td><td style=\"text-align: right;\">0.0196515  </td><td style=\"text-align: right;\">0.444858</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = glm_model3.predict(test)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomialGLM: glm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.31352594908343173\n",
      "RMSE: 0.5599338792066718\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref = glm_model3.model_performance(test)\n",
    "pref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For glm_model3 the mse is 0.309516262281894 on training data and 0.31352594908343173 on testing data. The model is a good fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_model3 = H2OGradientBoostingEstimator(distribution= \"multinomial\",nfolds = 5)\n",
    "gbm_model3.train(x=X, y=y, training_frame= train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_model_python_1539653458732_2\n",
      "\n",
      "\n",
      "ModelMetricsMultinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.23614872806015297\n",
      "RMSE: 0.4859513638834168\n",
      "LogLoss: 0.6688575285845426\n",
      "Mean Per-Class Error: 0.24886821721514865\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>F</b></td>\n",
       "<td><b>I</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>714.0</td>\n",
       "<td>106.0</td>\n",
       "<td>347.0</td>\n",
       "<td>0.3881748</td>\n",
       "<td>453 / 1,167</td></tr>\n",
       "<tr><td>47.0</td>\n",
       "<td>1048.0</td>\n",
       "<td>117.0</td>\n",
       "<td>0.1353135</td>\n",
       "<td>164 / 1,212</td></tr>\n",
       "<tr><td>139.0</td>\n",
       "<td>166.0</td>\n",
       "<td>1062.0</td>\n",
       "<td>0.2231163</td>\n",
       "<td>305 / 1,367</td></tr>\n",
       "<tr><td>900.0</td>\n",
       "<td>1320.0</td>\n",
       "<td>1526.0</td>\n",
       "<td>0.2461292</td>\n",
       "<td>922 / 3,746</td></tr></table></div>"
      ],
      "text/plain": [
       "F    I     M     Error     Rate\n",
       "---  ----  ----  --------  -----------\n",
       "714  106   347   0.388175  453 / 1,167\n",
       "47   1048  117   0.135314  164 / 1,212\n",
       "139  166   1062  0.223116  305 / 1,367\n",
       "900  1320  1526  0.246129  922 / 3,746"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.7538708</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9482114</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.753871\n",
       "2    0.948211\n",
       "3    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.3132555820182874\n",
      "RMSE: 0.5596923994644625\n",
      "LogLoss: 0.862548455755394\n",
      "Mean Per-Class Error: 0.45337843665836336\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>F</b></td>\n",
       "<td><b>I</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>412.0</td>\n",
       "<td>156.0</td>\n",
       "<td>599.0</td>\n",
       "<td>0.6469580</td>\n",
       "<td>755 / 1,167</td></tr>\n",
       "<tr><td>89.0</td>\n",
       "<td>939.0</td>\n",
       "<td>184.0</td>\n",
       "<td>0.2252475</td>\n",
       "<td>273 / 1,212</td></tr>\n",
       "<tr><td>434.0</td>\n",
       "<td>233.0</td>\n",
       "<td>700.0</td>\n",
       "<td>0.4879298</td>\n",
       "<td>667 / 1,367</td></tr>\n",
       "<tr><td>935.0</td>\n",
       "<td>1328.0</td>\n",
       "<td>1483.0</td>\n",
       "<td>0.4524826</td>\n",
       "<td>1,695 / 3,746</td></tr></table></div>"
      ],
      "text/plain": [
       "F    I     M     Error     Rate\n",
       "---  ----  ----  --------  -------------\n",
       "412  156   599   0.646958  755 / 1,167\n",
       "89   939   184   0.225248  273 / 1,212\n",
       "434  233   700   0.48793   667 / 1,367\n",
       "935  1328  1483  0.452483  1,695 / 3,746"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.5475174</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.8918847</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.547517\n",
       "2    0.891885\n",
       "3    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.5473762</td>\n",
       "<td>0.0066462</td>\n",
       "<td>0.5325615</td>\n",
       "<td>0.5583892</td>\n",
       "<td>0.5519481</td>\n",
       "<td>0.5406758</td>\n",
       "<td>0.5533063</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.4526238</td>\n",
       "<td>0.0066462</td>\n",
       "<td>0.4674385</td>\n",
       "<td>0.4416107</td>\n",
       "<td>0.4480520</td>\n",
       "<td>0.4593241</td>\n",
       "<td>0.4466937</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>339.0</td>\n",
       "<td>11.135529</td>\n",
       "<td>323.0</td>\n",
       "<td>329.0</td>\n",
       "<td>345.0</td>\n",
       "<td>367.0</td>\n",
       "<td>331.0</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.8623691</td>\n",
       "<td>0.0078519</td>\n",
       "<td>0.8568824</td>\n",
       "<td>0.8729094</td>\n",
       "<td>0.8752232</td>\n",
       "<td>0.8620682</td>\n",
       "<td>0.8447623</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.6466937</td>\n",
       "<td>0.0135459</td>\n",
       "<td>0.6363636</td>\n",
       "<td>0.6177778</td>\n",
       "<td>0.6638298</td>\n",
       "<td>0.6444445</td>\n",
       "<td>0.6710526</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.5468136</td>\n",
       "<td>0.0086540</td>\n",
       "<td>0.5274717</td>\n",
       "<td>0.5654629</td>\n",
       "<td>0.5430758</td>\n",
       "<td>0.5477610</td>\n",
       "<td>0.5502967</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.4531864</td>\n",
       "<td>0.0086540</td>\n",
       "<td>0.4725284</td>\n",
       "<td>0.4345371</td>\n",
       "<td>0.4569242</td>\n",
       "<td>0.4522390</td>\n",
       "<td>0.4497032</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.3132050</td>\n",
       "<td>0.0024354</td>\n",
       "<td>0.3122678</td>\n",
       "<td>0.3163342</td>\n",
       "<td>0.3165341</td>\n",
       "<td>0.3137847</td>\n",
       "<td>0.3071041</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.5339789</td>\n",
       "<td>0.0091190</td>\n",
       "<td>0.5246262</td>\n",
       "<td>0.5431416</td>\n",
       "<td>0.51319</td>\n",
       "<td>0.5464559</td>\n",
       "<td>0.5424811</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.5596387</td>\n",
       "<td>0.0021806</td>\n",
       "<td>0.5588093</td>\n",
       "<td>0.562436</td>\n",
       "<td>0.5626136</td>\n",
       "<td>0.5601649</td>\n",
       "<td>0.5541697</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean      sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  --------  ----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.547376  0.00664625  0.532562      0.558389      0.551948      0.540676      0.553306\n",
       "err                      0.452624  0.00664625  0.467438      0.441611      0.448052      0.459324      0.446694\n",
       "err_count                339       11.1355     323           329           345           367           331\n",
       "logloss                  0.862369  0.00785188  0.856882      0.872909      0.875223      0.862068      0.844762\n",
       "max_per_class_error      0.646694  0.0135459   0.636364      0.617778      0.66383       0.644444      0.671053\n",
       "mean_per_class_accuracy  0.546814  0.00865396  0.527472      0.565463      0.543076      0.547761      0.550297\n",
       "mean_per_class_error     0.453186  0.00865396  0.472528      0.434537      0.456924      0.452239      0.449703\n",
       "mse                      0.313205  0.00243537  0.312268      0.316334      0.316534      0.313785      0.307104\n",
       "r2                       0.533979  0.00911903  0.524626      0.543142      0.51319       0.546456      0.542481\n",
       "rmse                     0.559639  0.00218058  0.558809      0.562436      0.562614      0.560165      0.55417"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:32:14</td>\n",
       "<td> 4.983 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.6666667</td>\n",
       "<td>1.0986123</td>\n",
       "<td>0.6748532</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:32:14</td>\n",
       "<td> 5.039 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6493546</td>\n",
       "<td>1.0488117</td>\n",
       "<td>0.3996263</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:32:14</td>\n",
       "<td> 5.069 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.6343377</td>\n",
       "<td>1.0085204</td>\n",
       "<td>0.3940203</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:32:14</td>\n",
       "<td> 5.107 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.6209536</td>\n",
       "<td>0.9744216</td>\n",
       "<td>0.3913508</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:32:14</td>\n",
       "<td> 5.132 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.6093727</td>\n",
       "<td>0.9460551</td>\n",
       "<td>0.3865456</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:32:15</td>\n",
       "<td> 5.718 sec</td>\n",
       "<td>46.0</td>\n",
       "<td>0.4898879</td>\n",
       "<td>0.6787827</td>\n",
       "<td>0.2504004</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:32:15</td>\n",
       "<td> 5.727 sec</td>\n",
       "<td>47.0</td>\n",
       "<td>0.4887368</td>\n",
       "<td>0.6764341</td>\n",
       "<td>0.2493326</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:32:15</td>\n",
       "<td> 5.738 sec</td>\n",
       "<td>48.0</td>\n",
       "<td>0.4877799</td>\n",
       "<td>0.6734110</td>\n",
       "<td>0.2495996</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:32:15</td>\n",
       "<td> 5.748 sec</td>\n",
       "<td>49.0</td>\n",
       "<td>0.4866138</td>\n",
       "<td>0.6706693</td>\n",
       "<td>0.2463962</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:32:15</td>\n",
       "<td> 5.766 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.4859514</td>\n",
       "<td>0.6688575</td>\n",
       "<td>0.2461292</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    number_of_trees    training_rmse        training_logloss    training_classification_error\n",
       "---  -------------------  ----------  -----------------  -------------------  ------------------  -------------------------------\n",
       "     2018-10-15 21:32:14  4.983 sec   0.0                0.6666666666666657   1.0986122886681078  0.6748531767218366\n",
       "     2018-10-15 21:32:14  5.039 sec   1.0                0.6493545580188281   1.0488116668746812  0.3996262680192205\n",
       "     2018-10-15 21:32:14  5.069 sec   2.0                0.6343376703572252   1.008520379758735   0.39402028830752805\n",
       "     2018-10-15 21:32:14  5.107 sec   3.0                0.6209535661740008   0.9744215532897605  0.391350774159103\n",
       "     2018-10-15 21:32:14  5.132 sec   4.0                0.6093726818551298   0.9460550927369957  0.3865456486919381\n",
       "---  ---                  ---         ---                ---                  ---                 ---\n",
       "     2018-10-15 21:32:15  5.718 sec   46.0               0.4898879231725363   0.6787826798698512  0.25040042712226374\n",
       "     2018-10-15 21:32:15  5.727 sec   47.0               0.48873683078859725  0.6764340968164915  0.24933262146289376\n",
       "     2018-10-15 21:32:15  5.738 sec   48.0               0.48777986362645476  0.6734110151046523  0.24959957287773626\n",
       "     2018-10-15 21:32:15  5.748 sec   49.0               0.48661376164343806  0.6706693273359962  0.24639615589962627\n",
       "     2018-10-15 21:32:15  5.766 sec   50.0               0.4859513638834168   0.6688575285845426  0.24612920448478376"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>Viscera weight</td>\n",
       "<td>2064.1726074</td>\n",
       "<td>1.0</td>\n",
       "<td>0.4115473</td></tr>\n",
       "<tr><td>Whole weight</td>\n",
       "<td>806.6620483</td>\n",
       "<td>0.3907920</td>\n",
       "<td>0.1608294</td></tr>\n",
       "<tr><td>Rings</td>\n",
       "<td>608.5076294</td>\n",
       "<td>0.2947949</td>\n",
       "<td>0.1213221</td></tr>\n",
       "<tr><td>Shell weight</td>\n",
       "<td>368.6423340</td>\n",
       "<td>0.1785908</td>\n",
       "<td>0.0734986</td></tr>\n",
       "<tr><td>Length</td>\n",
       "<td>361.1393738</td>\n",
       "<td>0.1749560</td>\n",
       "<td>0.0720027</td></tr>\n",
       "<tr><td>Shucked weight</td>\n",
       "<td>342.5776672</td>\n",
       "<td>0.1659637</td>\n",
       "<td>0.0683019</td></tr>\n",
       "<tr><td>Height</td>\n",
       "<td>251.4588776</td>\n",
       "<td>0.1218207</td>\n",
       "<td>0.0501350</td></tr>\n",
       "<tr><td>Diameter</td>\n",
       "<td>212.4783783</td>\n",
       "<td>0.1029363</td>\n",
       "<td>0.0423632</td></tr></table></div>"
      ],
      "text/plain": [
       "variable        relative_importance    scaled_importance    percentage\n",
       "--------------  ---------------------  -------------------  ------------\n",
       "Viscera weight  2064.17                1                    0.411547\n",
       "Whole weight    806.662                0.390792             0.160829\n",
       "Rings           608.508                0.294795             0.121322\n",
       "Shell weight    368.642                0.178591             0.0734986\n",
       "Length          361.139                0.174956             0.0720027\n",
       "Shucked weight  342.578                0.165964             0.0683019\n",
       "Height          251.459                0.121821             0.050135\n",
       "Diameter        212.478                0.102936             0.0423632"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2OMultinomialModel.plot of >"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model3.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>predict  </th><th style=\"text-align: right;\">        F</th><th style=\"text-align: right;\">        I</th><th style=\"text-align: right;\">        M</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.371225 </td><td style=\"text-align: right;\">0.142345 </td><td style=\"text-align: right;\">0.48643  </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.324187 </td><td style=\"text-align: right;\">0.30939  </td><td style=\"text-align: right;\">0.366423 </td></tr>\n",
       "<tr><td>F        </td><td style=\"text-align: right;\">0.663245 </td><td style=\"text-align: right;\">0.0437376</td><td style=\"text-align: right;\">0.293018 </td></tr>\n",
       "<tr><td>F        </td><td style=\"text-align: right;\">0.673597 </td><td style=\"text-align: right;\">0.0248244</td><td style=\"text-align: right;\">0.301578 </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.366032 </td><td style=\"text-align: right;\">0.206476 </td><td style=\"text-align: right;\">0.427492 </td></tr>\n",
       "<tr><td>I        </td><td style=\"text-align: right;\">0.0418359</td><td style=\"text-align: right;\">0.86714  </td><td style=\"text-align: right;\">0.0910245</td></tr>\n",
       "<tr><td>I        </td><td style=\"text-align: right;\">0.124855 </td><td style=\"text-align: right;\">0.767445 </td><td style=\"text-align: right;\">0.107701 </td></tr>\n",
       "<tr><td>I        </td><td style=\"text-align: right;\">0.105622 </td><td style=\"text-align: right;\">0.727361 </td><td style=\"text-align: right;\">0.167017 </td></tr>\n",
       "<tr><td>I        </td><td style=\"text-align: right;\">0.168056 </td><td style=\"text-align: right;\">0.512412 </td><td style=\"text-align: right;\">0.319532 </td></tr>\n",
       "<tr><td>F        </td><td style=\"text-align: right;\">0.677168 </td><td style=\"text-align: right;\">0.0401887</td><td style=\"text-align: right;\">0.282643 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = gbm_model3.predict(test)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.30384745651547\n",
      "RMSE: 0.5512235993818388\n",
      "LogLoss: 0.834603465204004\n",
      "Mean Per-Class Error: 0.4359213250517598\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>F</b></td>\n",
       "<td><b>I</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>51.0</td>\n",
       "<td>16.0</td>\n",
       "<td>73.0</td>\n",
       "<td>0.6357143</td>\n",
       "<td>89 / 140</td></tr>\n",
       "<tr><td>8.0</td>\n",
       "<td>104.0</td>\n",
       "<td>18.0</td>\n",
       "<td>0.2</td>\n",
       "<td>26 / 130</td></tr>\n",
       "<tr><td>48.0</td>\n",
       "<td>28.0</td>\n",
       "<td>85.0</td>\n",
       "<td>0.4720497</td>\n",
       "<td>76 / 161</td></tr>\n",
       "<tr><td>107.0</td>\n",
       "<td>148.0</td>\n",
       "<td>176.0</td>\n",
       "<td>0.4431555</td>\n",
       "<td>191 / 431</td></tr></table></div>"
      ],
      "text/plain": [
       "F    I    M    Error     Rate\n",
       "---  ---  ---  --------  ---------\n",
       "51   16   73   0.635714  89 / 140\n",
       "8    104  18   0.2       26 / 130\n",
       "48   28   85   0.47205   76 / 161\n",
       "107  148  176  0.443155  191 / 431"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.5568445</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9025522</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.556845\n",
       "2    0.902552\n",
       "3    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref = gbm_model3.model_performance(test)\n",
    "pref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For GBM_model3 the mse is 0.23614872806015297 on training data and 0.30384745651547 on testing data. The model is a little bit overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "dp_model3 = H2ODeepLearningEstimator(\n",
    "    model_id=\"multdl\",\n",
    "    hidden=[50,50],           \n",
    "    epochs=50,                 \n",
    "    ignore_const_cols=False, \n",
    "    sparse=True,              \n",
    "    variable_importances=True,\n",
    "    nfolds = 5\n",
    ")\n",
    "dp_model3.train(x=X,y = y, training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ODeepLearningEstimator :  Deep Learning\n",
      "Model Key:  multdl\n",
      "\n",
      "\n",
      "ModelMetricsMultinomial: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.3434612685148062\n",
      "RMSE: 0.5860556872130891\n",
      "LogLoss: 0.9344598312434127\n",
      "Mean Per-Class Error: 0.49551928905804044\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>F</b></td>\n",
       "<td><b>I</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>917.0</td>\n",
       "<td>39.0</td>\n",
       "<td>211.0</td>\n",
       "<td>0.2142245</td>\n",
       "<td>250 / 1,167</td></tr>\n",
       "<tr><td>482.0</td>\n",
       "<td>639.0</td>\n",
       "<td>91.0</td>\n",
       "<td>0.4727723</td>\n",
       "<td>573 / 1,212</td></tr>\n",
       "<tr><td>971.0</td>\n",
       "<td>122.0</td>\n",
       "<td>274.0</td>\n",
       "<td>0.7995611</td>\n",
       "<td>1,093 / 1,367</td></tr>\n",
       "<tr><td>2370.0</td>\n",
       "<td>800.0</td>\n",
       "<td>576.0</td>\n",
       "<td>0.5114789</td>\n",
       "<td>1,916 / 3,746</td></tr></table></div>"
      ],
      "text/plain": [
       "F     I    M    Error     Rate\n",
       "----  ---  ---  --------  -------------\n",
       "917   39   211  0.214225  250 / 1,167\n",
       "482   639  91   0.472772  573 / 1,212\n",
       "971   122  274  0.799561  1,093 / 1,367\n",
       "2370  800  576  0.511479  1,916 / 3,746"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.4885211</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.8579819</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.488521\n",
       "2    0.857982\n",
       "3    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: deeplearning\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.34232626395160903\n",
      "RMSE: 0.5850865439843999\n",
      "LogLoss: 1.0620671136351103\n",
      "Mean Per-Class Error: 0.49559051517294733\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>F</b></td>\n",
       "<td><b>I</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>733.0</td>\n",
       "<td>126.0</td>\n",
       "<td>308.0</td>\n",
       "<td>0.3718937</td>\n",
       "<td>434 / 1,167</td></tr>\n",
       "<tr><td>345.0</td>\n",
       "<td>766.0</td>\n",
       "<td>101.0</td>\n",
       "<td>0.3679868</td>\n",
       "<td>446 / 1,212</td></tr>\n",
       "<tr><td>817.0</td>\n",
       "<td>204.0</td>\n",
       "<td>346.0</td>\n",
       "<td>0.7468910</td>\n",
       "<td>1,021 / 1,367</td></tr>\n",
       "<tr><td>1895.0</td>\n",
       "<td>1096.0</td>\n",
       "<td>755.0</td>\n",
       "<td>0.5074746</td>\n",
       "<td>1,901 / 3,746</td></tr></table></div>"
      ],
      "text/plain": [
       "F     I     M    Error     Rate\n",
       "----  ----  ---  --------  -------------\n",
       "733   126   308  0.371894  434 / 1,167\n",
       "345   766   101  0.367987  446 / 1,212\n",
       "817   204   346  0.746891  1,021 / 1,367\n",
       "1895  1096  755  0.507475  1,901 / 3,746"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.4925254</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.851575</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.492525\n",
       "2    0.851575\n",
       "3    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.4928896</td>\n",
       "<td>0.0334690</td>\n",
       "<td>0.5381526</td>\n",
       "<td>0.5465587</td>\n",
       "<td>0.4204244</td>\n",
       "<td>0.4979757</td>\n",
       "<td>0.4613368</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.5071104</td>\n",
       "<td>0.0334690</td>\n",
       "<td>0.4618474</td>\n",
       "<td>0.4534413</td>\n",
       "<td>0.5795756</td>\n",
       "<td>0.5020243</td>\n",
       "<td>0.5386631</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>380.2</td>\n",
       "<td>27.26683</td>\n",
       "<td>345.0</td>\n",
       "<td>336.0</td>\n",
       "<td>437.0</td>\n",
       "<td>372.0</td>\n",
       "<td>411.0</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>1.0609065</td>\n",
       "<td>0.0986136</td>\n",
       "<td>0.9248390</td>\n",
       "<td>0.8807687</td>\n",
       "<td>1.2260971</td>\n",
       "<td>1.0748032</td>\n",
       "<td>1.1980245</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.87092</td>\n",
       "<td>0.0803004</td>\n",
       "<td>0.8306451</td>\n",
       "<td>0.6742082</td>\n",
       "<td>0.9795222</td>\n",
       "<td>0.9805447</td>\n",
       "<td>0.8896797</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.5072957</td>\n",
       "<td>0.0230463</td>\n",
       "<td>0.5394249</td>\n",
       "<td>0.5420667</td>\n",
       "<td>0.4603877</td>\n",
       "<td>0.5155999</td>\n",
       "<td>0.4789993</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.4927043</td>\n",
       "<td>0.0230463</td>\n",
       "<td>0.4605751</td>\n",
       "<td>0.4579333</td>\n",
       "<td>0.5396123</td>\n",
       "<td>0.4844001</td>\n",
       "<td>0.5210007</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.3422061</td>\n",
       "<td>0.0160421</td>\n",
       "<td>0.3073812</td>\n",
       "<td>0.3320547</td>\n",
       "<td>0.3762621</td>\n",
       "<td>0.3432941</td>\n",
       "<td>0.3520384</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.4912423</td>\n",
       "<td>0.0239890</td>\n",
       "<td>0.5486918</td>\n",
       "<td>0.4999591</td>\n",
       "<td>0.4470255</td>\n",
       "<td>0.4707212</td>\n",
       "<td>0.4898138</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.584661</td>\n",
       "<td>0.0137410</td>\n",
       "<td>0.5544198</td>\n",
       "<td>0.5762419</td>\n",
       "<td>0.613402</td>\n",
       "<td>0.5859131</td>\n",
       "<td>0.5933283</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean      sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  --------  ---------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.49289   0.033469   0.538153      0.546559      0.420424      0.497976      0.461337\n",
       "err                      0.50711   0.033469   0.461847      0.453441      0.579576      0.502024      0.538663\n",
       "err_count                380.2     27.2668    345           336           437           372           411\n",
       "logloss                  1.06091   0.0986136  0.924839      0.880769      1.2261        1.0748        1.19802\n",
       "max_per_class_error      0.87092   0.0803004  0.830645      0.674208      0.979522      0.980545      0.88968\n",
       "mean_per_class_accuracy  0.507296  0.0230463  0.539425      0.542067      0.460388      0.5156        0.478999\n",
       "mean_per_class_error     0.492704  0.0230463  0.460575      0.457933      0.539612      0.4844        0.521001\n",
       "mse                      0.342206  0.0160421  0.307381      0.332055      0.376262      0.343294      0.352038\n",
       "r2                       0.491242  0.023989   0.548692      0.499959      0.447025      0.470721      0.489814\n",
       "rmse                     0.584661  0.013741   0.55442       0.576242      0.613402      0.585913      0.593328"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_r2</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:32:33</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:32:33</td>\n",
       "<td> 7.585 sec</td>\n",
       "<td>80891 obs/sec</td>\n",
       "<td>5.1825948</td>\n",
       "<td>1</td>\n",
       "<td>19414.0</td>\n",
       "<td>0.5820207</td>\n",
       "<td>0.9276845</td>\n",
       "<td>0.4971113</td>\n",
       "<td>0.4954618</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:32:35</td>\n",
       "<td> 9.271 sec</td>\n",
       "<td>112412 obs/sec</td>\n",
       "<td>57.1967432</td>\n",
       "<td>11</td>\n",
       "<td>214259.0</td>\n",
       "<td>0.5860557</td>\n",
       "<td>0.9344598</td>\n",
       "<td>0.4901142</td>\n",
       "<td>0.5114789</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  -------------------------------\n",
       "    2018-10-15 21:32:33  0.000 sec                     0         0             0          nan              nan                 nan            nan\n",
       "    2018-10-15 21:32:33  7.585 sec   80891 obs/sec     5.18259   1             19414      0.582021         0.927685            0.497111       0.495462\n",
       "    2018-10-15 21:32:35  9.271 sec   112412 obs/sec    57.1967   11            214259     0.586056         0.93446             0.490114       0.511479"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>Shucked weight</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1611106</td></tr>\n",
       "<tr><td>Whole weight</td>\n",
       "<td>0.9140861</td>\n",
       "<td>0.9140861</td>\n",
       "<td>0.1472690</td></tr>\n",
       "<tr><td>Viscera weight</td>\n",
       "<td>0.7611294</td>\n",
       "<td>0.7611294</td>\n",
       "<td>0.1226260</td></tr>\n",
       "<tr><td>Rings</td>\n",
       "<td>0.7565413</td>\n",
       "<td>0.7565413</td>\n",
       "<td>0.1218868</td></tr>\n",
       "<tr><td>Shell weight</td>\n",
       "<td>0.7537981</td>\n",
       "<td>0.7537981</td>\n",
       "<td>0.1214449</td></tr>\n",
       "<tr><td>Length</td>\n",
       "<td>0.7290813</td>\n",
       "<td>0.7290813</td>\n",
       "<td>0.1174627</td></tr>\n",
       "<tr><td>Diameter</td>\n",
       "<td>0.6851111</td>\n",
       "<td>0.6851111</td>\n",
       "<td>0.1103787</td></tr>\n",
       "<tr><td>Height</td>\n",
       "<td>0.6071684</td>\n",
       "<td>0.6071684</td>\n",
       "<td>0.0978213</td></tr></table></div>"
      ],
      "text/plain": [
       "variable        relative_importance    scaled_importance    percentage\n",
       "--------------  ---------------------  -------------------  ------------\n",
       "Shucked weight  1                      1                    0.161111\n",
       "Whole weight    0.914086               0.914086             0.147269\n",
       "Viscera weight  0.761129               0.761129             0.122626\n",
       "Rings           0.756541               0.756541             0.121887\n",
       "Shell weight    0.753798               0.753798             0.121445\n",
       "Length          0.729081               0.729081             0.117463\n",
       "Diameter        0.685111               0.685111             0.110379\n",
       "Height          0.607168               0.607168             0.0978213"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2OMultinomialModel.plot of >"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_model3.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning prediction progress: |███████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>predict  </th><th style=\"text-align: right;\">       F</th><th style=\"text-align: right;\">        I</th><th style=\"text-align: right;\">       M</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>F        </td><td style=\"text-align: right;\">0.519971</td><td style=\"text-align: right;\">0.0803151</td><td style=\"text-align: right;\">0.399714</td></tr>\n",
       "<tr><td>F        </td><td style=\"text-align: right;\">0.59099 </td><td style=\"text-align: right;\">0.0578152</td><td style=\"text-align: right;\">0.351195</td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.472416</td><td style=\"text-align: right;\">0.0454598</td><td style=\"text-align: right;\">0.482124</td></tr>\n",
       "<tr><td>F        </td><td style=\"text-align: right;\">0.663448</td><td style=\"text-align: right;\">0.0194301</td><td style=\"text-align: right;\">0.317122</td></tr>\n",
       "<tr><td>F        </td><td style=\"text-align: right;\">0.610993</td><td style=\"text-align: right;\">0.0526224</td><td style=\"text-align: right;\">0.336385</td></tr>\n",
       "<tr><td>I        </td><td style=\"text-align: right;\">0.309963</td><td style=\"text-align: right;\">0.452141 </td><td style=\"text-align: right;\">0.237897</td></tr>\n",
       "<tr><td>F        </td><td style=\"text-align: right;\">0.49082 </td><td style=\"text-align: right;\">0.200739 </td><td style=\"text-align: right;\">0.308441</td></tr>\n",
       "<tr><td>I        </td><td style=\"text-align: right;\">0.309923</td><td style=\"text-align: right;\">0.42647  </td><td style=\"text-align: right;\">0.263607</td></tr>\n",
       "<tr><td>F        </td><td style=\"text-align: right;\">0.444897</td><td style=\"text-align: right;\">0.162296 </td><td style=\"text-align: right;\">0.392807</td></tr>\n",
       "<tr><td>F        </td><td style=\"text-align: right;\">0.605719</td><td style=\"text-align: right;\">0.0516163</td><td style=\"text-align: right;\">0.342665</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = dp_model3.predict(test)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: deeplearning\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.3436010647651126\n",
      "RMSE: 0.5861749438223307\n",
      "LogLoss: 0.9221956579161925\n",
      "Mean Per-Class Error: 0.4903169294473642\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>F</b></td>\n",
       "<td><b>I</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>108.0</td>\n",
       "<td>10.0</td>\n",
       "<td>22.0</td>\n",
       "<td>0.2285714</td>\n",
       "<td>32 / 140</td></tr>\n",
       "<tr><td>53.0</td>\n",
       "<td>67.0</td>\n",
       "<td>10.0</td>\n",
       "<td>0.4846154</td>\n",
       "<td>63 / 130</td></tr>\n",
       "<tr><td>108.0</td>\n",
       "<td>14.0</td>\n",
       "<td>39.0</td>\n",
       "<td>0.7577640</td>\n",
       "<td>122 / 161</td></tr>\n",
       "<tr><td>269.0</td>\n",
       "<td>91.0</td>\n",
       "<td>71.0</td>\n",
       "<td>0.5034803</td>\n",
       "<td>217 / 431</td></tr></table></div>"
      ],
      "text/plain": [
       "F    I    M    Error     Rate\n",
       "---  ---  ---  --------  ---------\n",
       "108  10   22   0.228571  32 / 140\n",
       "53   67   10   0.484615  63 / 130\n",
       "108  14   39   0.757764  122 / 161\n",
       "269  91   71   0.50348   217 / 431"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.4965197</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.8422273</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9999999</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.49652\n",
       "2    0.842227\n",
       "3    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref = dp_model3.model_performance(test)\n",
    "pref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For deep learning model3 the mse is 0.3434612685148062 on training data and 0.3436010647651126 on testing data. The model is a good fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aml = H2OAutoML(max_runtime_secs=run_time,project_name=name3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "aml.train(x=X,y=y,training_frame = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aml_ld_df = aml.leaderboard.as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>mean_per_class_error</th>\n",
       "      <th>logloss</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StackedEnsemble_BestOfFamily_0_AutoML_20181015...</td>\n",
       "      <td>0.439096</td>\n",
       "      <td>0.848466</td>\n",
       "      <td>0.556677</td>\n",
       "      <td>0.309889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GLM_grid_0_AutoML_20181015_213242_model_0</td>\n",
       "      <td>0.441341</td>\n",
       "      <td>0.862569</td>\n",
       "      <td>0.558050</td>\n",
       "      <td>0.311420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_22</td>\n",
       "      <td>0.441818</td>\n",
       "      <td>0.909199</td>\n",
       "      <td>0.591513</td>\n",
       "      <td>0.349887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DeepLearning_grid_0_AutoML_20181015_213242_mod...</td>\n",
       "      <td>0.446192</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.551255</td>\n",
       "      <td>0.303882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_21</td>\n",
       "      <td>0.446759</td>\n",
       "      <td>0.855553</td>\n",
       "      <td>0.559897</td>\n",
       "      <td>0.313485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_35</td>\n",
       "      <td>0.446797</td>\n",
       "      <td>0.862696</td>\n",
       "      <td>0.560840</td>\n",
       "      <td>0.314541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_14</td>\n",
       "      <td>0.448043</td>\n",
       "      <td>0.985391</td>\n",
       "      <td>0.624715</td>\n",
       "      <td>0.390269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_12</td>\n",
       "      <td>0.448420</td>\n",
       "      <td>0.858938</td>\n",
       "      <td>0.564020</td>\n",
       "      <td>0.318119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_4</td>\n",
       "      <td>0.448430</td>\n",
       "      <td>0.854086</td>\n",
       "      <td>0.558031</td>\n",
       "      <td>0.311398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>StackedEnsemble_AllModels_0_AutoML_20181015_21...</td>\n",
       "      <td>0.448643</td>\n",
       "      <td>0.846669</td>\n",
       "      <td>0.556045</td>\n",
       "      <td>0.309186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_25</td>\n",
       "      <td>0.448914</td>\n",
       "      <td>0.912418</td>\n",
       "      <td>0.592731</td>\n",
       "      <td>0.351330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_17</td>\n",
       "      <td>0.450180</td>\n",
       "      <td>0.913159</td>\n",
       "      <td>0.593412</td>\n",
       "      <td>0.352138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_26</td>\n",
       "      <td>0.452313</td>\n",
       "      <td>0.916356</td>\n",
       "      <td>0.594581</td>\n",
       "      <td>0.353526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_7</td>\n",
       "      <td>0.454015</td>\n",
       "      <td>1.086515</td>\n",
       "      <td>0.662587</td>\n",
       "      <td>0.439022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_27</td>\n",
       "      <td>0.454078</td>\n",
       "      <td>0.976972</td>\n",
       "      <td>0.621021</td>\n",
       "      <td>0.385667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_15</td>\n",
       "      <td>0.454482</td>\n",
       "      <td>0.867403</td>\n",
       "      <td>0.565669</td>\n",
       "      <td>0.319981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_24</td>\n",
       "      <td>0.454695</td>\n",
       "      <td>0.891817</td>\n",
       "      <td>0.561166</td>\n",
       "      <td>0.314908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_1</td>\n",
       "      <td>0.456129</td>\n",
       "      <td>0.880989</td>\n",
       "      <td>0.565609</td>\n",
       "      <td>0.319914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_6</td>\n",
       "      <td>0.457004</td>\n",
       "      <td>0.940394</td>\n",
       "      <td>0.605503</td>\n",
       "      <td>0.366634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_33</td>\n",
       "      <td>0.457601</td>\n",
       "      <td>0.923160</td>\n",
       "      <td>0.597827</td>\n",
       "      <td>0.357397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_10</td>\n",
       "      <td>0.458722</td>\n",
       "      <td>0.993862</td>\n",
       "      <td>0.628098</td>\n",
       "      <td>0.394507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_34</td>\n",
       "      <td>0.458908</td>\n",
       "      <td>0.910971</td>\n",
       "      <td>0.591723</td>\n",
       "      <td>0.350136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_20</td>\n",
       "      <td>0.461495</td>\n",
       "      <td>0.925990</td>\n",
       "      <td>0.598989</td>\n",
       "      <td>0.358788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_2</td>\n",
       "      <td>0.462853</td>\n",
       "      <td>0.885802</td>\n",
       "      <td>0.566502</td>\n",
       "      <td>0.320924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_19</td>\n",
       "      <td>0.463084</td>\n",
       "      <td>1.087479</td>\n",
       "      <td>0.662914</td>\n",
       "      <td>0.439455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_18</td>\n",
       "      <td>0.464845</td>\n",
       "      <td>0.928524</td>\n",
       "      <td>0.599671</td>\n",
       "      <td>0.359605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_8</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.086333</td>\n",
       "      <td>0.662519</td>\n",
       "      <td>0.438932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>XRT_0_AutoML_20181015_213242</td>\n",
       "      <td>0.466988</td>\n",
       "      <td>1.176779</td>\n",
       "      <td>0.566676</td>\n",
       "      <td>0.321121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_23</td>\n",
       "      <td>0.467196</td>\n",
       "      <td>0.943196</td>\n",
       "      <td>0.606104</td>\n",
       "      <td>0.367362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_0</td>\n",
       "      <td>0.468976</td>\n",
       "      <td>0.876045</td>\n",
       "      <td>0.565570</td>\n",
       "      <td>0.319869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_3</td>\n",
       "      <td>0.470560</td>\n",
       "      <td>0.903350</td>\n",
       "      <td>0.571479</td>\n",
       "      <td>0.326588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>DeepLearning_0_AutoML_20181015_213242</td>\n",
       "      <td>0.473731</td>\n",
       "      <td>0.908639</td>\n",
       "      <td>0.569251</td>\n",
       "      <td>0.324047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_5</td>\n",
       "      <td>0.474758</td>\n",
       "      <td>0.939469</td>\n",
       "      <td>0.576609</td>\n",
       "      <td>0.332478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>DRF_0_AutoML_20181015_213242</td>\n",
       "      <td>0.475056</td>\n",
       "      <td>1.211644</td>\n",
       "      <td>0.568224</td>\n",
       "      <td>0.322878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_13</td>\n",
       "      <td>0.475432</td>\n",
       "      <td>2.161950</td>\n",
       "      <td>0.643656</td>\n",
       "      <td>0.414293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_29</td>\n",
       "      <td>0.475622</td>\n",
       "      <td>0.936402</td>\n",
       "      <td>0.601461</td>\n",
       "      <td>0.361755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_32</td>\n",
       "      <td>0.475799</td>\n",
       "      <td>0.915116</td>\n",
       "      <td>0.576040</td>\n",
       "      <td>0.331822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_30</td>\n",
       "      <td>0.475852</td>\n",
       "      <td>1.017827</td>\n",
       "      <td>0.637501</td>\n",
       "      <td>0.406408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_16</td>\n",
       "      <td>0.477078</td>\n",
       "      <td>0.948736</td>\n",
       "      <td>0.580553</td>\n",
       "      <td>0.337042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_31</td>\n",
       "      <td>0.481068</td>\n",
       "      <td>1.270723</td>\n",
       "      <td>0.611205</td>\n",
       "      <td>0.373571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>DeepLearning_grid_0_AutoML_20181015_213242_mod...</td>\n",
       "      <td>0.483185</td>\n",
       "      <td>0.950508</td>\n",
       "      <td>0.578726</td>\n",
       "      <td>0.334923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_9</td>\n",
       "      <td>0.483856</td>\n",
       "      <td>1.078997</td>\n",
       "      <td>0.595749</td>\n",
       "      <td>0.354917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>DeepLearning_grid_0_AutoML_20181015_213242_mod...</td>\n",
       "      <td>0.485761</td>\n",
       "      <td>0.971095</td>\n",
       "      <td>0.580567</td>\n",
       "      <td>0.337058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_11</td>\n",
       "      <td>0.492224</td>\n",
       "      <td>1.147914</td>\n",
       "      <td>0.606909</td>\n",
       "      <td>0.368339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>GBM_grid_0_AutoML_20181015_213242_model_28</td>\n",
       "      <td>0.502533</td>\n",
       "      <td>1.692354</td>\n",
       "      <td>0.638831</td>\n",
       "      <td>0.408105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             model_id  mean_per_class_error  \\\n",
       "0   StackedEnsemble_BestOfFamily_0_AutoML_20181015...              0.439096   \n",
       "1           GLM_grid_0_AutoML_20181015_213242_model_0              0.441341   \n",
       "2          GBM_grid_0_AutoML_20181015_213242_model_22              0.441818   \n",
       "3   DeepLearning_grid_0_AutoML_20181015_213242_mod...              0.446192   \n",
       "4          GBM_grid_0_AutoML_20181015_213242_model_21              0.446759   \n",
       "5          GBM_grid_0_AutoML_20181015_213242_model_35              0.446797   \n",
       "6          GBM_grid_0_AutoML_20181015_213242_model_14              0.448043   \n",
       "7          GBM_grid_0_AutoML_20181015_213242_model_12              0.448420   \n",
       "8           GBM_grid_0_AutoML_20181015_213242_model_4              0.448430   \n",
       "9   StackedEnsemble_AllModels_0_AutoML_20181015_21...              0.448643   \n",
       "10         GBM_grid_0_AutoML_20181015_213242_model_25              0.448914   \n",
       "11         GBM_grid_0_AutoML_20181015_213242_model_17              0.450180   \n",
       "12         GBM_grid_0_AutoML_20181015_213242_model_26              0.452313   \n",
       "13          GBM_grid_0_AutoML_20181015_213242_model_7              0.454015   \n",
       "14         GBM_grid_0_AutoML_20181015_213242_model_27              0.454078   \n",
       "15         GBM_grid_0_AutoML_20181015_213242_model_15              0.454482   \n",
       "16         GBM_grid_0_AutoML_20181015_213242_model_24              0.454695   \n",
       "17          GBM_grid_0_AutoML_20181015_213242_model_1              0.456129   \n",
       "18          GBM_grid_0_AutoML_20181015_213242_model_6              0.457004   \n",
       "19         GBM_grid_0_AutoML_20181015_213242_model_33              0.457601   \n",
       "20         GBM_grid_0_AutoML_20181015_213242_model_10              0.458722   \n",
       "21         GBM_grid_0_AutoML_20181015_213242_model_34              0.458908   \n",
       "22         GBM_grid_0_AutoML_20181015_213242_model_20              0.461495   \n",
       "23          GBM_grid_0_AutoML_20181015_213242_model_2              0.462853   \n",
       "24         GBM_grid_0_AutoML_20181015_213242_model_19              0.463084   \n",
       "25         GBM_grid_0_AutoML_20181015_213242_model_18              0.464845   \n",
       "26          GBM_grid_0_AutoML_20181015_213242_model_8              0.466667   \n",
       "27                       XRT_0_AutoML_20181015_213242              0.466988   \n",
       "28         GBM_grid_0_AutoML_20181015_213242_model_23              0.467196   \n",
       "29          GBM_grid_0_AutoML_20181015_213242_model_0              0.468976   \n",
       "30          GBM_grid_0_AutoML_20181015_213242_model_3              0.470560   \n",
       "31              DeepLearning_0_AutoML_20181015_213242              0.473731   \n",
       "32          GBM_grid_0_AutoML_20181015_213242_model_5              0.474758   \n",
       "33                       DRF_0_AutoML_20181015_213242              0.475056   \n",
       "34         GBM_grid_0_AutoML_20181015_213242_model_13              0.475432   \n",
       "35         GBM_grid_0_AutoML_20181015_213242_model_29              0.475622   \n",
       "36         GBM_grid_0_AutoML_20181015_213242_model_32              0.475799   \n",
       "37         GBM_grid_0_AutoML_20181015_213242_model_30              0.475852   \n",
       "38         GBM_grid_0_AutoML_20181015_213242_model_16              0.477078   \n",
       "39         GBM_grid_0_AutoML_20181015_213242_model_31              0.481068   \n",
       "40  DeepLearning_grid_0_AutoML_20181015_213242_mod...              0.483185   \n",
       "41          GBM_grid_0_AutoML_20181015_213242_model_9              0.483856   \n",
       "42  DeepLearning_grid_0_AutoML_20181015_213242_mod...              0.485761   \n",
       "43         GBM_grid_0_AutoML_20181015_213242_model_11              0.492224   \n",
       "44         GBM_grid_0_AutoML_20181015_213242_model_28              0.502533   \n",
       "\n",
       "     logloss      rmse       mse  \n",
       "0   0.848466  0.556677  0.309889  \n",
       "1   0.862569  0.558050  0.311420  \n",
       "2   0.909199  0.591513  0.349887  \n",
       "3   0.880841  0.551255  0.303882  \n",
       "4   0.855553  0.559897  0.313485  \n",
       "5   0.862696  0.560840  0.314541  \n",
       "6   0.985391  0.624715  0.390269  \n",
       "7   0.858938  0.564020  0.318119  \n",
       "8   0.854086  0.558031  0.311398  \n",
       "9   0.846669  0.556045  0.309186  \n",
       "10  0.912418  0.592731  0.351330  \n",
       "11  0.913159  0.593412  0.352138  \n",
       "12  0.916356  0.594581  0.353526  \n",
       "13  1.086515  0.662587  0.439022  \n",
       "14  0.976972  0.621021  0.385667  \n",
       "15  0.867403  0.565669  0.319981  \n",
       "16  0.891817  0.561166  0.314908  \n",
       "17  0.880989  0.565609  0.319914  \n",
       "18  0.940394  0.605503  0.366634  \n",
       "19  0.923160  0.597827  0.357397  \n",
       "20  0.993862  0.628098  0.394507  \n",
       "21  0.910971  0.591723  0.350136  \n",
       "22  0.925990  0.598989  0.358788  \n",
       "23  0.885802  0.566502  0.320924  \n",
       "24  1.087479  0.662914  0.439455  \n",
       "25  0.928524  0.599671  0.359605  \n",
       "26  1.086333  0.662519  0.438932  \n",
       "27  1.176779  0.566676  0.321121  \n",
       "28  0.943196  0.606104  0.367362  \n",
       "29  0.876045  0.565570  0.319869  \n",
       "30  0.903350  0.571479  0.326588  \n",
       "31  0.908639  0.569251  0.324047  \n",
       "32  0.939469  0.576609  0.332478  \n",
       "33  1.211644  0.568224  0.322878  \n",
       "34  2.161950  0.643656  0.414293  \n",
       "35  0.936402  0.601461  0.361755  \n",
       "36  0.915116  0.576040  0.331822  \n",
       "37  1.017827  0.637501  0.406408  \n",
       "38  0.948736  0.580553  0.337042  \n",
       "39  1.270723  0.611205  0.373571  \n",
       "40  0.950508  0.578726  0.334923  \n",
       "41  1.078997  0.595749  0.354917  \n",
       "42  0.971095  0.580567  0.337058  \n",
       "43  1.147914  0.606909  0.368339  \n",
       "44  1.692354  0.638831  0.408105  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml_ld_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_grid_0_AutoML_20181015_213242_model_22\n",
      "\n",
      "\n",
      "ModelMetricsMultinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.3355628277811455\n",
      "RMSE: 0.5792778502421316\n",
      "LogLoss: 0.8764685140691142\n",
      "Mean Per-Class Error: 0.3713549762853448\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>F</b></td>\n",
       "<td><b>I</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>430.0</td>\n",
       "<td>104.0</td>\n",
       "<td>417.0</td>\n",
       "<td>0.5478444</td>\n",
       "<td>521 / 951</td></tr>\n",
       "<tr><td>30.0</td>\n",
       "<td>777.0</td>\n",
       "<td>168.0</td>\n",
       "<td>0.2030769</td>\n",
       "<td>198 / 975</td></tr>\n",
       "<tr><td>241.0</td>\n",
       "<td>161.0</td>\n",
       "<td>705.0</td>\n",
       "<td>0.3631436</td>\n",
       "<td>402 / 1,107</td></tr>\n",
       "<tr><td>701.0</td>\n",
       "<td>1042.0</td>\n",
       "<td>1290.0</td>\n",
       "<td>0.3696011</td>\n",
       "<td>1,121 / 3,033</td></tr></table></div>"
      ],
      "text/plain": [
       "F    I     M     Error     Rate\n",
       "---  ----  ----  --------  -------------\n",
       "430  104   417   0.547844  521 / 951\n",
       "30   777   168   0.203077  198 / 975\n",
       "241  161   705   0.363144  402 / 1,107\n",
       "701  1042  1290  0.369601  1,121 / 3,033"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.6303989</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9218595</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9999999</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.630399\n",
       "2    0.92186\n",
       "3    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.34790847558027604\n",
      "RMSE: 0.5898376688380254\n",
      "LogLoss: 0.9046046572431098\n",
      "Mean Per-Class Error: 0.42848221476913456\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>F</b></td>\n",
       "<td><b>I</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>82.0</td>\n",
       "<td>22.0</td>\n",
       "<td>112.0</td>\n",
       "<td>0.6203704</td>\n",
       "<td>134 / 216</td></tr>\n",
       "<tr><td>11.0</td>\n",
       "<td>176.0</td>\n",
       "<td>50.0</td>\n",
       "<td>0.2573840</td>\n",
       "<td>61 / 237</td></tr>\n",
       "<tr><td>66.0</td>\n",
       "<td>40.0</td>\n",
       "<td>154.0</td>\n",
       "<td>0.4076923</td>\n",
       "<td>106 / 260</td></tr>\n",
       "<tr><td>159.0</td>\n",
       "<td>238.0</td>\n",
       "<td>316.0</td>\n",
       "<td>0.4221599</td>\n",
       "<td>301 / 713</td></tr></table></div>"
      ],
      "text/plain": [
       "F    I    M    Error     Rate\n",
       "---  ---  ---  --------  ---------\n",
       "82   22   112  0.62037   134 / 216\n",
       "11   176  50   0.257384  61 / 237\n",
       "66   40   154  0.407692  106 / 260\n",
       "159  238  316  0.42216   301 / 713"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.5778401</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.8934081</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.57784\n",
       "2    0.893408\n",
       "3    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.3498871040759861\n",
      "RMSE: 0.5915125561439809\n",
      "LogLoss: 0.9091992934581864\n",
      "Mean Per-Class Error: 0.441817981079862\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>F</b></td>\n",
       "<td><b>I</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>342.0</td>\n",
       "<td>113.0</td>\n",
       "<td>496.0</td>\n",
       "<td>0.6403785</td>\n",
       "<td>609 / 951</td></tr>\n",
       "<tr><td>49.0</td>\n",
       "<td>758.0</td>\n",
       "<td>168.0</td>\n",
       "<td>0.2225641</td>\n",
       "<td>217 / 975</td></tr>\n",
       "<tr><td>332.0</td>\n",
       "<td>180.0</td>\n",
       "<td>595.0</td>\n",
       "<td>0.4625113</td>\n",
       "<td>512 / 1,107</td></tr>\n",
       "<tr><td>723.0</td>\n",
       "<td>1051.0</td>\n",
       "<td>1259.0</td>\n",
       "<td>0.4411474</td>\n",
       "<td>1,338 / 3,033</td></tr></table></div>"
      ],
      "text/plain": [
       "F    I     M     Error     Rate\n",
       "---  ----  ----  --------  -------------\n",
       "342  113   496   0.640379  609 / 951\n",
       "49   758   168   0.222564  217 / 975\n",
       "332  180   595   0.462511  512 / 1,107\n",
       "723  1051  1259  0.441147  1,338 / 3,033"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.5588526</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.8882295</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.558853\n",
       "2    0.88823\n",
       "3    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.5588475</td>\n",
       "<td>0.0092528</td>\n",
       "<td>0.5453048</td>\n",
       "<td>0.5683690</td>\n",
       "<td>0.5782537</td>\n",
       "<td>0.5445545</td>\n",
       "<td>0.5577558</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.4411524</td>\n",
       "<td>0.0092528</td>\n",
       "<td>0.4546952</td>\n",
       "<td>0.4316310</td>\n",
       "<td>0.4217463</td>\n",
       "<td>0.4554456</td>\n",
       "<td>0.4422442</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>267.6</td>\n",
       "<td>5.5425625</td>\n",
       "<td>276.0</td>\n",
       "<td>262.0</td>\n",
       "<td>256.0</td>\n",
       "<td>276.0</td>\n",
       "<td>268.0</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.9092017</td>\n",
       "<td>0.0083847</td>\n",
       "<td>0.9263616</td>\n",
       "<td>0.8963156</td>\n",
       "<td>0.8976175</td>\n",
       "<td>0.9192444</td>\n",
       "<td>0.9064695</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.6529588</td>\n",
       "<td>0.0241632</td>\n",
       "<td>0.5896415</td>\n",
       "<td>0.6632124</td>\n",
       "<td>0.6556604</td>\n",
       "<td>0.6631579</td>\n",
       "<td>0.6931217</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.5610532</td>\n",
       "<td>0.0109361</td>\n",
       "<td>0.5579544</td>\n",
       "<td>0.5648125</td>\n",
       "<td>0.5882248</td>\n",
       "<td>0.542308</td>\n",
       "<td>0.5519665</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.4389467</td>\n",
       "<td>0.0109361</td>\n",
       "<td>0.4420456</td>\n",
       "<td>0.4351875</td>\n",
       "<td>0.4117753</td>\n",
       "<td>0.4576920</td>\n",
       "<td>0.4480334</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.3498882</td>\n",
       "<td>0.0040182</td>\n",
       "<td>0.3582157</td>\n",
       "<td>0.3434380</td>\n",
       "<td>0.3448337</td>\n",
       "<td>0.3546322</td>\n",
       "<td>0.3483211</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.4804542</td>\n",
       "<td>0.0094307</td>\n",
       "<td>0.4649361</td>\n",
       "<td>0.4845100</td>\n",
       "<td>0.5039874</td>\n",
       "<td>0.4727658</td>\n",
       "<td>0.4760716</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.5914940</td>\n",
       "<td>0.0033925</td>\n",
       "<td>0.5985112</td>\n",
       "<td>0.5860359</td>\n",
       "<td>0.5872254</td>\n",
       "<td>0.59551</td>\n",
       "<td>0.5901874</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean      sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  --------  ----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.558848  0.00925283  0.545305      0.568369      0.578254      0.544555      0.557756\n",
       "err                      0.441152  0.00925283  0.454695      0.431631      0.421746      0.455446      0.442244\n",
       "err_count                267.6     5.54256     276           262           256           276           268\n",
       "logloss                  0.909202  0.00838468  0.926362      0.896316      0.897617      0.919244      0.906469\n",
       "max_per_class_error      0.652959  0.0241632   0.589641      0.663212      0.65566       0.663158      0.693122\n",
       "mean_per_class_accuracy  0.561053  0.0109361   0.557954      0.564813      0.588225      0.542308      0.551967\n",
       "mean_per_class_error     0.438947  0.0109361   0.442046      0.435188      0.411775      0.457692      0.448033\n",
       "mse                      0.349888  0.00401822  0.358216      0.343438      0.344834      0.354632      0.348321\n",
       "r2                       0.480454  0.00943075  0.464936      0.48451       0.503987      0.472766      0.476072\n",
       "rmse                     0.591494  0.00339248  0.598511      0.586036      0.587225      0.59551       0.590187"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:33:59</td>\n",
       "<td>43.170 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.6666667</td>\n",
       "<td>1.0986123</td>\n",
       "<td>0.6795252</td>\n",
       "<td>0.6666667</td>\n",
       "<td>1.0986123</td>\n",
       "<td>0.6577840</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:33:59</td>\n",
       "<td>43.204 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.6589148</td>\n",
       "<td>1.0758151</td>\n",
       "<td>0.3999341</td>\n",
       "<td>0.6594934</td>\n",
       "<td>1.0775274</td>\n",
       "<td>0.4361851</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:33:59</td>\n",
       "<td>43.240 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.6516291</td>\n",
       "<td>1.0551450</td>\n",
       "<td>0.3916914</td>\n",
       "<td>0.6526977</td>\n",
       "<td>1.0582666</td>\n",
       "<td>0.4291725</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:33:59</td>\n",
       "<td>43.276 sec</td>\n",
       "<td>15.0</td>\n",
       "<td>0.6447465</td>\n",
       "<td>1.0362364</td>\n",
       "<td>0.3972964</td>\n",
       "<td>0.6463798</td>\n",
       "<td>1.0409502</td>\n",
       "<td>0.4319776</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:33:59</td>\n",
       "<td>43.302 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.6382737</td>\n",
       "<td>1.0189422</td>\n",
       "<td>0.3943290</td>\n",
       "<td>0.6404499</td>\n",
       "<td>1.0251628</td>\n",
       "<td>0.4235624</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:33:59</td>\n",
       "<td>43.326 sec</td>\n",
       "<td>25.0</td>\n",
       "<td>0.6322953</td>\n",
       "<td>1.0033566</td>\n",
       "<td>0.3982855</td>\n",
       "<td>0.6348419</td>\n",
       "<td>1.0105629</td>\n",
       "<td>0.4207574</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:33:59</td>\n",
       "<td>43.350 sec</td>\n",
       "<td>30.0</td>\n",
       "<td>0.6265554</td>\n",
       "<td>0.9887010</td>\n",
       "<td>0.4002638</td>\n",
       "<td>0.6296340</td>\n",
       "<td>0.9973630</td>\n",
       "<td>0.4165498</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:33:59</td>\n",
       "<td>43.372 sec</td>\n",
       "<td>35.0</td>\n",
       "<td>0.6211944</td>\n",
       "<td>0.9752536</td>\n",
       "<td>0.3943290</td>\n",
       "<td>0.6249506</td>\n",
       "<td>0.9857307</td>\n",
       "<td>0.4207574</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:33:59</td>\n",
       "<td>43.397 sec</td>\n",
       "<td>40.0</td>\n",
       "<td>0.6161599</td>\n",
       "<td>0.9628211</td>\n",
       "<td>0.3887240</td>\n",
       "<td>0.6206128</td>\n",
       "<td>0.9751460</td>\n",
       "<td>0.4179523</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:33:59</td>\n",
       "<td>43.432 sec</td>\n",
       "<td>45.0</td>\n",
       "<td>0.6113498</td>\n",
       "<td>0.9511279</td>\n",
       "<td>0.3854270</td>\n",
       "<td>0.6164051</td>\n",
       "<td>0.9650137</td>\n",
       "<td>0.4193548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:33:59</td>\n",
       "<td>43.461 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.6069116</td>\n",
       "<td>0.9404838</td>\n",
       "<td>0.3857567</td>\n",
       "<td>0.6125847</td>\n",
       "<td>0.9559910</td>\n",
       "<td>0.4291725</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:33:59</td>\n",
       "<td>43.497 sec</td>\n",
       "<td>55.0</td>\n",
       "<td>0.6026932</td>\n",
       "<td>0.9304485</td>\n",
       "<td>0.3877349</td>\n",
       "<td>0.6090266</td>\n",
       "<td>0.9476800</td>\n",
       "<td>0.4263675</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:33:59</td>\n",
       "<td>43.525 sec</td>\n",
       "<td>60.0</td>\n",
       "<td>0.5986856</td>\n",
       "<td>0.9210301</td>\n",
       "<td>0.3818002</td>\n",
       "<td>0.6055994</td>\n",
       "<td>0.9397738</td>\n",
       "<td>0.4235624</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:33:59</td>\n",
       "<td>43.564 sec</td>\n",
       "<td>65.0</td>\n",
       "<td>0.5949586</td>\n",
       "<td>0.9123260</td>\n",
       "<td>0.3801517</td>\n",
       "<td>0.6025618</td>\n",
       "<td>0.9328706</td>\n",
       "<td>0.4249649</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:33:59</td>\n",
       "<td>43.592 sec</td>\n",
       "<td>70.0</td>\n",
       "<td>0.5914491</td>\n",
       "<td>0.9041945</td>\n",
       "<td>0.3758655</td>\n",
       "<td>0.5996274</td>\n",
       "<td>0.9262205</td>\n",
       "<td>0.4165498</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:33:59</td>\n",
       "<td>43.625 sec</td>\n",
       "<td>75.0</td>\n",
       "<td>0.5881361</td>\n",
       "<td>0.8965868</td>\n",
       "<td>0.3735575</td>\n",
       "<td>0.5969497</td>\n",
       "<td>0.9202256</td>\n",
       "<td>0.4207574</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:33:59</td>\n",
       "<td>43.655 sec</td>\n",
       "<td>80.0</td>\n",
       "<td>0.5849721</td>\n",
       "<td>0.8893604</td>\n",
       "<td>0.3719090</td>\n",
       "<td>0.5944023</td>\n",
       "<td>0.9146085</td>\n",
       "<td>0.4207574</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:33:59</td>\n",
       "<td>43.686 sec</td>\n",
       "<td>85.0</td>\n",
       "<td>0.5820931</td>\n",
       "<td>0.8828244</td>\n",
       "<td>0.3728981</td>\n",
       "<td>0.5920360</td>\n",
       "<td>0.9093678</td>\n",
       "<td>0.4207574</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-10-15 21:33:59</td>\n",
       "<td>43.715 sec</td>\n",
       "<td>90.0</td>\n",
       "<td>0.5792779</td>\n",
       "<td>0.8764685</td>\n",
       "<td>0.3696011</td>\n",
       "<td>0.5898377</td>\n",
       "<td>0.9046047</td>\n",
       "<td>0.4221599</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_classification_error    validation_rmse    validation_logloss    validation_classification_error\n",
       "--  -------------------  ----------  -----------------  ---------------  ------------------  -------------------------------  -----------------  --------------------  ---------------------------------\n",
       "    2018-10-15 21:33:59  43.170 sec  0                  0.666667         1.09861             0.679525                         0.666667           1.09861               0.657784\n",
       "    2018-10-15 21:33:59  43.204 sec  5                  0.658915         1.07582             0.399934                         0.659493           1.07753               0.436185\n",
       "    2018-10-15 21:33:59  43.240 sec  10                 0.651629         1.05515             0.391691                         0.652698           1.05827               0.429173\n",
       "    2018-10-15 21:33:59  43.276 sec  15                 0.644747         1.03624             0.397296                         0.64638            1.04095               0.431978\n",
       "    2018-10-15 21:33:59  43.302 sec  20                 0.638274         1.01894             0.394329                         0.64045            1.02516               0.423562\n",
       "    2018-10-15 21:33:59  43.326 sec  25                 0.632295         1.00336             0.398286                         0.634842           1.01056               0.420757\n",
       "    2018-10-15 21:33:59  43.350 sec  30                 0.626555         0.988701            0.400264                         0.629634           0.997363              0.41655\n",
       "    2018-10-15 21:33:59  43.372 sec  35                 0.621194         0.975254            0.394329                         0.624951           0.985731              0.420757\n",
       "    2018-10-15 21:33:59  43.397 sec  40                 0.61616          0.962821            0.388724                         0.620613           0.975146              0.417952\n",
       "    2018-10-15 21:33:59  43.432 sec  45                 0.61135          0.951128            0.385427                         0.616405           0.965014              0.419355\n",
       "    2018-10-15 21:33:59  43.461 sec  50                 0.606912         0.940484            0.385757                         0.612585           0.955991              0.429173\n",
       "    2018-10-15 21:33:59  43.497 sec  55                 0.602693         0.930449            0.387735                         0.609027           0.94768               0.426367\n",
       "    2018-10-15 21:33:59  43.525 sec  60                 0.598686         0.92103             0.3818                           0.605599           0.939774              0.423562\n",
       "    2018-10-15 21:33:59  43.564 sec  65                 0.594959         0.912326            0.380152                         0.602562           0.932871              0.424965\n",
       "    2018-10-15 21:33:59  43.592 sec  70                 0.591449         0.904194            0.375865                         0.599627           0.92622               0.41655\n",
       "    2018-10-15 21:33:59  43.625 sec  75                 0.588136         0.896587            0.373558                         0.59695            0.920226              0.420757\n",
       "    2018-10-15 21:33:59  43.655 sec  80                 0.584972         0.88936             0.371909                         0.594402           0.914608              0.420757\n",
       "    2018-10-15 21:33:59  43.686 sec  85                 0.582093         0.882824            0.372898                         0.592036           0.909368              0.420757\n",
       "    2018-10-15 21:33:59  43.715 sec  90                 0.579278         0.876469            0.369601                         0.589838           0.904605              0.42216"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>Viscera weight</td>\n",
       "<td>8141.4252930</td>\n",
       "<td>1.0</td>\n",
       "<td>0.3942294</td></tr>\n",
       "<tr><td>Whole weight</td>\n",
       "<td>4870.9775391</td>\n",
       "<td>0.5982954</td>\n",
       "<td>0.2358657</td></tr>\n",
       "<tr><td>Rings</td>\n",
       "<td>2587.4948730</td>\n",
       "<td>0.3178184</td>\n",
       "<td>0.1252934</td></tr>\n",
       "<tr><td>Shell weight</td>\n",
       "<td>2470.8752441</td>\n",
       "<td>0.3034942</td>\n",
       "<td>0.1196463</td></tr>\n",
       "<tr><td>Shucked weight</td>\n",
       "<td>909.9114990</td>\n",
       "<td>0.1117632</td>\n",
       "<td>0.0440603</td></tr>\n",
       "<tr><td>Length</td>\n",
       "<td>747.4481201</td>\n",
       "<td>0.0918080</td>\n",
       "<td>0.0361934</td></tr>\n",
       "<tr><td>Height</td>\n",
       "<td>519.3305054</td>\n",
       "<td>0.0637886</td>\n",
       "<td>0.0251474</td></tr>\n",
       "<tr><td>Diameter</td>\n",
       "<td>404.0267639</td>\n",
       "<td>0.0496260</td>\n",
       "<td>0.0195640</td></tr></table></div>"
      ],
      "text/plain": [
       "variable        relative_importance    scaled_importance    percentage\n",
       "--------------  ---------------------  -------------------  ------------\n",
       "Viscera weight  8141.43                1                    0.394229\n",
       "Whole weight    4870.98                0.598295             0.235866\n",
       "Rings           2587.49                0.317818             0.125293\n",
       "Shell weight    2470.88                0.303494             0.119646\n",
       "Shucked weight  909.911                0.111763             0.0440603\n",
       "Length          747.448                0.091808             0.0361934\n",
       "Height          519.331                0.0637886            0.0251474\n",
       "Diameter        404.027                0.049626             0.019564"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = h2o.get_model(aml.leaderboard[2,\"model_id\"])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3UAAAJTCAYAAACvjD+/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1AEAAAzMqAMAABiYUQcAADCw/wCTIzUeqTa1hAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e58c198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m.varimp_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomialGLM: stackedensemble\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.2696322129165289\n",
      "RMSE: 0.5192612183829338\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader.model_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>predict  </th><th style=\"text-align: right;\">        F</th><th style=\"text-align: right;\">        I</th><th style=\"text-align: right;\">        M</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.439717 </td><td style=\"text-align: right;\">0.0871061</td><td style=\"text-align: right;\">0.473177 </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.337998 </td><td style=\"text-align: right;\">0.266052 </td><td style=\"text-align: right;\">0.395951 </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.453455 </td><td style=\"text-align: right;\">0.0570543</td><td style=\"text-align: right;\">0.489491 </td></tr>\n",
       "<tr><td>F        </td><td style=\"text-align: right;\">0.51255  </td><td style=\"text-align: right;\">0.0507531</td><td style=\"text-align: right;\">0.436697 </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.434549 </td><td style=\"text-align: right;\">0.110384 </td><td style=\"text-align: right;\">0.455067 </td></tr>\n",
       "<tr><td>I        </td><td style=\"text-align: right;\">0.0383781</td><td style=\"text-align: right;\">0.879028 </td><td style=\"text-align: right;\">0.0825935</td></tr>\n",
       "<tr><td>I        </td><td style=\"text-align: right;\">0.104493 </td><td style=\"text-align: right;\">0.710135 </td><td style=\"text-align: right;\">0.185373 </td></tr>\n",
       "<tr><td>I        </td><td style=\"text-align: right;\">0.110964 </td><td style=\"text-align: right;\">0.681731 </td><td style=\"text-align: right;\">0.207305 </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.351413 </td><td style=\"text-align: right;\">0.216321 </td><td style=\"text-align: right;\">0.432266 </td></tr>\n",
       "<tr><td>F        </td><td style=\"text-align: right;\">0.494625 </td><td style=\"text-align: right;\">0.061071 </td><td style=\"text-align: right;\">0.444304 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = aml.predict(test)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomialGLM: stackedensemble\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.3082800466453451\n",
      "RMSE: 0.5552297242091286\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref = aml.leader.model_performance(test)\n",
    "pref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model the mse is 0.2696322129165289 on the training data and 0.3082800466453451 on the testing data. The model is a litte bit overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
